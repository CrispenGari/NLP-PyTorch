{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_English -  Afrikaans.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8hWaEWxsbjf"
      },
      "source": [
        "### NMT (Nueral Machine Translation)\n",
        "\n",
        "In these series of notebooks we are going to do create bidirectional NMT model for our application. We are going to use the following notebooks as reference to this notebook.\n",
        "\n",
        "1. [17_Custom_Dataset_and_Translation.ipynb](https://github.com/CrispenGari/pytorch-python/blob/main/09_NLP/03_Sequence_To_Sequence/17_Custom_Dataset_and_Translation.ipynb)\n",
        "2. [16_Data_Preparation_Translation_Dataset.ipynb](https://github.com/CrispenGari/pytorch-python/blob/main/09_NLP/03_Sequence_To_Sequence/16_Data_Preparation_Translation_Dataset.ipynb)\n",
        "\n",
        "I will be loading the data from my google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEY0_2fdsbLZ",
        "outputId": "dd46e625-4164-42ed-a3d7-4ce97b809ff7"
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P61k3sTWuGYt"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lNfuXwhsbFx"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn  import functional as F\n",
        "import spacy, math, random\n",
        "import numpy as np\n",
        "from torchtext.legacy import datasets, data\n",
        "import time, os, json\n",
        "from prettytable import PrettyTable\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3nOk8n7sbCx"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deteministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjqtcpj8uZsW",
        "outputId": "d9caa634-0818-41d4-ed79-733781a83c3c"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKiHZEUKuR2f",
        "outputId": "8ecfb8d2-a3a5-4bc8-a134-bfc3fc62113a"
      },
      "source": [
        "base_path = '/content/drive/My Drive/NLP Data/seq2seq/manythings'\n",
        "path_to_files = os.path.join(base_path, \"Afrikaans - English\")\n",
        "os.listdir(path_to_files)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['afr.txt',\n",
              " 'train.en',\n",
              " 'test.en',\n",
              " 'valid.en',\n",
              " 'valid.af',\n",
              " 'test.af',\n",
              " 'train.af']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga_vPyt3u5IE"
      },
      "source": [
        "### File extensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XV9PLt7uRyI"
      },
      "source": [
        "exts = (\".en\", \".af\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMXQVQAZvB60"
      },
      "source": [
        "### Tokenizer models\n",
        "\n",
        "All the tokenization models that we are going to use are going to be found [here](https://spacy.io/usage/models) but to those languages that doesn't have tokenization models we are going to create our own tokenizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drvBIe75uRwR"
      },
      "source": [
        "import en_core_web_sm\n",
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC2PFvU6uRsm"
      },
      "source": [
        "def tokenize_af(sent):\n",
        "  return sent.split(\" \")\n",
        "\n",
        "def tokenize_en(sent):\n",
        "  return [tok.text for tok in spacy_en.tokenizer(sent)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmCTTn4Hwiom"
      },
      "source": [
        "### Fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa8oJesouRqO"
      },
      "source": [
        "SRC = data.Field(\n",
        "     tokenize = tokenize_en,\n",
        "     lower= True,\n",
        "     init_token = \"<sos>\",\n",
        "     eos_token = \"<eos>\",\n",
        "     batch_first =True\n",
        ")\n",
        "TRG = data.Field(\n",
        "    tokenize = tokenize_af,\n",
        "    lower= True,\n",
        "    init_token = \"<sos>\",\n",
        "    eos_token = \"<eos>\",\n",
        "    batch_first =True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWi2bUtHw4_e"
      },
      "source": [
        "### Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "natPw3mhuRnQ"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.TranslationDataset.splits(\n",
        "    exts= exts,\n",
        "    path=path_to_files,\n",
        "    train='train', validation='valid', test='test',\n",
        "    fields = (SRC, TRG)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-04eSK8uRkp",
        "outputId": "43e94bff-6828-43fc-df66-f667296a5d77"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': ['i', \"'m\", 'glad', 'you', 'finally', 'made', 'it', 'back', '.'], 'trg': ['ek', 'is', 'bly', 'jy', 'het', 'uiteindelik', 'terug', 'gekom.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEHHOMmDxKlO",
        "outputId": "7410e656-0059-4426-80c6-db5c3ef951de"
      },
      "source": [
        "print(vars(valid_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': ['i', 'have', 'certain', 'rights', '.'], 'trg': ['ek', 'is', 'bly', 'jy', 'het', 'uiteindelik', 'terug', 'gekom.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxM9sZGfuRhx",
        "outputId": "3e67dbc1-ed14-4a3f-e14b-696d06ab7c93"
      },
      "source": [
        "print(vars(test_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': ['you', \"'re\", 'a', 'long', 'way', 'from', 'home', '.'], 'trg': ['ek', 'is', 'bly', 'jy', 'het', 'uiteindelik', 'terug', 'gekom.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAV3a9mPxOss"
      },
      "source": [
        "### Counting examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyEk_Y01uRen",
        "outputId": "7b600529-06a4-4df4-cf5c-04b2885cb300"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "def tabulate(column_names, data):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= \"VISUALIZING SETS EXAMPLES\"\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'r'\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "\n",
        "column_names = [\"SUBSET\", \"EXAMPLE(s)\"]\n",
        "row_data = [\n",
        "        [\"training\", len(train_data)],\n",
        "        ['validation', len(valid_data)],\n",
        "        ['test', len(test_data)]\n",
        "]\n",
        "tabulate(column_names, row_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+\n",
            "|  VISUALIZING SETS EXAMPLES  |\n",
            "+--------------+--------------+\n",
            "| SUBSET       |   EXAMPLE(s) |\n",
            "+--------------+--------------+\n",
            "| training     |          825 |\n",
            "| validation   |            9 |\n",
            "| test         |            9 |\n",
            "+--------------+--------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljHsxO81xVdn"
      },
      "source": [
        "Our dataset is very small so we are not going to set the `min_freq` to a number greater than 1 dring building of the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmv9XL9EuRcN"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=1)\n",
        "TRG.build_vocab(train_data, min_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7oilFldx-X9"
      },
      "source": [
        "Saving the dictionary maping of our SRC and TRG to a json file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA_gPfD2uRZb",
        "outputId": "5e30f8ef-5b71-49d3-c6b0-5a8b1018f5f7"
      },
      "source": [
        "len(SRC.vocab.stoi), len(TRG.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1032, 1240)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceitelKvuRWX",
        "outputId": "c4e8dd50-40f5-432f-8678-7ae46055725e"
      },
      "source": [
        "src = dict(SRC.vocab.stoi)\n",
        "trg = dict(TRG.vocab.stoi)\n",
        "\n",
        "src_vocab_path = \"src_vocab.json\"\n",
        "trg_vocab_path = \"trg_vocab.json\"\n",
        "\n",
        "with open(src_vocab_path, \"w\") as f:\n",
        "  json.dump(src, f, indent=2)\n",
        "\n",
        "with open(trg_vocab_path, \"w\") as f:\n",
        "  json.dump(trg, f, indent=2)\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gd0l5cL4uRTO",
        "outputId": "9abfb7ec-99a2-4652-ecf4-94ba168fe5fb"
      },
      "source": [
        "files.download(src_vocab_path)\n",
        "files.download(trg_vocab_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_dd917af1-c23c-4ade-b007-f98db99f0f30\", \"src_vocab.json\", 21302)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_03551eaa-d525-4ade-83b5-9fe4e90fcf51\", \"trg_vocab.json\", 16962)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX6pZxDwzQAT"
      },
      "source": [
        "### Iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTE-gGpHuQRH"
      },
      "source": [
        "BATCH_SIZE = 64 # 128 for languages with good vocab corpus\n",
        "sort_key = lambda x: len(x.src)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key= sort_key,\n",
        "    sort_within_batch = True,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rrB0xv60mIv"
      },
      "source": [
        "### Model based on (Attention is all you need) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY4p8X1Bzrrv"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TstLLxavsbAQ"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, hid_dim, n_layers, \n",
        "               n_heads, pf_dim, dropout, device, max_length=100):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.device = device \n",
        "\n",
        "    self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "    self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "\n",
        "    self.layers = nn.ModuleList([\n",
        "          EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device) for _ in range(n_layers)\n",
        "    ])\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([\n",
        "        hid_dim\n",
        "    ])).to(device)\n",
        "\n",
        "  def forward(self, src, src_mask):\n",
        "    batch_size = src.shape[0]\n",
        "    src_len = src.shape[1]\n",
        "    pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "    src = self.dropout(\n",
        "        (self.tok_embedding(src) * self.scale) + self.pos_embedding(pos)\n",
        "    )\n",
        "    for layer in self.layers:\n",
        "      src = layer(src, src_mask)\n",
        "    return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDKNRHQS04CG"
      },
      "source": [
        "### Encoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDr-sIsW06HO"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, hid_dim, n_heads, pf_dim,\n",
        "               dropout, device):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "    self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "    self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, \n",
        "                                                  dropout, device)\n",
        "    self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                 pf_dim,\n",
        "                                                                 dropout\n",
        "                                                                 )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, src, src_mask):\n",
        "    _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "    src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "    _src = self.positionwise_feedforward(src)\n",
        "    src = self.ff_layer_norm(src + self.dropout(_src)) # src = [batch size, src len, hid dim]\n",
        "    return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7NlD1sz1BSi"
      },
      "source": [
        "### Mutli Head Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHiBnQaF1AtW"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "  def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "    super(MultiHeadAttentionLayer, self).__init__()\n",
        "\n",
        "    assert hid_dim % n_heads == 0\n",
        "\n",
        "    self.hid_dim = hid_dim\n",
        "    self.n_heads = n_heads\n",
        "    self.head_dim = hid_dim // n_heads\n",
        "\n",
        "    self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "    self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "    self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "    self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([\n",
        "        self.head_dim\n",
        "    ])).to(device)\n",
        "\n",
        "  def forward(self, query, key, value, mask):\n",
        "    \"\"\"\n",
        "    query = [batch size, query len, hid dim]\n",
        "    key = [batch size, key len, hid dim]\n",
        "    value = [batch size, value len, hid dim]\n",
        "    \"\"\"\n",
        "    batch_size = query.shape[0]\n",
        "\n",
        "    Q = self.fc_q(query)\n",
        "    K = self.fc_k(key)\n",
        "    V = self.fc_v(value)\n",
        "    \"\"\"\n",
        "    Q = [batch size, query len, hid dim]\n",
        "    K = [batch size, key len, hid dim]\n",
        "    V = [batch size, value len, hid dim]\n",
        "    \"\"\"\n",
        "\n",
        "    Q = Q.view(batch_size, -1, self.n_heads, self.head_dim\n",
        "               ).permute(0, 2, 1, 3)\n",
        "    K = K.view(batch_size, -1, self.n_heads, self.head_dim\n",
        "               ).permute(0, 2, 1, 3)\n",
        "    V = V.view(batch_size, -1, self.n_heads, self.head_dim\n",
        "               ).permute(0, 2, 1, 3)\n",
        "    \n",
        "    \"\"\"\n",
        "    Q = [batch size, n heads, query len, head dim]\n",
        "    K = [batch size, n heads, key len, head dim]\n",
        "    V = [batch size, n heads, value len, head dim]\n",
        "    \"\"\"\n",
        "\n",
        "    energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "    if mask is not None:\n",
        "      energy = energy.masked_fill(mask == 0, -1e10)\n",
        "    \n",
        "    attention = torch.softmax(energy, dim = -1)\n",
        "    # attention = [batch size, n heads, query len, key len]\n",
        "    x = torch.matmul(self.dropout(attention), V) # x = [batch size, n heads, query len, head dim]\n",
        "    x = x.permute(0, 2, 1, 3).contiguous()\n",
        "    # x = [batch size, query len, n heads, head dim]\n",
        "    x = x.view(batch_size, -1, self.hid_dim)\n",
        "    # x = [batch size, query len, hid dim]\n",
        "    x = self.fc_o(x)\n",
        "    # x = [batch size, query len, hid dim]\n",
        "    return x, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRi_d5xy1LPM"
      },
      "source": [
        "### Pointwise Feed Forwad Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMyUUMnr1K0I"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "  def __init__(self, hid_dim, pf_dim, dropout):\n",
        "    super(PositionwiseFeedforwardLayer, self).__init__()\n",
        "    self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "    self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x = [batch size, seq len, hid dim]\n",
        "    x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "    # x = [batch size, seq len, pf dim]\n",
        "    x = self.fc_2(x) # x = [batch size, seq len, hid dim]\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2bNVH3q1Kee"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y24p2UPZ1Wqw"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,\n",
        "                output_dim,  hid_dim,   n_layers, \n",
        "                 n_heads, pf_dim,  dropout,  device,\n",
        "                 max_length = 100\n",
        "               ):\n",
        "    super(Decoder, self).__init__()\n",
        "    \n",
        "    self.device = device\n",
        "    self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "    self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "\n",
        "    self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "    self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "  def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "    \"\"\"\n",
        "    trg = [batch size, trg len]\n",
        "    enc_src = [batch size, src len, hid dim]\n",
        "    trg_mask = [batch size, 1, trg len, trg len]\n",
        "    src_mask = [batch size, 1, 1, src len]\n",
        "    \"\"\"\n",
        "    batch_size = trg.shape[0]\n",
        "    trg_len = trg.shape[1]\n",
        "    pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "    # pos = [batch size, trg len]\n",
        "    trg = self.dropout(\n",
        "        (self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos)\n",
        "    )\n",
        "    # trg = [batch size, trg len, hid dim]\n",
        "\n",
        "    for layer in self.layers:\n",
        "      trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "    \n",
        "    \"\"\"\n",
        "    trg = [batch size, trg len, hid dim]\n",
        "    attention = [batch size, n heads, trg len, src len]\n",
        "    \"\"\"\n",
        "    output = self.fc_out(trg) # output = [batch size, trg len, output dim]\n",
        "\n",
        "    return output, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aP4_gPazxof"
      },
      "source": [
        "### Decoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWt-1Vnczvte"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self, hid_dim,  n_heads, \n",
        "                 pf_dim, dropout, device\n",
        "               ):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "    self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "    self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "    self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "    self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, \n",
        "                                                  dropout, device)\n",
        "    self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout,\n",
        "                                                     device)\n",
        "    self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim,\n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout\n",
        "                                                                 )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "    \"\"\"\n",
        "    trg = [batch size, trg len, hid dim]\n",
        "    enc_src = [batch size, src len, hid dim]\n",
        "    trg_mask = [batch size, 1, trg len, trg len]\n",
        "    src_mask = [batch size, 1, 1, src len]\n",
        "    \"\"\"\n",
        "    # self attention\n",
        "    _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "    # dropout, residual connection and layer norm\n",
        "    trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "    # trg = [batch size, trg len, hid dim]\n",
        "\n",
        "    # encoder attention\n",
        "    _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "\n",
        "    # dropout, residual connection and layer norm\n",
        "    trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "    # trg = [batch size, trg len, hid dim]\n",
        "    # positionwise feedforward\n",
        "    _trg = self.positionwise_feedforward(trg)\n",
        "    # dropout, residual and layer norm\n",
        "    trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "    \"\"\"\n",
        "    trg = [batch size, trg len, hid dim]\n",
        "    attention = [batch size, n heads, trg len, src len]\n",
        "    \"\"\"\n",
        "    return trg, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t119XXIrzzxW"
      },
      "source": [
        "### Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur8VvLnwsa9j"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "    self.trg_pad_idx = trg_pad_idx\n",
        "    self.device = device\n",
        "\n",
        "  def make_src_mask(self, src):\n",
        "    # src = [batch size, src len]\n",
        "    src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    # src_mask = [batch size, 1, 1, src len]\n",
        "    return src_mask\n",
        "\n",
        "  def make_trg_mask(self, trg):\n",
        "    # trg = [batch size, trg len]\n",
        "    trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    # trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "    trg_len = trg.shape[1]\n",
        "    trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), \n",
        "                                         device = self.device)).bool()\n",
        "\n",
        "    # trg_sub_mask = [trg len, trg len]\n",
        "    trg_mask = trg_pad_mask & trg_sub_mask\n",
        "    # trg_mask = [batch size, 1, trg len, trg len]\n",
        "    return trg_mask\n",
        "\n",
        "  def forward(self, src, trg):\n",
        "    \"\"\"\n",
        "    src = [batch size, src len]\n",
        "    trg = [batch size, trg len]\n",
        "    \"\"\"\n",
        "    src_mask = self.make_src_mask(src)\n",
        "    trg_mask = self.make_trg_mask(trg)\n",
        "    \"\"\"\n",
        "    src_mask = [batch size, 1, 1, src len]\n",
        "    trg_mask = [batch size, 1, trg len, trg len]\n",
        "    \"\"\"\n",
        "    enc_src = self.encoder(src, src_mask)\n",
        "    # enc_src = [batch size, src len, hid dim]\n",
        "    output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "    \"\"\"\n",
        "    output = [batch size, trg len, output dim]\n",
        "    attention = [batch size, n heads, trg len, src len]\n",
        "    \"\"\"\n",
        "    return output, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6RraZNi1tS0"
      },
      "source": [
        "### Seq2Seq model instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUEfOF60sa6s",
        "outputId": "15b5dc9a-0a8f-4ec1-cd2a-907b3bd1eaac"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = DEC_LAYERS = 3\n",
        "ENC_HEADS = DEC_HEADS = 8\n",
        "ENC_PF_DIM =  DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)\n",
        "print(enc)\n",
        "dec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (tok_embedding): Embedding(1032, 256)\n",
            "  (pos_embedding): Embedding(100, 256)\n",
            "  (layers): ModuleList(\n",
            "    (0): EncoderLayer(\n",
            "      (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (self_attention): MultiHeadAttentionLayer(\n",
            "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
            "        (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
            "        (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): EncoderLayer(\n",
            "      (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (self_attention): MultiHeadAttentionLayer(\n",
            "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
            "        (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
            "        (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): EncoderLayer(\n",
            "      (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (self_attention): MultiHeadAttentionLayer(\n",
            "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
            "        (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
            "        (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Decoder(\n",
              "  (tok_embedding): Embedding(1240, 256)\n",
              "  (pos_embedding): Embedding(100, 256)\n",
              "  (layers): ModuleList(\n",
              "    (0): DecoderLayer(\n",
              "      (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (self_attention): MultiHeadAttentionLayer(\n",
              "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder_attention): MultiHeadAttentionLayer(\n",
              "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "        (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "        (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): DecoderLayer(\n",
              "      (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (self_attention): MultiHeadAttentionLayer(\n",
              "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder_attention): MultiHeadAttentionLayer(\n",
              "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "        (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "        (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): DecoderLayer(\n",
              "      (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (self_attention): MultiHeadAttentionLayer(\n",
              "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder_attention): MultiHeadAttentionLayer(\n",
              "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "        (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "        (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (fc_out): Linear(in_features=256, out_features=1240, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSqGJjkdsa3m",
        "outputId": "050c5693-7c10-47d4-9966-dcf4bafcbd26"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(1032, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(1240, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=1240, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N44tQz5V2CIK"
      },
      "source": [
        "### Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdNL1peTsa0s",
        "outputId": "09dc10fc-76f8-401d-d456-6653e4d8a695"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of paramaters: 4,905,176\n",
            "Total tainable parameters: 4,905,176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yld0SPhi2HUm"
      },
      "source": [
        "Initialize model weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JDmgtkGsav_",
        "outputId": "581cf3d4-141e-4d4d-c04d-f7829d722c70"
      },
      "source": [
        "def initialize_weights(m):\n",
        "  if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "    nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(1032, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(1240, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=1240, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PowuX5bsasj"
      },
      "source": [
        "# Note that the learning rate needs to be lower than the default used by Adam or else learning is unstable.\n",
        "\n",
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg_nGzuHsapS"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpNeWJEJ2pcN"
      },
      "source": [
        "### Train and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXVjp9XOsamS"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  for i, batch in enumerate(iterator):\n",
        "    src = batch.src\n",
        "    trg = batch.trg\n",
        "    optimizer.zero_grad()\n",
        "    output, _ = model(src, trg[:,:-1])\n",
        "    \"\"\"\n",
        "    output = [batch size, trg len - 1, output dim]\n",
        "    trg = [batch size, trg len]\n",
        "    \"\"\"\n",
        "    output_dim = output.shape[-1]\n",
        "    \n",
        "    output = output.contiguous().view(-1, output_dim)\n",
        "    trg = trg[:,1:].contiguous().view(-1)\n",
        "    \"\"\"\n",
        "    output = [batch size * trg len - 1, output dim]\n",
        "    trg = [batch size * trg len - 1]\n",
        "    \"\"\"\n",
        "    loss = criterion(output, trg)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "  return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for i, batch in enumerate(iterator):\n",
        "      src = batch.src\n",
        "      trg = batch.trg\n",
        "      output, _ = model(src, trg[:,:-1])\n",
        "      \"\"\"\n",
        "      output = [batch size, trg len - 1, output dim]\n",
        "      trg = [batch size, trg len]\n",
        "      \"\"\"\n",
        "      output_dim = output.shape[-1]\n",
        "      \n",
        "      output = output.contiguous().view(-1, output_dim)\n",
        "      trg = trg[:,1:].contiguous().view(-1)\n",
        "      \"\"\"\n",
        "      output = [batch size * trg len - 1, output dim]\n",
        "      trg = [batch size * trg len - 1]\n",
        "      \"\"\"\n",
        "      loss = criterion(output, trg)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "  return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQG1RgUi2ujL"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z8_TXq8sadI"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "def tabulate_training(column_names, data, title):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= title\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'r'\n",
        "  table.align[column_names[2]] = 'r'\n",
        "  table.align[column_names[3]] = 'r'\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhkS-JDd35qx"
      },
      "source": [
        "### Model Name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOCDVLXV39iK"
      },
      "source": [
        "MODEL_NAME = \"eng-af.pt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shJMTRS7saRC",
        "outputId": "b5061589-d4e8-4bdc-8b62-85ca35e4df7b"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 0.1\n",
        "best_valid_loss = float('inf')\n",
        "column_names = [\"SET\", \"LOSS\", \"PPL\", \"ETA\"]\n",
        "print(\"TRAINING START....\")\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start = time.time()\n",
        "  train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "  valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "  end = time.time()\n",
        "  title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} | {'saving model...' if valid_loss < best_valid_loss else 'not saving...'}\" \n",
        "  if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(model.state_dict(), MODEL_NAME)\n",
        "  rows_data =[\n",
        "        [\"train\", f\"{train_loss:.3f}\", f\"{math.exp(train_loss):7.3f}\", hms_string(end - start) ],\n",
        "        [\"val\", f\"{valid_loss:.3f}\", f\"{math.exp(train_loss):7.3f}\", '' ]\n",
        "  ]\n",
        "  tabulate_training(column_names, rows_data, title)\n",
        "\n",
        "print(\"TRAINING ENDS....\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING START....\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 01/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 5.979 | 394.898 | 0:00:00.87 |\n",
            "| val   | 5.128 | 394.898 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 02/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 5.036 | 153.787 | 0:00:00.77 |\n",
            "| val   | 5.055 | 153.787 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 03/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 4.544 |  94.082 | 0:00:00.76 |\n",
            "| val   | 5.248 |  94.082 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 04/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 4.135 |  62.513 | 0:00:00.77 |\n",
            "| val   | 5.232 |  62.513 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 05/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 3.767 |  43.238 | 0:00:00.77 |\n",
            "| val   | 5.172 |  43.238 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 06/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 3.460 |  31.827 | 0:00:00.76 |\n",
            "| val   | 5.159 |  31.827 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 07/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 3.166 |  23.704 | 0:00:00.75 |\n",
            "| val   | 5.089 |  23.704 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 08/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 2.905 |  18.257 | 0:00:00.77 |\n",
            "| val   | 5.291 |  18.257 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 09/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 2.672 |  14.467 | 0:00:00.75 |\n",
            "| val   | 5.061 |  14.467 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|     EPOCH: 10/10 | not saving...     |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 2.445 |  11.535 | 0:00:00.76 |\n",
            "| val   | 5.262 |  11.535 |            |\n",
            "+-------+-------+---------+------------+\n",
            "TRAINING ENDS....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1_A2Nz5sKJu",
        "outputId": "c995584b-edd2-44ab-ef71-9fc5c565544b"
      },
      "source": [
        "model.load_state_dict(torch.load(MODEL_NAME))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "title = \"Model Evaluation Summary\"\n",
        "data_rows = [[\"Test\", f'{test_loss:.3f}', f'{math.exp(test_loss):7.3f}', \"\"]]\n",
        "\n",
        "tabulate_training([\"SET\", \"LOSS\", \"PPL\", \"ETA\"], data_rows, title)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+\n",
            "|   Model Evaluation Summary   |\n",
            "+------+-------+---------+-----+\n",
            "| SET  |  LOSS |     PPL | ETA |\n",
            "+------+-------+---------+-----+\n",
            "| Test | 4.702 | 110.218 |     |\n",
            "+------+-------+---------+-----+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J9H6zur4WU0"
      },
      "source": [
        "### Model inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPwMVJZ14Sxr"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    model.eval()\n",
        "    if isinstance(sentence, str):\n",
        "        # nlp = spacy.load('de_core_news_sm')\n",
        "        tokens = sentence.split(\" \")\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqGmZM3q4uRG",
        "outputId": "39bab62f-35a3-48c9-8324-9affdbe757b8"
      },
      "source": [
        "example_idx = 0\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['src']\n",
        "trg = vars(train_data.examples[example_idx])['trg']\n",
        "\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['i', \"'m\", 'glad', 'you', 'finally', 'made', 'it', 'back', '.']\n",
            "trg = ['ek', 'is', 'bly', 'jy', 'het', 'uiteindelik', 'terug', 'gekom.']\n",
            "predicted trg = ['ek', 'ek', 'is', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyPjW60N4ve_",
        "outputId": "6b68179a-62ae-4c40-9c86-1febb573bc0b"
      },
      "source": [
        "example_idx = 6\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['src']\n",
        "trg = vars(test_data.examples[example_idx])['trg']\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = ['you', 'can', 'do', 'whatever', 'you', 'want', 'to', 'do', ',', 'of', 'course', '.']\n",
            "trg = ['kan', 'jy', 'my', 'indruk?']\n",
            "predicted trg = ['jy', 'jy', 'jy', 'jy', 'jy', 'jy', 'jy', 'jy', 'jy', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xndxi8HR5QH_"
      },
      "source": [
        "Downloading the model name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "47bvlKVO43k6",
        "outputId": "cf689d2b-3968-490e-98af-de288d7c4bd2"
      },
      "source": [
        "files.download(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_098b1a4a-1098-400b-b399-6079c4943b86\", \"eng-af.pt\", 19670585)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qF2GsD85SM-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}