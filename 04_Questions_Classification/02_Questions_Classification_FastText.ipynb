{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Questions_Classification_FastText.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwFkL0ZK1L-X"
      },
      "source": [
        "### Questions Classification Custom dataset Fast Text.\n",
        "\n",
        "In this Notebook we are hoing to use the previous notebook as the base to our `FastText` model for predicting question classes. In the last notebook we used `RNN`, in this notebook we are going to use `FastText`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5bfB7PC1HRJ",
        "outputId": "5851904f-dcce-43b6-f814-d72a01e18e0b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpcZ-TG63VID"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qpE80WdY3TgV",
        "outputId": "fbb449b9-361a-4fb5-84fc-a1dfbdeb003d"
      },
      "source": [
        "import time\n",
        "from prettytable import PrettyTable\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch, os, random\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.9.0+cu102'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAkhI0Ns3wiU"
      },
      "source": [
        "### Setting up the seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwYV_hrz3sSB"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deteministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoTx8u2J344-"
      },
      "source": [
        "### Loading files.\n",
        "\n",
        "Now we have 3 files for three sets that were created which are:\n",
        "```\n",
        "train.csv\n",
        "test.csv\n",
        "val.csv\n",
        "```\n",
        "\n",
        "We are going to use torchtext to load these files.\n",
        "\n",
        "**Note:** In the previous notebooks we loaded these our files as json files. This time around we are going to load `csv` files instead. The procedure is the same.\n",
        "\n",
        "### Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdKKgohm34DD"
      },
      "source": [
        "files_path = '/content/drive/MyDrive/NLP Data/questions-classification/pytorch'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBBoZ8MqGsGR"
      },
      "source": [
        "train_path = 'train.csv'\n",
        "test_path = 'test.csv'\n",
        "val_path = 'val.csv'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3bh0FGhXv3u"
      },
      "source": [
        "### Fast Text.\n",
        "\n",
        "Accoding to the `TochText` paper we need to generate bigrams for each sentence.\n",
        "\n",
        "\n",
        "We are going to create a function called `generate_bigram()` that will generate bigrams for us. We will pass this function to the `Text` field as the preprocessing function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGQyOn9JYOVG",
        "outputId": "f9b827c5-374a-42ce-989f-2bbd27318b96"
      },
      "source": [
        "def generate_bigrams(x):\n",
        "  n_grams = set(zip(*[x[i: ] for i in range(2)]))\n",
        "  for n_gram in n_grams:\n",
        "      x.append(' '.join(n_gram))\n",
        "  return x\n",
        "generate_bigrams(['What', 'is', 'the', 'meaning', \"of\", \"OCR\", \"in\", \"python\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What',\n",
              " 'is',\n",
              " 'the',\n",
              " 'meaning',\n",
              " 'of',\n",
              " 'OCR',\n",
              " 'in',\n",
              " 'python',\n",
              " 'of OCR',\n",
              " 'meaning of',\n",
              " 'the meaning',\n",
              " 'is the',\n",
              " 'What is',\n",
              " 'in python',\n",
              " 'OCR in']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7YMbs8a43jD"
      },
      "source": [
        "### Creating the Fields.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_xUMByB5tGa"
      },
      "source": [
        "from torchtext.legacy import data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RaqW-b-4lJJ"
      },
      "source": [
        "TEXT = data.Field(\n",
        "   tokenize=\"spacy\",\n",
        "  preprocessing = generate_bigrams,\n",
        "  tokenizer_language = 'en_core_web_sm',\n",
        ")\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugU18S_7tAS"
      },
      "source": [
        "fields = {\n",
        "  \"Questions\": ('text', TEXT),\n",
        "  \"Category1\": ('label', LABEL)\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiNOBqFO8pyo"
      },
      "source": [
        "### Creating the dataset.\n",
        "\n",
        "We ar going to use the `TabularDataset.split()` to create the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAgiWOoh8mWO"
      },
      "source": [
        "train_data, val_data, test_data = data.TabularDataset.splits(\n",
        "   files_path,\n",
        "   train=train_path,\n",
        "   test= train_path,\n",
        "   validation= train_path,\n",
        "   format = \"csv\",\n",
        "   fields=fields,\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f4YEu-fQ1WK",
        "outputId": "31df2a8b-2a11-4fe7-f105-0579524829d3"
      },
      "source": [
        "len(train_data), len(test_data), len(val_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5179, 5179, 5179)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ1oWIQW9KWn",
        "outputId": "53266191-e817-4d5c-9852-cc63259bfb68"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['What', 'is', 'the', 'name', 'of', 'Miss', 'India', '1994', '?', 'India 1994', 'the name', 'Miss India', 'name of', 'is the', 'of Miss', 'What is', '1994 ?'], 'label': 'HUM'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t-0JC1U-l73"
      },
      "source": [
        "### Building the Vocabulary and Loading the `pretrained` word vectors.\n",
        "\n",
        "We are going to use the `glove.6B.100d` word vectors which was trained with 6 billion words and each word is a 100 dimesional vector.\n",
        "\n",
        "**Note** We should only build the vocabulary on the `train` dataset only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4p3m1_--WYU"
      },
      "source": [
        "MAX_VOCAB_SIZE = 100_000_000\n",
        "\n",
        "TEXT.build_vocab(\n",
        "    train_data,\n",
        "     max_size = MAX_VOCAB_SIZE,\n",
        "    vectors = \"glove.6B.100d\",\n",
        "    unk_init = torch.Tensor.normal_\n",
        ")\n",
        "LABEL.build_vocab(train_data)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFukx38W_aNv"
      },
      "source": [
        "### Device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYPGTIZ7_Zet",
        "outputId": "800cb9bf-8a2d-4a22-a5cd-81cce2cff559"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKkUJMz6K0WH",
        "outputId": "12c076e1-0ed5-4758-ab5a-203f27f5f005"
      },
      "source": [
        "LABEL.vocab.stoi"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None,\n",
              "            {'ABBR': 5, 'DESC': 2, 'ENTY': 0, 'HUM': 1, 'LOC': 4, 'NUM': 3})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaCMz4yZ_n5W"
      },
      "source": [
        "### Creating iterators.\n",
        "\n",
        "We are going to use our favorite iterator known as the `BucketIterator` to create iterators for all the sets that we have.\n",
        "\n",
        "For the `batch_size` this time around we want to test a huge batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPDrPFKQ_mf1"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    device = device,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spZX8zodA91F"
      },
      "source": [
        "### Creating the Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReThGRspA7uO"
      },
      "source": [
        "class QuestionsFastText(nn.Module):\n",
        "  def __init__(self, \n",
        "               vocab_size,\n",
        "               embedding_size,\n",
        "               output_dim,\n",
        "               pad_index,\n",
        "               ):\n",
        "    super(QuestionsFastText, self).__init__()\n",
        "    self.embedding = nn.Embedding(\n",
        "        vocab_size,\n",
        "        embedding_size,\n",
        "        padding_idx = pad_index\n",
        "    )\n",
        "    self.out = nn.Linear(\n",
        "        embedding_size,\n",
        "        out_features = output_dim\n",
        "    )\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text).permute(1 ,0, 2)\n",
        "    pooled = F.avg_pool2d(embedded,\n",
        "                         (embedded.shape[1], 1)\n",
        "                          ).squeeze(1)\n",
        "    return self.out(pooled)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2IVtv8EDhJd"
      },
      "source": [
        "### Creating the model instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbJdW058DgTl",
        "outputId": "1e7f1048-9903-4e19-cd9a-14a108fe347a"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM =  6\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] \n",
        "\n",
        "questions_model = QuestionsFastText(\n",
        "            INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            pad_index = PAD_IDX\n",
        "            ).to(device)\n",
        "questions_model"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuestionsFastText(\n",
              "  (embedding): Embedding(37259, 100, padding_idx=1)\n",
              "  (out): Linear(in_features=100, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acQD-B6zEE72"
      },
      "source": [
        "### Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQaztp4ID-HI",
        "outputId": "76a8174c-67f8-4a52-8ba0-8b0abfd563a5"
      },
      "source": [
        "\n",
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(questions_model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of paramaters: 3,726,506\n",
            "Total tainable parameters: 3,726,506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8gjXny7EUNb"
      },
      "source": [
        "### Loading pretrained vextors to the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULe__PiKEQS8"
      },
      "source": [
        "pretrained_embeddings  = TEXT.vocab.vectors"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeXa9ycREfuV",
        "outputId": "6c8d6861-4512-452a-d762-d4f59d1d50e8"
      },
      "source": [
        "questions_model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.1233,  0.3499,  0.6173],\n",
              "        [ 0.7262,  0.0912, -0.3891,  ...,  0.0821,  0.4440, -0.7240],\n",
              "        [ 0.1638,  0.6046,  1.0789,  ..., -0.3140,  0.1844,  0.3624],\n",
              "        ...,\n",
              "        [ 1.4463, -1.1674, -0.2216,  ..., -1.6196, -0.6633,  1.1526],\n",
              "        [-0.8444, -0.5054,  0.2824,  ...,  1.2317, -0.8442,  0.2483],\n",
              "        [ 1.1007,  0.2795, -0.3990,  ..., -0.7641,  0.7015,  0.8293]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q27hKnrpEoKF"
      },
      "source": [
        "### Zeroing the `<pad>` and `<unk>` tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_qvO2teEmvh",
        "outputId": "e4f25ad5-f0dd-4aeb-e982-7556412828ff"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token] or TEXT.vocab.stoi[\"<unk>\"]\n",
        "questions_model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "questions_model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "questions_model.embedding.weight.data"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.1638,  0.6046,  1.0789,  ..., -0.3140,  0.1844,  0.3624],\n",
              "        ...,\n",
              "        [ 1.4463, -1.1674, -0.2216,  ..., -1.6196, -0.6633,  1.1526],\n",
              "        [-0.8444, -0.5054,  0.2824,  ...,  1.2317, -0.8442,  0.2483],\n",
              "        [ 1.1007,  0.2795, -0.3990,  ..., -0.7641,  0.7015,  0.8293]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm2RklTLE-Dv"
      },
      "source": [
        "### Loss and optimizer.\n",
        "We are going to use the Adam as our optimizer with the default leaning rate. We are also going to use `CrossEntropyLoss()` as our loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7UCyAlYE1nA"
      },
      "source": [
        "optimizer = torch.optim.Adam(questions_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi2tk-kSFTVq"
      },
      "source": [
        "### Accuracy function.\n",
        "We are going to create the `categorical_accuracy()` function that will calculate the categorical accuracy for predicted labels and actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRCfQZvmFPBS"
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "  top_pred = preds.argmax(1, keepdim = True)\n",
        "  correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "  return correct.float() / y.shape[0]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gf_nyXVFvOG"
      },
      "source": [
        "### Training and Evaluation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80QEfQeaFuVZ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss ,epoch_acc = 0, 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text = batch.text\n",
        "        predictions = model(text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss , epoch_acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.text\n",
        "            predictions = model(text)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdtkgFFJG1WS"
      },
      "source": [
        "### Training loop.\n",
        "We are going to create helper functions that will help us to visualize our training.\n",
        "\n",
        "1. Time to string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMH6iA1AG0tj"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp5OjGiPHR6h"
      },
      "source": [
        "2. tabulate training epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtCTm84HHQb5"
      },
      "source": [
        "def visualize_training(start, end, train_loss, train_accuracy, val_loss, val_accuracy, title):\n",
        "  data = [\n",
        "       [\"Training\", f'{train_loss:.3f}', f'{train_accuracy:.3f}', f\"{hms_string(end - start)}\" ],\n",
        "       [\"Validation\", f'{val_loss:.3f}', f'{val_accuracy:.3f}', \"\" ],       \n",
        "  ]\n",
        "  table = PrettyTable([\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"])\n",
        "  table.align[\"CATEGORY\"] = 'l'\n",
        "  table.align[\"LOSS\"] = 'r'\n",
        "  table.align[\"ACCURACY\"] = 'r'\n",
        "  table.align[\"ETA\"] = 'r'\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcu_WMc2HXqb",
        "outputId": "614369fc-204f-4a73-ce95-ba844a310ae3"
      },
      "source": [
        "N_EPOCHS = 100\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss, train_acc = train(questions_model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(questions_model, val_iter, criterion)\n",
        "    title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} {'saving best model...' if valid_loss < best_valid_loss else 'not saving...'}\"\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(questions_model.state_dict(), 'best-model.pt')\n",
        "    end = time.time()\n",
        "    visualize_training(start, end, train_loss, train_acc, valid_loss, valid_acc, title)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------+\n",
            "|     EPOCH: 01/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.751 |    0.249 | 0:00:00.30 |\n",
            "| Validation | 1.641 |    0.346 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 02/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.683 |    0.298 | 0:00:00.44 |\n",
            "| Validation | 1.529 |    0.433 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 03/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.620 |    0.383 | 0:00:00.42 |\n",
            "| Validation | 1.408 |    0.516 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 04/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.553 |    0.491 | 0:00:00.41 |\n",
            "| Validation | 1.269 |    0.606 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 05/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.472 |    0.580 | 0:00:00.41 |\n",
            "| Validation | 1.114 |    0.669 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 06/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.378 |    0.670 | 0:00:00.41 |\n",
            "| Validation | 0.952 |    0.730 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 07/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.266 |    0.737 | 0:00:00.41 |\n",
            "| Validation | 0.798 |    0.782 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 08/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.158 |    0.793 | 0:00:00.42 |\n",
            "| Validation | 0.658 |    0.823 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 09/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.023 |    0.830 | 0:00:00.41 |\n",
            "| Validation | 0.540 |    0.854 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 10/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.922 |    0.858 | 0:00:00.41 |\n",
            "| Validation | 0.446 |    0.880 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 11/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.802 |    0.886 | 0:00:00.41 |\n",
            "| Validation | 0.368 |    0.903 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 12/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.723 |    0.903 | 0:00:00.41 |\n",
            "| Validation | 0.310 |    0.920 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 13/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.623 |    0.921 | 0:00:00.29 |\n",
            "| Validation | 0.261 |    0.932 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 14/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.559 |    0.933 | 0:00:00.29 |\n",
            "| Validation | 0.222 |    0.942 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 15/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.484 |    0.941 | 0:00:00.30 |\n",
            "| Validation | 0.188 |    0.951 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 16/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.427 |    0.950 | 0:00:00.45 |\n",
            "| Validation | 0.162 |    0.958 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 17/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.372 |    0.955 | 0:00:00.41 |\n",
            "| Validation | 0.139 |    0.964 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 18/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.336 |    0.963 | 0:00:00.41 |\n",
            "| Validation | 0.121 |    0.970 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 19/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.295 |    0.967 | 0:00:00.41 |\n",
            "| Validation | 0.105 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 20/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.266 |    0.972 | 0:00:00.41 |\n",
            "| Validation | 0.092 |    0.979 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 21/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.243 |    0.977 | 0:00:00.42 |\n",
            "| Validation | 0.082 |    0.981 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 22/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.219 |    0.980 | 0:00:00.41 |\n",
            "| Validation | 0.072 |    0.984 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 23/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.198 |    0.983 | 0:00:00.41 |\n",
            "| Validation | 0.066 |    0.985 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 24/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.175 |    0.985 | 0:00:00.41 |\n",
            "| Validation | 0.059 |    0.986 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 25/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.162 |    0.987 | 0:00:00.41 |\n",
            "| Validation | 0.054 |    0.988 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 26/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.148 |    0.988 | 0:00:00.29 |\n",
            "| Validation | 0.049 |    0.989 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 27/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.136 |    0.989 | 0:00:00.29 |\n",
            "| Validation | 0.044 |    0.990 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 28/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.126 |    0.990 | 0:00:00.31 |\n",
            "| Validation | 0.041 |    0.991 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 29/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.116 |    0.991 | 0:00:00.45 |\n",
            "| Validation | 0.038 |    0.992 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 30/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.108 |    0.991 | 0:00:00.41 |\n",
            "| Validation | 0.035 |    0.993 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 31/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.095 |    0.993 | 0:00:00.42 |\n",
            "| Validation | 0.032 |    0.993 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 32/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.090 |    0.993 | 0:00:00.40 |\n",
            "| Validation | 0.030 |    0.994 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 33/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.087 |    0.993 | 0:00:00.41 |\n",
            "| Validation | 0.028 |    0.994 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 34/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.078 |    0.994 | 0:00:00.41 |\n",
            "| Validation | 0.025 |    0.994 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 35/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.073 |    0.994 | 0:00:00.41 |\n",
            "| Validation | 0.024 |    0.995 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 36/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.067 |    0.995 | 0:00:00.41 |\n",
            "| Validation | 0.022 |    0.995 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 37/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.066 |    0.995 | 0:00:00.41 |\n",
            "| Validation | 0.021 |    0.996 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 38/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.057 |    0.995 | 0:00:00.42 |\n",
            "| Validation | 0.019 |    0.996 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 39/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.054 |    0.996 | 0:00:00.28 |\n",
            "| Validation | 0.018 |    0.997 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 40/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.054 |    0.996 | 0:00:00.29 |\n",
            "| Validation | 0.017 |    0.997 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 41/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.047 |    0.996 | 0:00:00.31 |\n",
            "| Validation | 0.015 |    0.997 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 42/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.048 |    0.997 | 0:00:00.45 |\n",
            "| Validation | 0.014 |    0.997 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 43/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.044 |    0.997 | 0:00:00.41 |\n",
            "| Validation | 0.013 |    0.997 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 44/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.041 |    0.997 | 0:00:00.41 |\n",
            "| Validation | 0.012 |    0.997 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 45/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.039 |    0.997 | 0:00:00.41 |\n",
            "| Validation | 0.012 |    0.997 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 46/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.038 |    0.997 | 0:00:00.41 |\n",
            "| Validation | 0.011 |    0.997 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 47/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.037 |    0.997 | 0:00:00.42 |\n",
            "| Validation | 0.010 |    0.997 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 48/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.034 |    0.997 | 0:00:00.41 |\n",
            "| Validation | 0.009 |    0.998 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 49/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.031 |    0.997 | 0:00:00.41 |\n",
            "| Validation | 0.008 |    0.998 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 50/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.030 |    0.997 | 0:00:00.41 |\n",
            "| Validation | 0.007 |    0.998 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 51/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.029 |    0.997 | 0:00:00.41 |\n",
            "| Validation | 0.007 |    0.998 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 52/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.028 |    0.998 | 0:00:00.29 |\n",
            "| Validation | 0.006 |    0.998 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 53/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.026 |    0.998 | 0:00:00.29 |\n",
            "| Validation | 0.005 |    0.998 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 54/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.025 |    0.998 | 0:00:00.29 |\n",
            "| Validation | 0.005 |    0.998 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 55/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.023 |    0.998 | 0:00:00.31 |\n",
            "| Validation | 0.004 |    0.998 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 56/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.022 |    0.998 | 0:00:00.44 |\n",
            "| Validation | 0.004 |    0.998 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 57/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.021 |    0.997 | 0:00:00.41 |\n",
            "| Validation | 0.003 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 58/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.020 |    0.998 | 0:00:00.41 |\n",
            "| Validation | 0.003 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 59/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.021 |    0.998 | 0:00:00.40 |\n",
            "| Validation | 0.003 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 60/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.019 |    0.998 | 0:00:00.41 |\n",
            "| Validation | 0.002 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 61/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.018 |    0.998 | 0:00:00.41 |\n",
            "| Validation | 0.002 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 62/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.017 |    0.999 | 0:00:00.41 |\n",
            "| Validation | 0.002 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 63/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.017 |    0.999 | 0:00:00.41 |\n",
            "| Validation | 0.001 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 64/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.016 |    0.999 | 0:00:00.42 |\n",
            "| Validation | 0.001 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 65/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.015 |    0.999 | 0:00:00.41 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 66/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.015 |    0.999 | 0:00:00.31 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 67/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.015 |    0.999 | 0:00:00.30 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 68/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.013 |    1.000 | 0:00:00.32 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 69/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.013 |    1.000 | 0:00:00.45 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 70/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.013 |    1.000 | 0:00:00.38 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 71/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.012 |    1.000 | 0:00:00.43 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 72/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.011 |    1.000 | 0:00:00.41 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 73/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.011 |    1.000 | 0:00:00.42 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 74/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.010 |    1.000 | 0:00:00.41 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 75/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.009 |    1.000 | 0:00:00.42 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 76/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.010 |    1.000 | 0:00:00.41 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 77/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.010 |    1.000 | 0:00:00.40 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 78/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.009 |    1.000 | 0:00:00.42 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 79/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.009 |    1.000 | 0:00:00.31 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 80/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.009 |    1.000 | 0:00:00.31 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 81/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.008 |    1.000 | 0:00:00.32 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 82/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.008 |    1.000 | 0:00:00.44 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 83/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.008 |    1.000 | 0:00:00.42 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 84/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.007 |    1.000 | 0:00:00.42 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 85/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.007 |    1.000 | 0:00:00.32 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 86/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.007 |    1.000 | 0:00:00.44 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 87/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.007 |    1.000 | 0:00:00.41 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 88/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.007 |    1.000 | 0:00:00.42 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 89/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.006 |    1.000 | 0:00:00.41 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 90/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.006 |    1.000 | 0:00:00.41 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 91/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.006 |    1.000 | 0:00:00.41 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 92/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.006 |    1.000 | 0:00:00.42 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 93/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.006 |    1.000 | 0:00:00.32 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 94/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.006 |    1.000 | 0:00:00.31 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 95/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.006 |    1.000 | 0:00:00.44 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 96/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.005 |    1.000 | 0:00:00.42 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 97/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.005 |    1.000 | 0:00:00.41 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 98/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.005 |    1.000 | 0:00:00.39 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 99/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.004 |    1.000 | 0:00:00.43 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 100/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.004 |    1.000 | 0:00:00.42 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNkikbDIB2z"
      },
      "source": [
        "### Model Evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8fWTBruHw1p",
        "outputId": "8f87dee0-9486-42e6-936d-efb232efedbd"
      },
      "source": [
        "questions_model.load_state_dict(torch.load('best-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(questions_model, test_iter, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.000 | Test Acc: 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4zEBLYsLki5"
      },
      "source": [
        "### Model Inference.\n",
        "\n",
        "We are now ready to make predictions with our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyNLifHaJBKS"
      },
      "source": [
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clNBiJ9NPkRJ",
        "outputId": "ec9b4524-f53e-4bf1-dfed-2809e5858285"
      },
      "source": [
        "reversed_labels = dict([(v, k) for (k, v) in LABEL.vocab.stoi.items()])\n",
        "reversed_labels"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'ENTY', 1: 'HUM', 2: 'DESC', 3: 'NUM', 4: 'LOC', 5: 'ABBR'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9A6ZGTILzWD"
      },
      "source": [
        "def tabulate(column_names, data, title=\"QUESTIONS PREDICTIONS TABLE\"):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.align[column_names[0]] = \"l\"\n",
        "  table.align[column_names[1]] = \"l\"\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "\n",
        "def predict_question_type(model, sentence, min_len = 5, actual_class=0):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "     \n",
        "      if len(tokenized) < min_len:\n",
        "          tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "      indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "      tensor = torch.LongTensor(indexed).to(device).unsqueeze(1)\n",
        "      probabilities = model(tensor)\n",
        "      prediction = torch.argmax(probabilities, dim=1)\n",
        "      prediction = prediction.item()\n",
        "    \n",
        "      table_headers =[\"KEY\", \"VALUE\"]\n",
        "      table_data = [\n",
        "          [\"PREDICTED CLASS\",  prediction],\n",
        "          [\"ACTUAL CLASS\", actual_class],\n",
        "          [\"PREDICTED CLASS NAME\",  reversed_labels[prediction]],    \n",
        "      ]\n",
        "      tabulate(table_headers, table_data)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm5h2CDLUECt",
        "outputId": "0baefcd3-e844-4478-da72-81dd8521c746"
      },
      "source": [
        "reversed_labels"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'ENTY', 1: 'HUM', 2: 'DESC', 3: 'NUM', 4: 'LOC', 5: 'ABBR'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W93zzSlQMO4p"
      },
      "source": [
        "### Location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcuHlaPwML4Y",
        "outputId": "55848a95-55bd-438d-8a3a-824fa4fd7f54"
      },
      "source": [
        "predict_question_type(questions_model, \"What are the largest libraries in the US ?\", actual_class=4)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 4     |\n",
            "| ACTUAL CLASS         | 4     |\n",
            "| PREDICTED CLASS NAME | LOC   |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5Eqjo0MMP8L"
      },
      "source": [
        "### Human"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnhFchDiMQQn",
        "outputId": "d5288e4a-9b9e-42b8-94c4-75c200f72556"
      },
      "source": [
        "predict_question_type(questions_model, \"Who is John Macarthur , 1767-1834 ?\", actual_class=1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 1     |\n",
            "| ACTUAL CLASS         | 1     |\n",
            "| PREDICTED CLASS NAME | HUM   |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WvswKe5MQ3D"
      },
      "source": [
        "### DESCRIPTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3jeZM6xMRVy",
        "outputId": "4755a610-6c85-43ae-fdb9-7c1248e91377"
      },
      "source": [
        "predict_question_type(questions_model, \"What is the root of all evil ? \", actual_class=2)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 2     |\n",
            "| ACTUAL CLASS         | 2     |\n",
            "| PREDICTED CLASS NAME | DESC  |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeGjIT9NMRxA"
      },
      "source": [
        "### Numeric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GxH8LKiMSOH",
        "outputId": "46a20193-23ad-4d04-fd2c-3a1e54057651"
      },
      "source": [
        "predict_question_type(questions_model, \"How many watts make a kilowatt ?\", actual_class=3)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 3     |\n",
            "| ACTUAL CLASS         | 3     |\n",
            "| PREDICTED CLASS NAME | NUM   |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-7beS0jPLW7"
      },
      "source": [
        "### ENTITY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvQq7ul9PHFI",
        "outputId": "0eacae3f-2a44-4009-ebe7-cc0ff2c45c90"
      },
      "source": [
        "\n",
        "predict_question_type(questions_model, \"What films featured the character Popeye Doyle ?\", actual_class=0)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 0     |\n",
            "| ACTUAL CLASS         | 0     |\n",
            "| PREDICTED CLASS NAME | ENTY  |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ0cQrfFQ9QI"
      },
      "source": [
        "### ABBREVIATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvzy3XHRQZQQ",
        "outputId": "f708c5de-0ce9-4f23-815f-58c910965e8e"
      },
      "source": [
        "predict_question_type(questions_model, \"What does NECROSIS mean ?\", actual_class=5)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 2     |\n",
            "| ACTUAL CLASS         | 5     |\n",
            "| PREDICTED CLASS NAME | DESC  |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sa3_lq4VHSn"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "We were able to create our model and get a loss of `0` and `100%` accuracy on the validation and test data.\n",
        "\n",
        "### Next Step\n",
        "* In the next Notebook we are going to use `CNN` to perform sentiment analyisis on this dataset."
      ]
    }
  ]
}