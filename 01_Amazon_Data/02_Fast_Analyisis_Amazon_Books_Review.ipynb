{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Fast_Analyisis_Amazon_Books_Review.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6SS2euwauZR"
      },
      "source": [
        "### Amazon Data - Sentiment Analyisis\n",
        "\n",
        "In this notebook we are going to use our own datset, load it using the `torchtext` predict positive or negative sentiments. We have two files which are:\n",
        "\n",
        "```\n",
        "Books_small_10000.json -> training\n",
        "Books_small.json -> testing\n",
        "```\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbtouX3Qce7L"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import en_core_web_sm\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO001mo-c5sm"
      },
      "source": [
        "### Device Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64XFKQXYce-b"
      },
      "source": [
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.deteministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrMhTAUvd65Q"
      },
      "source": [
        "### Data Prep.\n",
        "\n",
        "The json files has the following data in them:\n",
        "```json\n",
        "{\"reviewerID\": \"A1E5ZR1Z4OQJG\", \"asin\": \"1495329321\", \"reviewerName\": \"Pure Jonel \\\"Pure Jonel\\\"\", \"helpful\": [0, 0], \"reviewText\": \"Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\", \"overall\": 4.0, \"summary\": \"An amazing first novel\", \"unixReviewTime\": 1396137600, \"reviewTime\": \"03 30, 2014\"}\n",
        "\n",
        "```\n",
        "Here we are interested in two things:\n",
        "\n",
        "\"reviewText\" -> thats the review\n",
        "\n",
        "\"overall\" -> that's the sentiment we will be working with assuming that greater than 2 is a positive review.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT_oyr1he3hn"
      },
      "source": [
        "### Preparing the `Fields`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpkLX0W0gDzR"
      },
      "source": [
        "get_sentiment = lambda x: 1 if x >=3 else 0\n",
        "# dtype = torch.float"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUa0UiJyMo_w",
        "outputId": "60a70be5-81cc-4da5-8bba-7ff0f97fd06a"
      },
      "source": [
        "\n",
        "def generate_bigrams(x):\n",
        "  n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
        "  for n_gram in n_grams:\n",
        "      x.append(' '.join(n_gram))\n",
        "  return x\n",
        "generate_bigrams(['This', 'film', 'is', 'terrible'])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'film', 'is', 'terrible', 'This film', 'film is', 'is terrible']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fck6PIdcfBL"
      },
      "source": [
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm',\n",
        "                  preprocessing=generate_bigrams\n",
        "                  )\n",
        "LABEL = data.LabelField(preprocessing=get_sentiment, dtype = torch.float)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHW-bUelcfDz"
      },
      "source": [
        "fields = {\n",
        "    'reviewText': ('review', TEXT),\n",
        "    'overall': ('sentiment', LABEL)\n",
        "}"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d59-h0Tjh0i5"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXmEmynRcfGz"
      },
      "source": [
        "train_data, test_data = data.TabularDataset.splits(\n",
        "    path=\"/content/\",\n",
        "    train=\"Books_small_10000.json\",\n",
        "    test=\"Books_small.json\",\n",
        "    format=\"json\",\n",
        "    fields=fields\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEpWC3DXcfM7",
        "outputId": "46836ff4-e25c-4381-8c2b-27dfa4c597d7"
      },
      "source": [
        "print(vars(train_data[0]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'review': ['I', 'bought', 'both', 'boxed', 'sets', ',', 'books', '1', '-', '5', '.', ' ', 'Really', 'a', 'great', 'series', '!', ' ', 'Start', 'book', '1', 'three', 'weeks', 'ago', 'and', 'just', 'finished', 'book', '5', '.', ' ', 'Sloane', 'Monroe', 'is', 'a', 'great', 'character', 'and', 'being', 'able', 'to', 'follow', 'her', 'through', 'both', 'private', 'life', 'and', 'her', 'PI', 'life', 'gets', 'a', 'reader', 'very', 'involved', '!', ' ', 'Although', 'clues', 'may', 'be', 'right', 'in', 'front', 'of', 'the', 'reader', ',', 'there', 'are', 'twists', 'and', 'turns', 'that', 'keep', 'one', 'guessing', 'until', 'the', 'last', 'page', '!', ' ', 'These', 'are', 'books', 'you', 'wo', \"n't\", 'be', 'disappointed', 'with', '.', 'are books', 'I bought', 'a reader', '  Really', '  Although', ', books', 'series !', 'both boxed', 'sets ,', 'being able', 'book 1', 'Monroe is', 'to follow', \"wo n't\", '  Start', 'book 5', 'you wo', 'These are', 'great series', 'her PI', 'books you', '- 5', 'twists and', 'of the', '.  ', 'right in', 'guessing until', 'Start book', 'PI life', 'finished book', 'in front', 'through both', 'follow her', 'involved !', 'gets a', 'last page', 'that keep', 'character and', 'may be', 'books 1', 'and her', '  These', '  Sloane', 'life gets', 'one guessing', 'and just', 'page !', 'weeks ago', 'front of', \"n't be\", 'turns that', 'are twists', 'be right', 'until the', '!  ', '1 -', 'reader very', 'the last', 'keep one', 'is a', '5 .', 'three weeks', 'reader ,', 'just finished', ', there', 'Although clues', 'great character', 'and turns', 'both private', 'be disappointed', 'bought both', 'her through', 'able to', '1 three', 'life and', 'the reader', 'clues may', 'with .', 'very involved', 'Really a', 'Sloane Monroe', 'and being', 'there are', 'ago and', 'private life', 'a great', 'boxed sets', 'disappointed with'], 'sentiment': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX5C56UxJtW3",
        "outputId": "8af8002c-1063-4eab-9edc-ec7e01c48b5d"
      },
      "source": [
        "from collections import Counter\n",
        "counter = Counter()\n",
        "\n",
        "for i in train_data:\n",
        "  counter[i.sentiment] += 1\n",
        "\n",
        "counter"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 644, 1: 9356})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj1b_eH4KDri"
      },
      "source": [
        "We have `466` negative and `6534` positive reviews in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ka7dFwjHpv"
      },
      "source": [
        "### Checking the data sizes for each sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht5bL08VcfQL",
        "outputId": "3021bf94-fddd-467c-d4fb-17753f1325ec"
      },
      "source": [
        "print(f\"TRAINING EXAMPLES: \\t {len(train_data)}\\nTEST EXAMPLES: \\t {len(test_data)}\\nTOTAL EXAMPLES: \\t {len(train_data) + len(test_data)}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING EXAMPLES: \t 10000\n",
            "TEST EXAMPLES: \t 1000\n",
            "TOTAL EXAMPLES: \t 11000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kXlMXFOjPum"
      },
      "source": [
        "### Creating A Validation data from the train_data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K26Q-gNcfTE"
      },
      "source": [
        "train_data, validation_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMsuVgdwcfV8",
        "outputId": "a60f24bf-f98c-4ce1-f6ee-507607758ca8"
      },
      "source": [
        "print(f\"TRAINING EXAMPLES: \\t {len(train_data)}\\nVALIDATION EXAMPLES: \\t {len(validation_data)}\\nTEST EXAMPLES: \\t {len(test_data)}\\nTOTAL EXAMPLES: \\t {len(train_data) + len(test_data) + len(validation_data)}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING EXAMPLES: \t 7000\n",
            "VALIDATION EXAMPLES: \t 3000\n",
            "TEST EXAMPLES: \t 1000\n",
            "TOTAL EXAMPLES: \t 11000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdRfrVESj1Qx"
      },
      "source": [
        "### Loading pretrained word Embedings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jfgi21_cfZL"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(\n",
        "    train_data,\n",
        "    max_size = MAX_VOCAB_SIZE,\n",
        "    vectors = \"glove.6B.100d\",\n",
        "    unk_init = torch.Tensor.normal_\n",
        ")\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrxkNOBWkRYu"
      },
      "source": [
        "### Creating Iterators - `Bucket Iterator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRah5w02kQHj"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, validation_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, validation_data, test_data),\n",
        "    device = device,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.review),\n",
        ")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K0RRtuek3T-"
      },
      "source": [
        "### Creating a Model\n",
        "In this notebook we are going to use a `bidirectional` LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE6-YqQpk3Dm"
      },
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xnkpV_-kzOB"
      },
      "source": [
        "class AmazonFastText(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
        "    super(AmazonFastText, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "    self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "\n",
        "  def forward(self, text):\n",
        "    #text = [sent len, batch size]\n",
        "    embedded = self.embedding(text)\n",
        "    #embedded = [sent len, batch size, emb dim]\n",
        "    embedded = embedded.permute(1, 0, 2)\n",
        "    #embedded = [batch size, sent len, emb dim]\n",
        "    pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
        "    #pooled = [batch size, embedding_dim]\n",
        "    return self.fc(pooled)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHwFdkMsnSnW"
      },
      "source": [
        "### Creating a model instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7oXh35UkzK9",
        "outputId": "38e6ad5b-f7cf-4683-f1ca-af8926db1676"
      },
      "source": [
        "\n",
        "INPUT_DIM = len(TEXT.vocab) # # 25002\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # 0\n",
        "amazon_model = AmazonFastText(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            PAD_IDX)\n",
        "amazon_model"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AmazonFastText(\n",
              "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
              "  (fc): Linear(in_features=100, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW_XcObanet-"
      },
      "source": [
        "### Counting number of trainable parameters in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9ee96uakzHg",
        "outputId": "6f09dadd-692d-4026-82ca-e645e433394f"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum([i.numel() for i in model.parameters() if i.requires_grad])\n",
        "\n",
        "print(f'The model has {count_trainable_params(amazon_model):,} trainable parameters')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,500,301 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYQEJMkokzEg"
      },
      "source": [
        "#### Loading pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Mlsrd7oJtn"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbdF-1l6kzBO",
        "outputId": "b8d39b04-4567-44df-9b9d-8db308d4025a"
      },
      "source": [
        "amazon_model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5072,  0.3010,  0.1951,  ..., -2.3340,  0.4329,  0.7085],\n",
              "        [-0.8397,  0.0715, -0.5994,  ...,  0.2574, -1.7856,  1.1859],\n",
              "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
              "        ...,\n",
              "        [ 1.0017,  1.7874,  1.9818,  ..., -0.2203,  0.6225,  0.0553],\n",
              "        [ 0.3806, -0.6303,  1.6362,  ...,  1.1622,  1.1987,  0.0910],\n",
              "        [ 1.3815,  1.1543,  1.3951,  ...,  1.7253,  0.4228,  1.5155]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "124pKMgaoc09"
      },
      "source": [
        "### Zeroing the <pad> and <unk> tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1WRrLudky92",
        "outputId": "c0e663da-5d88-4dfa-9411-e261e204d9ed"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token] or TEXT.vocab.stoi[\"<unk>\"]\n",
        "amazon_model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "amazon_model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "print(amazon_model.embedding.weight.data)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
            "        ...,\n",
            "        [ 1.0017,  1.7874,  1.9818,  ..., -0.2203,  0.6225,  0.0553],\n",
            "        [ 0.3806, -0.6303,  1.6362,  ...,  1.1622,  1.1987,  0.0910],\n",
            "        [ 1.3815,  1.1543,  1.3951,  ...,  1.7253,  0.4228,  1.5155]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMGyQ5pyooSa"
      },
      "source": [
        "### Trainning the Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLnToh2ZooWG"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(amazon_model.parameters())"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5D6CNrHphNx"
      },
      "source": [
        "### Criterion and amazon_model to the Device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq4Qm_x7ooZv"
      },
      "source": [
        "amazon_model = amazon_model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_DaI4fepwew"
      },
      "source": [
        "### The Binary Accuracy Function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrHG4OjWoofv"
      },
      "source": [
        "def binary_accuracy(y_preds, y_true):\n",
        "  #round predictions to the closest integer\n",
        "  rounded_preds = torch.round(torch.sigmoid(y_preds))\n",
        "  correct = (rounded_preds == y_true).float() #convert into float for division \n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuQMnQJWp7Qi"
      },
      "source": [
        "### Trainning and evaluation Functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWuc6c-zoojB"
      },
      "source": [
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text = batch.review\n",
        "        predictions = model(text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.sentiment)\n",
        "        acc = binary_accuracy(predictions, batch.sentiment)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.review\n",
        "            predictions = model(text).squeeze(1)\n",
        "            loss = criterion(predictions, batch.sentiment)\n",
        "            acc = binary_accuracy(predictions, batch.sentiment)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhvBTP5OqKL-"
      },
      "source": [
        "We'll also create a function to tell us how long an epoch takes to compare training times between models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WhT7wkToonV"
      },
      "source": [
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LEZP7cWqPwG"
      },
      "source": [
        "### Trainning Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zSJTbCEoopE",
        "outputId": "a05fead1-7431-4a7f-e329-5d7c305e955b"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(amazon_model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(amazon_model, validation_iterator, criterion)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(amazon_model.state_dict(), 'best-model.pt')\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 3s\n",
            "\tTrain Loss: 0.642 | Train Acc: 72.38%\n",
            "\t Val. Loss: 0.250 |  Val. Acc: 94.08%\n",
            "Epoch: 02 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.507 | Train Acc: 93.36%\n",
            "\t Val. Loss: 0.312 |  Val. Acc: 94.08%\n",
            "Epoch: 03 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.424 | Train Acc: 93.33%\n",
            "\t Val. Loss: 0.471 |  Val. Acc: 94.08%\n",
            "Epoch: 04 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.388 | Train Acc: 93.36%\n",
            "\t Val. Loss: 0.598 |  Val. Acc: 94.08%\n",
            "Epoch: 05 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.369 | Train Acc: 93.36%\n",
            "\t Val. Loss: 0.656 |  Val. Acc: 94.08%\n",
            "Epoch: 06 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.358 | Train Acc: 93.31%\n",
            "\t Val. Loss: 0.682 |  Val. Acc: 94.08%\n",
            "Epoch: 07 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.337 | Train Acc: 93.38%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 94.08%\n",
            "Epoch: 08 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.334 | Train Acc: 93.33%\n",
            "\t Val. Loss: 0.702 |  Val. Acc: 94.08%\n",
            "Epoch: 09 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.322 | Train Acc: 93.33%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 94.08%\n",
            "Epoch: 10 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.307 | Train Acc: 93.31%\n",
            "\t Val. Loss: 0.672 |  Val. Acc: 94.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm6C3rlIFJn3"
      },
      "source": [
        "### Evaluating the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0xDEYz1oovX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f694a915-0f36-442b-f5e5-6191df4f1ff0"
      },
      "source": [
        "amazon_model.load_state_dict(torch.load('best-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(amazon_model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.221 | Test Acc: 92.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRd4xDQwFubf"
      },
      "source": [
        "### Model Inference - Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reP3lwspooz7"
      },
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "sentiments = [\"NEG\", \"POS\"]\n",
        "def predict_sentiment(model, sent):\n",
        "  model.eval()\n",
        "  tokenized = [tok.text for tok in nlp.tokenizer(sent)]\n",
        "  indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "  length = [len(indexed)]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(1)\n",
        "  length_tensor = torch.LongTensor(length)\n",
        "  prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "\n",
        "  predicted_class = round(prediction.item())\n",
        "  confidence = prediction.item() if prediction.item() >= .5 else 1 - prediction.item()\n",
        "  print(f'PREDICTED CLASS:\\t{predicted_class}\\nCONFIDENCE:\\t\\t{confidence * 100:.2f}%\\nSENTIMENT:\\t\\t{sentiments[predicted_class]}')\n",
        "  return prediction.item()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVEc71MrIjZQ"
      },
      "source": [
        "### Negative review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAzsMzkCoo3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c130f08-9522-48a5-84c1-d8f7b8aaf129"
      },
      "source": [
        "predict_sentiment(amazon_model, \"This book is terrible\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTED CLASS:\t0\n",
            "CONFIDENCE:\t\t58.68%\n",
            "SENTIMENT:\t\tNEG\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.41323035955429077"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CKI6umcImtx"
      },
      "source": [
        "### Positive review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEPwGxu0kyp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8eb9110-680a-4f75-b78b-340bad32729f"
      },
      "source": [
        "predict_sentiment(amazon_model, \"Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTED CLASS:\t0\n",
            "CONFIDENCE:\t\t99.97%\n",
            "SENTIMENT:\t\tNEG\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0002923606662079692"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IexvtkKvItpl"
      },
      "source": [
        ""
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}