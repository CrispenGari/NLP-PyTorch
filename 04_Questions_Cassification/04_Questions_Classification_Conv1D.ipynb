{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Questions_Classification_Conv1D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwFkL0ZK1L-X"
      },
      "source": [
        "### Questions Classification Custom dataset Conv1D.\n",
        "\n",
        "In the previous notebook we used ``Conv2D`` layers in our model to classify question classes. This notebook is almost the same as the previous model We are only going to modify the model. Insead of using the `Conv2D` this time around we are going for the `Conv1D` model.\n",
        "\n",
        "\n",
        "### First let's mount our drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5bfB7PC1HRJ",
        "outputId": "d29f5687-26e2-4fef-a9a0-d021726ea5b1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpcZ-TG63VID"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qpE80WdY3TgV",
        "outputId": "7f31bd05-4afe-48d9-d2ec-b0a57899c37b"
      },
      "source": [
        "import time\n",
        "from prettytable import PrettyTable\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch, os, random\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.9.0+cu102'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAkhI0Ns3wiU"
      },
      "source": [
        "### Setting up the seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwYV_hrz3sSB"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deteministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoTx8u2J344-"
      },
      "source": [
        "### Loading files.\n",
        "\n",
        "Now we have 3 files for three sets that were created which are:\n",
        "```\n",
        "train.csv\n",
        "test.csv\n",
        "val.csv\n",
        "```\n",
        "\n",
        "We are going to use torchtext to load these files.\n",
        "\n",
        "**Note:** In the previous notebooks we loaded these our files as json files. This time around we are going to load `csv` files instead. The procedure is the same.\n",
        "\n",
        "### Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdKKgohm34DD"
      },
      "source": [
        "files_path = '/content/drive/MyDrive/NLP Data/questions-classification/pytorch'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBBoZ8MqGsGR"
      },
      "source": [
        "train_path = 'train.csv'\n",
        "test_path = 'test.csv'\n",
        "val_path = 'val.csv'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3bh0FGhXv3u"
      },
      "source": [
        "### Conv1D\n",
        "\n",
        "Again the data processing and loading remains exactly the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7YMbs8a43jD"
      },
      "source": [
        "### Creating the Fields.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_xUMByB5tGa"
      },
      "source": [
        "from torchtext.legacy import data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RaqW-b-4lJJ"
      },
      "source": [
        "TEXT = data.Field(\n",
        "   tokenize=\"spacy\",\n",
        "  batch_first=True,\n",
        "  tokenizer_language = 'en_core_web_sm',\n",
        ")\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugU18S_7tAS"
      },
      "source": [
        "fields = {\n",
        "  \"Questions\": ('text', TEXT),\n",
        "  \"Category1\": ('label', LABEL)\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiNOBqFO8pyo"
      },
      "source": [
        "### Creating the dataset.\n",
        "\n",
        "We ar going to use the `TabularDataset.split()` to create the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAgiWOoh8mWO"
      },
      "source": [
        "train_data, val_data, test_data = data.TabularDataset.splits(\n",
        "   files_path,\n",
        "   train=train_path,\n",
        "   test= train_path,\n",
        "   validation= train_path,\n",
        "   format = \"csv\",\n",
        "   fields=fields,\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f4YEu-fQ1WK",
        "outputId": "6017b576-fbce-4398-ca46-617dbfdade1b"
      },
      "source": [
        "len(train_data), len(test_data), len(val_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5179, 5179, 5179)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ1oWIQW9KWn",
        "outputId": "691e2910-141e-43e9-f175-bd91d49cfbad"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['What', 'is', 'the', 'name', 'of', 'Miss', 'India', '1994', '?'], 'label': 'HUM'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t-0JC1U-l73"
      },
      "source": [
        "### Building the Vocabulary and Loading the `pretrained` word vectors.\n",
        "\n",
        "We are going to use the `glove.6B.100d` word vectors which was trained with 6 billion words and each word is a 100 dimesional vector.\n",
        "\n",
        "**Note** We should only build the vocabulary on the `train` dataset only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4p3m1_--WYU"
      },
      "source": [
        "MAX_VOCAB_SIZE = 100_000_000\n",
        "\n",
        "TEXT.build_vocab(\n",
        "    train_data,\n",
        "     max_size = MAX_VOCAB_SIZE,\n",
        "    vectors = \"glove.6B.100d\",\n",
        "    unk_init = torch.Tensor.normal_\n",
        ")\n",
        "LABEL.build_vocab(train_data)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFukx38W_aNv"
      },
      "source": [
        "### Device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYPGTIZ7_Zet",
        "outputId": "002a665f-40f7-49c2-f2f5-67bd0790a30d"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKkUJMz6K0WH",
        "outputId": "a108be66-5695-4f47-938d-deeab4bfea16"
      },
      "source": [
        "LABEL.vocab.stoi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None,\n",
              "            {'ABBR': 5, 'DESC': 2, 'ENTY': 0, 'HUM': 1, 'LOC': 4, 'NUM': 3})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaCMz4yZ_n5W"
      },
      "source": [
        "### Creating iterators.\n",
        "\n",
        "We are going to use our favorite iterator known as the `BucketIterator` to create iterators for all the sets that we have.\n",
        "\n",
        "For the `batch_size` this time around we want to test a huge batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPDrPFKQ_mf1"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    device = device,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spZX8zodA91F"
      },
      "source": [
        "### Creating the  Conv1D Model.\n",
        "\n",
        "* In this notebook I'm not going to explain how convnets works but If you want to understand more about convnets. I recommend [this](https://github.com/CrispenGari/pytorch-python/blob/main/09_TorchText/02_Sentiment_Analyisis_Series/04_CNN_Sentiment_Analyisis.ipynb) notebook. Which has a clear explanation of how conv nets work on sequential data.\n",
        "\n",
        "\n",
        "* We are going to create a generic `ConvNet` model that accepts a number of parameters and all the magic will hapen behind the scene. **Really!!**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReThGRspA7uO"
      },
      "source": [
        "class QuestionsConv1DNet(nn.Module):\n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               embedding_size,\n",
        "               n_filters,\n",
        "               filter_sizes,\n",
        "               output_size,\n",
        "               pad_idx,\n",
        "               dropout=.5\n",
        "               ):\n",
        "    super(QuestionsConv1DNet, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(\n",
        "        vocab_size, embedding_size, padding_idx=pad_idx\n",
        "    )\n",
        "    self.convs = nn.ModuleList([\n",
        "        nn.Conv1d(\n",
        "            in_channels=embedding_size,\n",
        "            out_channels = n_filters,\n",
        "            kernel_size=fs\n",
        "        ) for fs in filter_sizes \n",
        "    ])\n",
        "\n",
        "    self.fc = nn.Linear(len(filter_sizes) * n_filters, output_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text).permute(0, 2, 1)\n",
        "    conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2)\n",
        "            for conv in conved\n",
        "            ]\n",
        "    cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "    return self.fc(cat)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2IVtv8EDhJd"
      },
      "source": [
        "### Creating the model instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbJdW058DgTl",
        "outputId": "f141ed8a-1198-4d4f-903f-a1a1982117db"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5]\n",
        "OUTPUT_DIM =  6\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] \n",
        "DROPOUT = 0.5\n",
        "\n",
        "questions_model = QuestionsConv1DNet(\n",
        "            INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            N_FILTERS,\n",
        "            FILTER_SIZES,\n",
        "            OUTPUT_DIM, \n",
        "            pad_idx = PAD_IDX,\n",
        "            dropout=DROPOUT\n",
        "            ).to(device)\n",
        "questions_model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuestionsConv1DNet(\n",
              "  (embedding): Embedding(9053, 100, padding_idx=1)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
              "    (1): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
              "    (2): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
              "    (3): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
              "    (4): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
              "    (5): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
              "    (6): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
              "    (7): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
              "    (8): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
              "    (9): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
              "    (10): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
              "  )\n",
              "  (fc): Linear(in_features=1100, out_features=6, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acQD-B6zEE72"
      },
      "source": [
        "### Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQaztp4ID-HI",
        "outputId": "a0ad8e25-4d8b-4de6-8cee-acaaecbed09a"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(questions_model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of paramaters: 1,343,006\n",
            "Total tainable parameters: 1,343,006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8gjXny7EUNb"
      },
      "source": [
        "### Loading pretrained vectors to the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULe__PiKEQS8"
      },
      "source": [
        "pretrained_embeddings  = TEXT.vocab.vectors"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeXa9ycREfuV",
        "outputId": "442604a1-b162-4295-b0a7-1f94f3b39b63"
      },
      "source": [
        "questions_model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.1233,  0.3499,  0.6173],\n",
              "        [ 0.7262,  0.0912, -0.3891,  ...,  0.0821,  0.4440, -0.7240],\n",
              "        [ 0.1638,  0.6046,  1.0789,  ..., -0.3140,  0.1844,  0.3624],\n",
              "        ...,\n",
              "        [ 0.0091,  0.2810,  0.7356,  ..., -0.7508,  0.8967, -0.7631],\n",
              "        [ 0.2906,  0.3217,  0.2419,  ..., -0.9444, -0.3790,  0.6196],\n",
              "        [-0.3898, -0.5949,  0.2729,  ..., -1.0948,  0.8617, -0.4429]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q27hKnrpEoKF"
      },
      "source": [
        "### Zeroing the `<pad>` and `<unk>` tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_qvO2teEmvh",
        "outputId": "c2afb8f8-c65a-4493-9355-f35692dc4551"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token] or TEXT.vocab.stoi[\"<unk>\"]\n",
        "questions_model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "questions_model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "questions_model.embedding.weight.data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.1638,  0.6046,  1.0789,  ..., -0.3140,  0.1844,  0.3624],\n",
              "        ...,\n",
              "        [ 0.0091,  0.2810,  0.7356,  ..., -0.7508,  0.8967, -0.7631],\n",
              "        [ 0.2906,  0.3217,  0.2419,  ..., -0.9444, -0.3790,  0.6196],\n",
              "        [-0.3898, -0.5949,  0.2729,  ..., -1.0948,  0.8617, -0.4429]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm2RklTLE-Dv"
      },
      "source": [
        "### Loss and optimizer.\n",
        "We are going to use the Adam as our optimizer with the default leaning rate. We are also going to use `CrossEntropyLoss()` as our loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7UCyAlYE1nA"
      },
      "source": [
        "optimizer = torch.optim.Adam(questions_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi2tk-kSFTVq"
      },
      "source": [
        "### Accuracy function.\n",
        "We are going to create the `categorical_accuracy()` function that will calculate the categorical accuracy for predicted labels and actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRCfQZvmFPBS"
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "  top_pred = preds.argmax(1, keepdim = True)\n",
        "  correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "  return correct.float() / y.shape[0]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gf_nyXVFvOG"
      },
      "source": [
        "### Training and Evaluation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80QEfQeaFuVZ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss ,epoch_acc = 0, 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text = batch.text\n",
        "        predictions = model(text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss , epoch_acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.text\n",
        "            predictions = model(text)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdtkgFFJG1WS"
      },
      "source": [
        "### Training loop.\n",
        "We are going to create helper functions that will help us to visualize our training.\n",
        "\n",
        "1. Time to string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMH6iA1AG0tj"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "    "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp5OjGiPHR6h"
      },
      "source": [
        "2. tabulate training epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtCTm84HHQb5"
      },
      "source": [
        "def visualize_training(start, end, train_loss, train_accuracy, val_loss, val_accuracy, title):\n",
        "  data = [\n",
        "       [\"Training\", f'{train_loss:.3f}', f'{train_accuracy:.3f}', f\"{hms_string(end - start)}\" ],\n",
        "       [\"Validation\", f'{val_loss:.3f}', f'{val_accuracy:.3f}', \"\" ],       \n",
        "  ]\n",
        "  table = PrettyTable([\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"])\n",
        "  table.align[\"CATEGORY\"] = 'l'\n",
        "  table.align[\"LOSS\"] = 'r'\n",
        "  table.align[\"ACCURACY\"] = 'r'\n",
        "  table.align[\"ETA\"] = 'r'\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcu_WMc2HXqb",
        "outputId": "c8710227-b299-4b4b-f0f7-ac0a64edb4d1"
      },
      "source": [
        "\n",
        "N_EPOCHS = 100\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss, train_acc = train(questions_model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(questions_model, val_iter, criterion)\n",
        "    title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} {'saving best model...' if valid_loss < best_valid_loss else 'not saving...'}\"\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(questions_model.state_dict(), 'best-model.pt')\n",
        "    end = time.time()\n",
        "    visualize_training(start, end, train_loss, train_acc, valid_loss, valid_acc, title)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------+\n",
            "|     EPOCH: 01/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.209 |    0.530 | 0:00:00.63 |\n",
            "| Validation | 0.745 |    0.739 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 02/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.691 |    0.756 | 0:00:00.51 |\n",
            "| Validation | 0.473 |    0.861 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 03/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.470 |    0.843 | 0:00:00.51 |\n",
            "| Validation | 0.346 |    0.901 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 04/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.336 |    0.891 | 0:00:00.52 |\n",
            "| Validation | 0.218 |    0.943 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 05/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.229 |    0.935 | 0:00:00.51 |\n",
            "| Validation | 0.147 |    0.966 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 06/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.161 |    0.959 | 0:00:00.51 |\n",
            "| Validation | 0.099 |    0.979 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 07/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.109 |    0.973 | 0:00:00.52 |\n",
            "| Validation | 0.070 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 08/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.076 |    0.986 | 0:00:00.51 |\n",
            "| Validation | 0.048 |    0.994 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 09/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.053 |    0.992 | 0:00:00.49 |\n",
            "| Validation | 0.035 |    0.995 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 10/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.039 |    0.996 | 0:00:00.50 |\n",
            "| Validation | 0.028 |    0.998 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 11/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.031 |    0.995 | 0:00:00.50 |\n",
            "| Validation | 0.020 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 12/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.024 |    0.998 | 0:00:00.52 |\n",
            "| Validation | 0.018 |    0.998 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 13/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.019 |    0.999 | 0:00:00.51 |\n",
            "| Validation | 0.012 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 14/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.016 |    0.998 | 0:00:00.51 |\n",
            "| Validation | 0.011 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 15/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.013 |    0.999 | 0:00:00.53 |\n",
            "| Validation | 0.010 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 16/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.011 |    0.999 | 0:00:00.52 |\n",
            "| Validation | 0.008 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 17/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.008 |    0.999 | 0:00:00.51 |\n",
            "| Validation | 0.007 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 18/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.007 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.006 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 19/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.006 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.005 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 20/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.006 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.005 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 21/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.005 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.005 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 22/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.005 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.004 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 23/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.005 |    1.000 | 0:00:00.54 |\n",
            "| Validation | 0.003 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 24/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.005 |    0.999 | 0:00:00.51 |\n",
            "| Validation | 0.004 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 25/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.004 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.003 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 26/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.004 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.003 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 27/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.003 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.003 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 28/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.003 |    1.000 | 0:00:00.55 |\n",
            "| Validation | 0.003 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 29/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.002 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 30/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.003 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 31/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:00.54 |\n",
            "| Validation | 0.002 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 32/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.002 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 33/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.002 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 34/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:00.54 |\n",
            "| Validation | 0.002 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 35/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.002 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 36/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 37/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:00.54 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 38/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 39/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 40/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 41/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 42/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 43/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 44/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 45/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 46/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.54 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 47/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.54 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 48/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 49/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 50/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 51/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 52/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 53/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 54/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 55/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.54 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 56/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 57/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 58/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.53 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 59/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 60/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.54 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 61/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 62/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 63/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 64/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 65/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.49 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 66/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 67/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 68/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 69/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 70/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.49 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 71/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.49 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 72/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.49 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 73/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.49 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 74/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.50 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 75/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.49 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 76/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 77/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.50 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 78/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 79/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.49 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 80/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 81/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.50 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 82/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.51 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 83/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.50 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 84/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.50 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 85/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.49 |\n",
            "| Validation | 0.002 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 86/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.52 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 87/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.001 |    1.000 | 0:00:00.50 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 88/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.000 |    1.000 | 0:00:00.50 |\n",
            "| Validation | 0.000 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 89/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    1.000 | 0:00:00.48 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 90/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.003 |    0.999 | 0:00:00.50 |\n",
            "| Validation | 0.002 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 91/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.012 |    0.996 | 0:00:00.50 |\n",
            "| Validation | 0.002 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 92/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.039 |    0.985 | 0:00:00.53 |\n",
            "| Validation | 0.010 |    0.997 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 93/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.044 |    0.987 | 0:00:00.49 |\n",
            "| Validation | 0.010 |    0.997 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 94/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.028 |    0.993 | 0:00:00.49 |\n",
            "| Validation | 0.005 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 95/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.013 |    0.995 | 0:00:00.49 |\n",
            "| Validation | 0.012 |    0.996 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 96/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.018 |    0.995 | 0:00:00.50 |\n",
            "| Validation | 0.004 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 97/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.012 |    0.998 | 0:00:00.50 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 98/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.005 |    0.999 | 0:00:00.51 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 99/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.004 |    0.998 | 0:00:00.50 |\n",
            "| Validation | 0.002 |    0.999 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 100/100 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.002 |    0.999 | 0:00:00.49 |\n",
            "| Validation | 0.001 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNkikbDIB2z"
      },
      "source": [
        "### Model Evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8fWTBruHw1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf576a7-22eb-4bc9-9b8f-f2660c886fc8"
      },
      "source": [
        "questions_model.load_state_dict(torch.load('best-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(questions_model, test_iter, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.000 | Test Acc: 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4zEBLYsLki5"
      },
      "source": [
        "### Model Inference.\n",
        "\n",
        "We are now ready to make predictions with our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyNLifHaJBKS"
      },
      "source": [
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clNBiJ9NPkRJ",
        "outputId": "8e763362-f4a8-4fd1-fe5d-e1d5549d6da8"
      },
      "source": [
        "reversed_labels = dict([(v, k) for (k, v) in LABEL.vocab.stoi.items()])\n",
        "reversed_labels"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'ENTY', 1: 'HUM', 2: 'DESC', 3: 'NUM', 4: 'LOC', 5: 'ABBR'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9A6ZGTILzWD"
      },
      "source": [
        "def tabulate(column_names, data, title=\"QUESTIONS PREDICTIONS TABLE\"):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.align[column_names[0]] = \"l\"\n",
        "  table.align[column_names[1]] = \"l\"\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "\n",
        "def predict_question_type(model, sentence, min_len = 5, actual_class=0):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "     \n",
        "      if len(tokenized) < min_len:\n",
        "          tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "      indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "      tensor = torch.LongTensor(indexed).to(device).unsqueeze(0)\n",
        "      probabilities = model(tensor)\n",
        "      prediction = torch.argmax(probabilities, dim=1)\n",
        "      prediction = prediction.item()\n",
        "    \n",
        "      table_headers =[\"KEY\", \"VALUE\"]\n",
        "      table_data = [\n",
        "          [\"PREDICTED CLASS\",  prediction],\n",
        "          [\"ACTUAL CLASS\", actual_class],\n",
        "          [\"PREDICTED CLASS NAME\",  reversed_labels[prediction]],    \n",
        "      ]\n",
        "      tabulate(table_headers, table_data)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm5h2CDLUECt",
        "outputId": "1de669a5-9624-422c-8200-e56a67b759e1"
      },
      "source": [
        "reversed_labels"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'ENTY', 1: 'HUM', 2: 'DESC', 3: 'NUM', 4: 'LOC', 5: 'ABBR'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W93zzSlQMO4p"
      },
      "source": [
        "### Location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcuHlaPwML4Y",
        "outputId": "7e2244c2-2d9a-413f-d2bf-c639992d4544"
      },
      "source": [
        "predict_question_type(questions_model, \"What are the largest libraries in the US ?\", actual_class=4)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 4     |\n",
            "| ACTUAL CLASS         | 4     |\n",
            "| PREDICTED CLASS NAME | LOC   |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5Eqjo0MMP8L"
      },
      "source": [
        "### Human"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnhFchDiMQQn",
        "outputId": "9e3e776b-77d0-4d9a-bc66-536c900c6d7a"
      },
      "source": [
        "predict_question_type(questions_model, \"Who is John Macarthur , 1767-1834 ?\", actual_class=1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 1     |\n",
            "| ACTUAL CLASS         | 1     |\n",
            "| PREDICTED CLASS NAME | HUM   |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WvswKe5MQ3D"
      },
      "source": [
        "### DESCRIPTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3jeZM6xMRVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e9c704-a00a-4e0c-90aa-4e362ae53be4"
      },
      "source": [
        "predict_question_type(questions_model, \"What is the root of all evil ? \", actual_class=2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 2     |\n",
            "| ACTUAL CLASS         | 2     |\n",
            "| PREDICTED CLASS NAME | DESC  |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeGjIT9NMRxA"
      },
      "source": [
        "### Numeric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GxH8LKiMSOH",
        "outputId": "8b3b3ea1-700c-4bda-f3c9-4e9907a5c245"
      },
      "source": [
        "predict_question_type(questions_model, \"How many watts make a kilowatt ?\", actual_class=3)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 3     |\n",
            "| ACTUAL CLASS         | 3     |\n",
            "| PREDICTED CLASS NAME | NUM   |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-7beS0jPLW7"
      },
      "source": [
        "### ENTITY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvQq7ul9PHFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa61545a-90dd-4b77-bcad-87713cd94dd7"
      },
      "source": [
        "\n",
        "predict_question_type(questions_model, \"What films featured the character Popeye Doyle ?\", actual_class=0)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 0     |\n",
            "| ACTUAL CLASS         | 0     |\n",
            "| PREDICTED CLASS NAME | ENTY  |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ0cQrfFQ9QI"
      },
      "source": [
        "### ABBREVIATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvzy3XHRQZQQ",
        "outputId": "0a113258-f80f-4a8b-ae06-6f06fbbca0a2"
      },
      "source": [
        "predict_question_type(questions_model, \"What does NECROSIS stands for ?\", actual_class=5)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 5     |\n",
            "| ACTUAL CLASS         | 5     |\n",
            "| PREDICTED CLASS NAME | ABBR  |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sa3_lq4VHSn"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "We were able to create our model and get a loss of `0` and `100%` accuracy on the validation and test data.\n",
        "\n",
        "### Next Step\n",
        "*  In the next Notebook we will try to use `RNN` based on the first notebook to classify two labels for each question."
      ]
    }
  ]
}