{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Emotions_Sentiment_Analyisis_Packed_Padded_Sequences.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM1utmDx96W_"
      },
      "source": [
        "### Emotions.\n",
        "\n",
        "In this notebook we are going to create a pytorch model using torchtext and our custom dataset that identifies emotions of a given sentence.\n",
        "\n",
        "### Emotions:\n",
        "````\n",
        "😞 -> sadness\n",
        "😨 -> fear\n",
        "😄 -> joy\n",
        "😮 -> surprise\n",
        "😍 -> love\n",
        "😠 -> anger\n",
        "````\n",
        "\n",
        "We are going to use our custom dataset that we will load from my google drive.\n",
        "\n",
        "### Structure of the data.\n",
        "\n",
        "We have three files which are:\n",
        "* test.txt\n",
        "* train.txt\n",
        "* val.txt\n",
        "And each of these file contains lines with a respective lable. The text in these files looks as follows:\n",
        "\n",
        "```txt\n",
        "im feeling quite sad and sorry for myself but ill snap out of it soon;sadness\n",
        "i feel like i am still looking at a blank canvas blank pieces of paper;sadness\n",
        "i feel like a faithful servant;love\n",
        "```\n",
        "\n",
        "We will process these text file to come up with json files which is easy to work with when creating our own dataset using torchtext. The following files will be created\n",
        "\n",
        "* train.json\n",
        "* test.json\n",
        "* validation.json\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwW3ZpRa8M16"
      },
      "source": [
        "import json\n",
        "import time\n",
        "from prettytable import PrettyTable\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch, os, random\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3t_igXyM9t1"
      },
      "source": [
        "### Setting seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IMd2xVfNARk"
      },
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deteministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r80FOaPcCTdU"
      },
      "source": [
        "### Mounting my Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fUj1C0PCXzk",
        "outputId": "f081a449-4fc6-4753-b60d-5264b9d82bd7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVOh6a73CGIt",
        "outputId": "d4a200e0-4187-40d8-a5dd-be0650bd86ed"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/NLP Data/emotions-nlp'\n",
        "os.path.exists(data_path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmGTqOGmDdzo"
      },
      "source": [
        "### Loading files lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jgn2_KHCOsX"
      },
      "source": [
        "with open(os.path.join(data_path, 'test.txt'), 'r') as reader:\n",
        "  test_data = reader.read().splitlines()\n",
        "with open(os.path.join(data_path, 'val.txt'), 'r') as reader:\n",
        "  valid_data = reader.read().splitlines()\n",
        "with open(os.path.join(data_path, 'train.txt'), 'r') as reader:\n",
        "  train_data = reader.read().splitlines()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdDhHO4jDixm"
      },
      "source": [
        "### Creating `.json` file from these loaded list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwZ1FrzZClGD"
      },
      "source": [
        "train_data_dicts = []\n",
        "test_data_dicts = []\n",
        "valid_data_dicts = []\n",
        "\n",
        "emotions = ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise' ]\n",
        "emotions_dict = dict([(v, i) for (i, v) in enumerate(emotions)])\n",
        "\n",
        "for line in test_data:\n",
        "  text, emotion = line.split(';')\n",
        "  test_data_dicts.append({\n",
        "      'text': text,\n",
        "      \"emotion_text\": emotion,\n",
        "      \"emotion\": emotions_dict.get(emotion)\n",
        "  })\n",
        "\n",
        "for line in train_data:\n",
        "  text, emotion = line.split(';')\n",
        "  train_data_dicts.append({\n",
        "      'text': text,\n",
        "      \"emotion_text\": emotion,\n",
        "      \"emotion\": emotions_dict.get(emotion)\n",
        "  })\n",
        "\n",
        "for line in valid_data:\n",
        "  text, emotion = line.split(';')\n",
        "  valid_data_dicts.append({\n",
        "      'text': text,\n",
        "      \"emotion_text\": emotion,\n",
        "      \"emotion\": emotions_dict.get(emotion)\n",
        "  })"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiNlTgHMGlJ5",
        "outputId": "71e53dee-5e24-49b5-a695-2b69b9c236a0"
      },
      "source": [
        "test_path = 'test.json'\n",
        "train_path = 'train.json'\n",
        "valid_path = 'valid.json'\n",
        "\n",
        "base_path = '/content/drive/MyDrive/NLP Data/emotions-nlp/json'\n",
        "if not os.path.exists(base_path):\n",
        "  os.makedirs(base_path)\n",
        "  \n",
        "file_object = open(os.path.join(base_path, train_path), 'w')\n",
        "for line in train_data_dicts:\n",
        "  file_object.write(json.dumps(line))\n",
        "  file_object.write('\\n')\n",
        "file_object.close()\n",
        "print(\"train.json created\")\n",
        "\n",
        "file_object = open(os.path.join(base_path, test_path), 'w')\n",
        "for line in test_data_dicts:\n",
        "  file_object.write(json.dumps(line))\n",
        "  file_object.write('\\n')\n",
        "file_object.close()\n",
        "print(\"test.json created\")\n",
        "\n",
        "file_object = open(os.path.join(base_path, valid_path), 'w')\n",
        "for line in valid_data_dicts:\n",
        "  file_object.write(json.dumps(line))\n",
        "  file_object.write('\\n')\n",
        "file_object.close()\n",
        "print(\"valid.json created\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.json created\n",
            "test.json created\n",
            "valid.json created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdTT0Wf-FkQM"
      },
      "source": [
        "### Checking how many example do we have for each set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o__Q9Eg-ElOr",
        "outputId": "51107653-9fa9-4dcd-c865-bef3b8e837ef"
      },
      "source": [
        "def tabulate(column_names, data, title):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "\n",
        "data_rows =[\"training\", len(train_data_dicts) ], [\"testing\", len(test_data_dicts) ], [\"validation\", len(valid_data_dicts) ]\n",
        "title = \"EXAMPLES IN EACH SET\"\n",
        "column_data = \"SET\", \"EXAMPLES\"\n",
        "tabulate(column_data,data_rows, title )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+\n",
            "|  EXAMPLES IN EACH SET |\n",
            "+------------+----------+\n",
            "|    SET     | EXAMPLES |\n",
            "+------------+----------+\n",
            "|  training  |  16000   |\n",
            "|  testing   |   2000   |\n",
            "| validation |   2000   |\n",
            "+------------+----------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koSwViS6GgpG"
      },
      "source": [
        "### Preparing the fields\n",
        "Now that our `.json` files of all the sets looks as follows:\n",
        "\n",
        "```json\n",
        "{\"text\": \"i feel a little mellow today\", \"emotion_text\": \"joy\", \"emotion\": 2}\n",
        "```\n",
        "We are now ready to create the fields ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8gRW0MvF5zg"
      },
      "source": [
        "from torchtext.legacy import data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDdVTrC6IN6U"
      },
      "source": [
        "We are going to pass `include_lengths=True` to the text Field because we are using padding padded sequences in this notebook. In the label Field we have to specify the datatype as a LongTensor. This is because when doing multiclass classfication pytorch expects the datatype to be a long tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keaWKPOYIlji"
      },
      "source": [
        "TEXT = data.Field(\n",
        "    tokenize=\"spacy\",\n",
        "    include_lengths = True,\n",
        "    tokenizer_language = 'en_core_web_sm'\n",
        ")\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2-nJI3jJ1aX"
      },
      "source": [
        "### Creating Field"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42KSs4x4Jqn7"
      },
      "source": [
        "fields ={\n",
        "    \"emotion_text\": (\"emotion\", LABEL),\n",
        "    \"text\": (\"text\", TEXT)\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j4EktWIKNTe"
      },
      "source": [
        "### Now we have to create our datasets.\n",
        "\n",
        "We are going to use the `TabularDataset` to create sets of data for validation, training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KeetcfEKI4T"
      },
      "source": [
        "train_data, test_data, valid_data = data.TabularDataset.splits(\n",
        "    path=base_path,\n",
        "    train=train_path,\n",
        "    test=test_path,\n",
        "    validation = valid_path,\n",
        "    format=train_path.split('.')[-1],\n",
        "    fields=fields\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKXy_ncvKz3w",
        "outputId": "b9ef6f85-e017-4650-da3e-4f1ea7f11d5f"
      },
      "source": [
        "print(vars(train_data.examples[2]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'emotion': 'anger', 'text': ['i', 'm', 'grabbing', 'a', 'minute', 'to', 'post', 'i', 'feel', 'greedy', 'wrong']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GngtXNqBLKcY"
      },
      "source": [
        "### Loading the pretrained word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_U8PMxUK93K"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "TEXT.build_vocab(\n",
        "    train_data,\n",
        "    max_size = MAX_VOCAB_SIZE,\n",
        "    vectors = \"glove.6B.100d\",\n",
        "    unk_init = torch.Tensor.normal_\n",
        ")\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAIgg0FoMv5W"
      },
      "source": [
        "### Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YwSNu3PMx_8"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXmABbFBLYNc"
      },
      "source": [
        "### Now lets create iterators.\n",
        "\n",
        "For this we are going to use my fav ``BucketIterator`` to create iterators for each set.\n",
        "\n",
        "**Note:** - we have to pass a `sort_key` and `sort_within_batch=True` since we are using packed padded sequences otherwise it wont work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL3roEBULWeD"
      },
      "source": [
        "sort_key = lambda x: len(x.text)\n",
        "BATCH_SIZE = 64\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    device = device,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = sort_key,\n",
        "    sort_within_batch=True\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGYa4u1HN9on"
      },
      "source": [
        "### Creating a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LWvUzUBMnu8"
      },
      "source": [
        "class EmotionsLSTMRNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_size,\n",
        "               hidden_size, output_size, num_layers,\n",
        "               bidirectional, dropout, pad_index\n",
        "               ):\n",
        "    super(EmotionsLSTMRNN, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size,embedding_size,\n",
        "                                  padding_idx=pad_index)\n",
        "    self.lstm = nn.LSTM(embedding_size, hidden_size = hidden_size,\n",
        "                        bidirectional=bidirectional, num_layers=num_layers,\n",
        "                        dropout = dropout\n",
        "                        )\n",
        "    self.hidden_1 = nn.Linear(hidden_size * 2, out_features=512)\n",
        "    self.hidden_2 = nn.Linear(512, out_features=256)\n",
        "    self.output_layer = nn.Linear(256, out_features=output_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text, text_lengths):\n",
        "    embedded = self.dropout(self.embedding(text))\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'), enforce_sorted=False)\n",
        "    packed_output, (h_0, c_0) = self.lstm(packed_embedded)\n",
        "    output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "    h_0 = self.dropout(torch.cat((h_0[-2,:,:], h_0[-1,:,:]), dim = 1))\n",
        "\n",
        "    out = self.dropout(self.hidden_1(h_0))\n",
        "    out = self.hidden_2(out)\n",
        "    return self.output_layer(out)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7BEzpyGOyWX"
      },
      "source": [
        "### Creating the Model instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBitwM2eQi37",
        "outputId": "a5b66f7c-b1fa-472a-85bb-a9f9d51f145f"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab) # # 25002\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 6\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # 0\n",
        "emotions_model = EmotionsLSTMRNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX).to(device)\n",
        "emotions_model"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmotionsLSTMRNN(\n",
              "  (embedding): Embedding(15167, 100, padding_idx=1)\n",
              "  (lstm): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  (hidden_1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (hidden_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (output_layer): Linear(in_features=256, out_features=6, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fQgn0-IQ4kd"
      },
      "source": [
        "### Counting parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEaTKAgDQwxX",
        "outputId": "86e99f6b-6430-44c8-f00f-62b322c714bf"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(emotions_model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of paramaters: 4,222,370\n",
            "Total tainable parameters: 4,222,370\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjvZJEiAR5vc"
      },
      "source": [
        "### Loading pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoYhfS0PR0jF"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ3X6-PZR5XZ",
        "outputId": "42add9cb-7afe-4e81-972d-02e96122b88f"
      },
      "source": [
        "emotions_model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.1233,  0.3499,  0.6173],\n",
              "        [ 0.7262,  0.0912, -0.3891,  ...,  0.0821,  0.4440, -0.7240],\n",
              "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
              "        ...,\n",
              "        [-0.1438,  0.8681, -0.7219,  ...,  0.0553, -0.4339,  0.3486],\n",
              "        [-0.0422, -0.7724, -0.9311,  ..., -0.6228,  0.7262,  0.0521],\n",
              "        [-0.6644, -0.3045,  0.6151,  ...,  0.1404,  0.5788, -0.0333]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h7Av2P6SKbd"
      },
      "source": [
        "### Zeroiing the `pad` and `unk` indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zkoG-o5R5T7",
        "outputId": "2b445372-976e-4464-cfe2-991978358880"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token] or TEXT.vocab.stoi[\"<unk>\"]\n",
        "emotions_model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "emotions_model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "emotions_model.embedding.weight.data"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
              "        ...,\n",
              "        [-0.1438,  0.8681, -0.7219,  ...,  0.0553, -0.4339,  0.3486],\n",
              "        [-0.0422, -0.7724, -0.9311,  ..., -0.6228,  0.7262,  0.0521],\n",
              "        [-0.6644, -0.3045,  0.6151,  ...,  0.1404,  0.5788, -0.0333]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hR0X2h6Sesj"
      },
      "source": [
        "### Loss and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjPNxmwhR5Qu"
      },
      "source": [
        "optimizer = torch.optim.Adam(emotions_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGhXxngLS4gU"
      },
      "source": [
        "### Accuracy function (`categorical_accuracy`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs-y8LZvR5HO"
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    top_pred = preds.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdWa1ekITP3s"
      },
      "source": [
        "### Training and evaluation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q33IueZvR5Dh"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text, text_lengths = batch.text\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        loss = criterion(predictions, batch.emotion)\n",
        "        acc = categorical_accuracy(predictions, batch.emotion)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, text_lengths = batch.text\n",
        "            predictions = model(text, text_lengths)\n",
        "            loss = criterion(predictions, batch.emotion)\n",
        "            acc = categorical_accuracy(predictions, batch.emotion)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qla6TCZhT2uY"
      },
      "source": [
        "### Training Loop.\n",
        "\n",
        "We will create a function that will visualize our training loop `ETA` for each and every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmw6Zo9OUk_7"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "def visualize_training(start, end, train_loss, train_accuracy, val_loss, val_accuracy, title):\n",
        "  data = [\n",
        "       [\"Training\", f'{train_loss:.3f}', f'{train_accuracy:.3f}', f\"{hms_string(end - start)}\" ],\n",
        "       [\"Validation\", f'{val_loss:.3f}', f'{val_accuracy:.3f}', \"\" ],       \n",
        "  ]\n",
        "  table = PrettyTable([\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"])\n",
        "  table.align[\"CATEGORY\"] = 'l'\n",
        "  table.align[\"LOSS\"] = 'r'\n",
        "  table.align[\"ACCURACY\"] = 'r'\n",
        "  table.align[\"ETA\"] = 'r'\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_nNORR7T0cJ",
        "outputId": "b34326ad-775b-4e62-bda7-60413ca6af95"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss, train_acc = train(emotions_model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(emotions_model, valid_iterator, criterion)\n",
        "    title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} {'saving best model...' if valid_loss < best_valid_loss else 'not saving...'}\"\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(emotions_model.state_dict(), 'best-model.pt')\n",
        "    end = time.time()\n",
        "    visualize_training(start, end, train_loss, train_acc, valid_loss, valid_acc, title)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------+\n",
            "|     EPOCH: 01/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.174 |    0.933 | 0:00:07.95 |\n",
            "| Validation | 0.154 |    0.934 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 02/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.162 |    0.938 | 0:00:07.82 |\n",
            "| Validation | 0.139 |    0.934 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 03/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.144 |    0.942 | 0:00:07.78 |\n",
            "| Validation | 0.141 |    0.932 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 04/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.132 |    0.946 | 0:00:07.82 |\n",
            "| Validation | 0.131 |    0.934 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 05/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.123 |    0.948 | 0:00:07.73 |\n",
            "| Validation | 0.150 |    0.936 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 06/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.116 |    0.949 | 0:00:07.78 |\n",
            "| Validation | 0.157 |    0.927 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 07/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.113 |    0.955 | 0:00:07.75 |\n",
            "| Validation | 0.134 |    0.932 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 08/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.102 |    0.957 | 0:00:07.79 |\n",
            "| Validation | 0.142 |    0.938 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 09/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.096 |    0.961 | 0:00:07.81 |\n",
            "| Validation | 0.151 |    0.929 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 10/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.091 |    0.963 | 0:00:07.78 |\n",
            "| Validation | 0.144 |    0.938 |            |\n",
            "+------------+-------+----------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilgPdmFdZZWC"
      },
      "source": [
        "### Model Evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNxKwcnjXmTQ",
        "outputId": "6d95456e-7f4c-4be8-8fc5-13cd1ab4c8ed"
      },
      "source": [
        "emotions_model.load_state_dict(torch.load('best-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(emotions_model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.123 | Test Acc: 93.99%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta2Ie097ZtPQ"
      },
      "source": [
        "### Model Inference\n",
        "Making predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0iQvSoWaVX8"
      },
      "source": [
        "!pip install emoji\n",
        "import emoji\n",
        "emotions_emojis = {\n",
        "   'anger' : \":angry:\", \n",
        "   'fear': \":fearful:\", \n",
        "   'joy' : \":smile:\", \n",
        "   'love' : \":heart_eyes:\", \n",
        "   'sadness' : \":disappointed:\", \n",
        "   'surprise': \":open_mouth:\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xroYKDwsZiGm"
      },
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "\n",
        "def tabulate(column_names, data, title=\"EMOTION PREDICTIONS TABLE\"):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.align[column_names[0]] = \"l\"\n",
        "  table.align[column_names[1]] = \"l\"\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "\n",
        "classes = LABEL.vocab.itos \n",
        "def predict_emotion(model, sentence, min_len = 5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "      if len(tokenized) < min_len:\n",
        "          tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "      indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "      length =  [len(indexed)]\n",
        "      tensor = torch.LongTensor(indexed).to(device)\n",
        "      tensor = tensor.unsqueeze(1)\n",
        "      length_tensor = torch.LongTensor(length)\n",
        "      probabilities = model(tensor, length_tensor)\n",
        "      prediction = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "      class_name = classes[prediction]\n",
        "      emoji_text = emoji.emojize(emotions_emojis[class_name], language='en', use_aliases=True)\n",
        "      prediction = prediction.item()\n",
        "    \n",
        "      table_headers =[\"KEY\", \"VALUE\"]\n",
        "      table_data = [\n",
        "          [\"PREDICTED CLASS\",  prediction],\n",
        "          [\"PREDICTED CLASS NAME\",  class_name],\n",
        "          [\"PREDICTED CLASS EMOJI\",  emoji_text],     \n",
        "      ]\n",
        "      tabulate(table_headers, table_data)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRZQtawkegl1"
      },
      "source": [
        "### Sadness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwj7PF8hb4X2",
        "outputId": "3ed2907e-7db5-41b0-cb08-1349a7672b71"
      },
      "source": [
        "predict_emotion(emotions_model, \"im updating my blog because i feel shitty.\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+---------+\n",
            "| KEY                   | VALUE   |\n",
            "+-----------------------+---------+\n",
            "| PREDICTED CLASS       | 1       |\n",
            "| PREDICTED CLASS NAME  | sadness |\n",
            "| PREDICTED CLASS EMOJI | 😞      |\n",
            "+-----------------------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDTiOSS3erTD"
      },
      "source": [
        "### Fear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5hrWfjFcAsS",
        "outputId": "1123ff37-7d37-4dcc-a753-b2a18619bbd3"
      },
      "source": [
        "predict_emotion(emotions_model, \"i am feeling apprehensive about it but also wildly excited\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+-------+\n",
            "| KEY                   | VALUE |\n",
            "+-----------------------+-------+\n",
            "| PREDICTED CLASS       | 3     |\n",
            "| PREDICTED CLASS NAME  | fear  |\n",
            "| PREDICTED CLASS EMOJI | 😨    |\n",
            "+-----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLPx7Wt-e9j2"
      },
      "source": [
        "### Joy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSHjVNGwd_hA",
        "outputId": "7f216240-3ae1-4e3c-f7e8-2443103d1b81"
      },
      "source": [
        "predict_emotion(emotions_model, \"i feel a little mellow today.\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+-------+\n",
            "| KEY                   | VALUE |\n",
            "+-----------------------+-------+\n",
            "| PREDICTED CLASS       | 0     |\n",
            "| PREDICTED CLASS NAME  | joy   |\n",
            "| PREDICTED CLASS EMOJI | 😄    |\n",
            "+-----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwfwluRZfAKO"
      },
      "source": [
        "### Surprise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py05l1pBd_Z2",
        "outputId": "07fc4577-d30d-422e-b995-e41c0ecb9dea"
      },
      "source": [
        "predict_emotion(emotions_model, \"i feel shocked and sad at the fact that there are so many sick people.\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+----------+\n",
            "| KEY                   | VALUE    |\n",
            "+-----------------------+----------+\n",
            "| PREDICTED CLASS       | 5        |\n",
            "| PREDICTED CLASS NAME  | surprise |\n",
            "| PREDICTED CLASS EMOJI | 😮       |\n",
            "+-----------------------+----------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBYZw3NvfGEJ"
      },
      "source": [
        "### Love"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52BZlLjud_Vy",
        "outputId": "3b0a7640-ff60-4ea9-8127-61941a936c0a"
      },
      "source": [
        "predict_emotion(emotions_model, \"i want each of you to feel my gentle embrace.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+-------+\n",
            "| KEY                   | VALUE |\n",
            "+-----------------------+-------+\n",
            "| PREDICTED CLASS       | 4     |\n",
            "| PREDICTED CLASS NAME  | love  |\n",
            "| PREDICTED CLASS EMOJI | 😍    |\n",
            "+-----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCFQ1N6XfIWi"
      },
      "source": [
        "### Anger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWSblQCmeK0K",
        "outputId": "59aa839e-5eb1-45ae-fee4-e83f49712c3d"
      },
      "source": [
        "predict_emotion(emotions_model, \"i feel like my irritable sensitive combination skin has finally met it s match.\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+-------+\n",
            "| KEY                   | VALUE |\n",
            "+-----------------------+-------+\n",
            "| PREDICTED CLASS       | 2     |\n",
            "| PREDICTED CLASS NAME  | anger |\n",
            "| PREDICTED CLASS EMOJI | 😠    |\n",
            "+-----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M_vS13ufN0x"
      },
      "source": [
        "> Next we will clone this repository and use conv nets to perform emotions predictions using the same dataset."
      ]
    }
  ]
}