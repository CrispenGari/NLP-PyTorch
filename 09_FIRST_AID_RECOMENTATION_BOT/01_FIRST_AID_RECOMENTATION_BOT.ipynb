{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "___\n",
        "\n",
        "**project**: `First Aid Recomentation Bot (FARB)`\n",
        "\n",
        "**date**: `2022-12-14`\n",
        "\n",
        "**decription`**: `This notebook represent the code for data preparation all the way to model traing of an AI chatbot that will help in assisting people by giving them first aid recomendations.`\n",
        "\n",
        "**main**: `Natural Language Processing (NLP) pytorch`\n",
        "\n",
        "**programmer**: `crispengari`\n",
        "\n",
        "**architecture**: `Convulutional Neural Networks (torchtext)`\n",
        "\n",
        "**language:** `python` \n",
        "\n",
        "____\n",
        "\n",
        "\n",
        "### Problem Statement\n",
        "\"Human beings turn to forget First Aid precaution when someone is in need of it or gave them a wrong first aid treatment. Due to the power of Artificial intelligent in Natural Language Processing using deep leaning techniques, we can create ai models that will help humans as Bots.\"\n",
        "\n",
        "In this project i will introduce natural language processing techniques in health system, that can be used to help humans that are in need of a First Aid Treatment.\n",
        "\n",
        "### Data\n",
        "The dataset that we going to use in this notebook we be comming from [kaggle](https://www.kaggle.com/code/therealsampat/first-aid-recommendation-deep-learning-chatbot). We are going to generate our dataset based on the file called `intents.json` which is a file that contains `44` intents. We are going to save the prepared data into `.csv` files for three sets which are:\n",
        "\n",
        "1. train\n",
        "2. test\n",
        "3. validation\n",
        "\n",
        "\n",
        "### Model Architecture\n",
        "`CNN`s are not a good choice in processing sequential data, but in this notebook based on my repository `torchtext` we are going to use `CNN` in doing `multi-class` classifications of intents for our `Bot`. We are going to use the following notebook as reference:\n",
        "\n",
        "> [05_TORCHTEXT_CNN_1D](https://github.com/CrispenGari/torchtext/blob/main/sentiment-analyisis/05_TORCHTEXT_CNN_1D.ipynb)\n",
        "\n",
        "### Installing Helper Packages\n",
        "In the following code cell we are going to install the package called `helperfns` that provide us with some usefull helper functions for machine learning."
      ],
      "metadata": {
        "id": "_e0eOlNyp0Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install helperfns -q"
      ],
      "metadata": {
        "id": "AZEmuYO1pSCx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports\n",
        "\n",
        "In  the following code cell we are going to import all the packages that we are going to use throughout this `notebook`"
      ],
      "metadata": {
        "id": "-P5QiqDJtK37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "import torchtext\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torchtext import data\n",
        "from collections import Counter\n",
        "from torchtext import vocab\n",
        "\n",
        "from helperfns.tables import tabulate_data\n",
        "from helperfns.visualization import plot_complicated_confusion_matrix, plot_simple_confusion_matrix\n",
        "from helperfns.torch import models\n",
        "from helperfns.utils import hms_string\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive, files\n",
        "\n",
        "torchtext.__version__, torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXoDyT2RpR-0",
        "outputId": "7520d6cc-a34b-46ba-a195-5bcfaa3020d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('0.14.0', '1.13.0+cu116')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seed\n",
        "In the following code cell we are going to set the seed to all random operations for reproducivity."
      ],
      "metadata": {
        "id": "cVqGu8UDTkOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "4g7FAa9ETrDA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Device\n",
        "In the following code cell we are going to get `gpu` device if possible"
      ],
      "metadata": {
        "id": "fx6BtsYvTrtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4mXa6L0Tx4O",
        "outputId": "9953b7e8-cb20-45bf-8af8-cf86bb26bf51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "\n",
        "Our dataset that we are going to use will be comming from [`kaggle`](https://www.kaggle.com/code/therealsampat/first-aid-recommendation-deep-learning-chatbot/data) and will be loaded from google drive  where i uploaded it in a folder called `FARB`. So in the following code cell we are going to mount our google drive to this colab instance."
      ],
      "metadata": {
        "id": "eDiHxRiMtxgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2XqK2PNlpR8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203c2155-55f0-4b95-c2b1-633563430b4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Path to the dataset.\n",
        "Now we can define the path as a variable to the location where our `intents.json` file is located in the following codecell."
      ],
      "metadata": {
        "id": "ciiieVigOGCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/drive/My Drive/NLP Data/FARB\"\n",
        "\n",
        "assert os.path.exists(base_dir), f\"The path '{base_dir}' does not exists.\"\n",
        "\n",
        "intents_path = os.path.join(base_dir, 'intents.json')\n",
        "\n",
        "assert os.path.exists(intents_path), f\"The path '{intents_path}' does not exists.\""
      ],
      "metadata": {
        "id": "CEQ9QayBpR0L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we need to read the `intents.json` file and create a classification dataset from it."
      ],
      "metadata": {
        "id": "uhN_RheqQfGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(intents_path, \"r\") as f:\n",
        "  intents_data = json.load(f)"
      ],
      "metadata": {
        "id": "TmEiCSKDpRxq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of as single intent in that file looks as follows:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"tag\": \"Cuts\",\n",
        "   \"patterns\": [\"What to do if Cuts?\",\n",
        "    \"How to cure Cuts?\",\n",
        "    \"Which medicine to apply for Cuts?\",\n",
        "    \"what to apply on cuts?\",\n",
        "    \"Cuts\"],\n",
        "   \"responses\": [\"Wash the cut properly to prevent infection and stop the bleeding by applying pressure for 1-2minutes until bleeding stops. Apply Petroleum Jelly to make sure that the wound is moist for quick healing. Finally cover the cut with a sterile bandage. Pain relievers such as acetaminophen can be applied.\"],\n",
        "   \"context_set\": \"\"\n",
        "}\n",
        "```\n",
        "So what we are intrested in for model training is `patterns` and it's tag, so our target value that we are trying to predict is a `tag` given a certain `pattern`. So from this we are going to generate our data maped with all the `pattens` to their labels."
      ],
      "metadata": {
        "id": "z2rGLv9-Q637"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = list()\n",
        "for intent in intents_data.get('intents'):\n",
        "  label = intent.get('tag').lower()\n",
        "  for pattern in intent.get('patterns'):\n",
        "    feature = pattern.lower()\n",
        "    dataset.append((feature, label))\n",
        "\n",
        "print(\"Dataset size: {}\".format(len(dataset)))"
      ],
      "metadata": {
        "id": "OzuqHHnzpRuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bed4c35-9e91-4797-8437-58c475427ddc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a small dataset that contains `188` examples, let's check the first `10` examples in the dataset:"
      ],
      "metadata": {
        "id": "ZmXJtTEsTAA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "id": "mYtE32C2pRr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68eabe8f-7e56-4bcb-fb70-75e6746b0c3a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('what to do if cuts?', 'cuts'),\n",
              " ('how to cure cuts?', 'cuts'),\n",
              " ('which medicine to apply for cuts?', 'cuts'),\n",
              " ('what to apply on cuts?', 'cuts'),\n",
              " ('cuts', 'cuts'),\n",
              " ('how do you treat abrasions?', 'abrasions'),\n",
              " ('do abrasions cause scars?', 'abrasions'),\n",
              " ('abrasions', 'abrasions'),\n",
              " ('what to do if abrasions?', 'abrasions'),\n",
              " ('which medicine to apply for abrasions?', 'abrasions')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we are going to use the `random` module to shuffle our dataset and then check again the size first `10` examples before creating dataframes."
      ],
      "metadata": {
        "id": "miWuxr3nTTxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(dataset)"
      ],
      "metadata": {
        "id": "JjUTIfDIpRpE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OvbVPUrrnWRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804c4fe9-58ab-4328-cb9a-22962349e104"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('which medicine to apply for cuts?', 'cuts'),\n",
              " ('how do you treat a broken toe?', 'broken toe'),\n",
              " ('stings', 'stings'),\n",
              " ('how to help a drowning person in cpr?', 'cpr'),\n",
              " ('how to cure testicle pain?', 'testicle pain'),\n",
              " ('what to do if i have a blocked nose?', 'nasal congestion'),\n",
              " ('what to do if someone drowned?', 'drowning'),\n",
              " ('how do you treat a fracture?', 'fracture'),\n",
              " ('what to do if i get a wound?', 'wound'),\n",
              " ('what to do if you get a sting?', 'stings')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataset[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So for our train data we are going to take all the examples in the `dataset` and then for the `validation` and `testing` set we are going to take a fraction of `40%` and `60%` from the dataset respectively."
      ],
      "metadata": {
        "id": "qn6nF_4JUVMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_df = pd.DataFrame(dataset, columns=[\"text\", \"label\" ])\n",
        "\n",
        "TEST_EXAMPLES = int(.6 * len(dataset))\n",
        "\n",
        "random.shuffle(dataset)\n",
        "test_df = pd.DataFrame(dataset[:TEST_EXAMPLES], columns=[\"text\", \"label\" ])\n",
        "val_df = pd.DataFrame(dataset[TEST_EXAMPLES: ], columns=[\"text\", \"label\" ])"
      ],
      "metadata": {
        "id": "fbwMyFBzT8y_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking our dataframes.\n",
        "\n",
        "\n",
        "1. train dataframe"
      ],
      "metadata": {
        "id": "ShVBIiWjU9t_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vtBv4dnjU7tQ",
        "outputId": "a6f5bfc8-2da0-4700-ba39-d98f6d942f85"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    text          label\n",
              "0      which medicine to apply for cuts?           cuts\n",
              "1         how do you treat a broken toe?     broken toe\n",
              "2                                 stings         stings\n",
              "3  how to help a drowning person in cpr?            cpr\n",
              "4             how to cure testicle pain?  testicle pain"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47c4c1f2-d1ed-468a-a650-fc2a60a351b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>which medicine to apply for cuts?</td>\n",
              "      <td>cuts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how do you treat a broken toe?</td>\n",
              "      <td>broken toe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stings</td>\n",
              "      <td>stings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how to help a drowning person in cpr?</td>\n",
              "      <td>cpr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how to cure testicle pain?</td>\n",
              "      <td>testicle pain</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47c4c1f2-d1ed-468a-a650-fc2a60a351b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47c4c1f2-d1ed-468a-a650-fc2a60a351b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47c4c1f2-d1ed-468a-a650-fc2a60a351b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. test dataframe"
      ],
      "metadata": {
        "id": "X1ktJffeVIBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZwWqjTLcVHHU",
        "outputId": "732c3088-7f28-4427-f94f-a05077fe7bd4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         text         label\n",
              "0   which medicine to take if i get sun burn?      sun burn\n",
              "1        what to do if i my nose is bleeding?    nose bleed\n",
              "2  is heat or ice better for a pulled muscle?       strains\n",
              "3                    how to cure insect bite?  insect bites\n",
              "4                      what to apply on cuts?          cuts"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c1d6e55-942a-48b4-8379-06cafc1e5752\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>which medicine to take if i get sun burn?</td>\n",
              "      <td>sun burn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what to do if i my nose is bleeding?</td>\n",
              "      <td>nose bleed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is heat or ice better for a pulled muscle?</td>\n",
              "      <td>strains</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how to cure insect bite?</td>\n",
              "      <td>insect bites</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what to apply on cuts?</td>\n",
              "      <td>cuts</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c1d6e55-942a-48b4-8379-06cafc1e5752')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c1d6e55-942a-48b4-8379-06cafc1e5752 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c1d6e55-942a-48b4-8379-06cafc1e5752');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. validatation dataframe"
      ],
      "metadata": {
        "id": "UkqLes8-VNPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DzNJKAAVVEeL",
        "outputId": "809b5614-57d3-47e6-e40c-42d9c92905e3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            text       label\n",
              "0              what to do if i get a broken toe?  broken toe\n",
              "1                   how to cure a mild headache?    headache\n",
              "2  which medicine to take if i get a snake bite?  snake bite\n",
              "3  which medicine to take if i get a broken toe?  broken toe\n",
              "4                        how do you treat faint?    fainting"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db792fe8-5e00-4800-beea-51ef8b37ff31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what to do if i get a broken toe?</td>\n",
              "      <td>broken toe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how to cure a mild headache?</td>\n",
              "      <td>headache</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>which medicine to take if i get a snake bite?</td>\n",
              "      <td>snake bite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>which medicine to take if i get a broken toe?</td>\n",
              "      <td>broken toe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how do you treat faint?</td>\n",
              "      <td>fainting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db792fe8-5e00-4800-beea-51ef8b37ff31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db792fe8-5e00-4800-beea-51ef8b37ff31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db792fe8-5e00-4800-beea-51ef8b37ff31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have text matched to labels, we can go ahead and save the `csv` files for these 3 different sets of data"
      ],
      "metadata": {
        "id": "cvjr1em9VYNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(os.path.join(base_dir, \"train.csv\"),  index = False, header = True)\n",
        "test_df.to_csv(os.path.join(base_dir, \"test.csv\"),  index = False, header = True)\n",
        "val_df.to_csv(os.path.join(base_dir, \"val.csv\"),  index = False, header = True)\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQlpvRx4VWum",
        "outputId": "ae0c8634-e552-4284-d8fb-7f74ba7725f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code cell we are going to count the examples that are in each set of our whole dataset."
      ],
      "metadata": {
        "id": "6_0O8AsVV0ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"Set\", \"Example(s)\"]\n",
        "\n",
        "examples = [\n",
        "    ['training', len(train_df)],\n",
        "    ['validation', len(val_df)],\n",
        "    ['testing', len(test_df)],\n",
        "    ['total', len(train_df) +  len(test_df) + len(val_df)],\n",
        "]\n",
        "\n",
        "tabulate_data(columns, examples, \"Exmples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXeApTx7Vp-m",
        "outputId": "7b247598-a37d-45fb-b01b-70875a134817"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+\n",
            "|         Exmples         |\n",
            "+------------+------------+\n",
            "| Set        | Example(s) |\n",
            "+------------+------------+\n",
            "| training   |        188 |\n",
            "| validation |         76 |\n",
            "| testing    |        112 |\n",
            "| total      |        376 |\n",
            "+------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Features and Labels\n",
        "Our fetures are the actual `text` in the dataframes which is the column named `text` and our labels will come from the column called `label`. In the following code cell we are going to read features and labels in a numpy arrays for each set."
      ],
      "metadata": {
        "id": "f5MGCJeBWMr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "train_texts = train_df.text.values\n",
        "train_labels = train_df.label.values\n",
        "\n",
        "# test\n",
        "test_texts = test_df.text.values\n",
        "test_labels = test_df.label.values\n",
        "\n",
        "# val\n",
        "val_texts = val_df.text.values\n",
        "val_labels = val_df.label.values"
      ],
      "metadata": {
        "id": "0OtJMI3tWDxP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Preprocessing\n",
        "In our text processing pipeline we need to do the following steps:\n",
        "\n",
        "1. tokenize sentences\n",
        "* this is the process of converting a sentence or text into senquence of word. For this process we are going to use a pre-trained model from spacy language model. You can read more about other tokenizers that you can use at [pytorch](https://pytorch.org/text/stable/data_utils.html).org.\n",
        "\n",
        "2. vocabulary\n",
        "We will to create a vocabulary based on our sentences that are in the train dataset. A `vocabulary` is esentially a `word` to `index` mapping that allows us to reference the word with their integer representation, since machine leaning models does not understand words. This vocabulary will be used during model training and also can be used at model inference.\n",
        "\n",
        "### Tokenizer\n",
        "In the following code cell we are going to geta a tokenier object that will convert a sentence into a sequence of word using the `spacy-en` language model. The reason we are using the english langauge model it's because our intents are in english."
      ],
      "metadata": {
        "id": "zn4H4nQPWh6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = data.utils.get_tokenizer('spacy', 'en')\n",
        "tokenizer(\"This is a boy.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKzRB6ERWb-Z",
        "outputId": "74233e78-4038-4dc5-ede7-2483cb675351"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'a', 'boy', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary\n",
        "In the following code cell we are going to create a `vocabulary` object from torchtext. This vocabulary takes in an `` of words to their count. So we are going to use the `Counter` module from `collections` to generate these counts from our train features.\n",
        "\n",
        "We are going to specify the `min_freq` to `2` meaning that the words that does not appear at least 2 times will be converted to unknown. We are also going to specify the special tokens during creation of the vocabulary object."
      ],
      "metadata": {
        "id": "6eg16gaXXYXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = Counter()\n",
        "for line in train_texts:\n",
        "    counter.update(tokenizer(line))\n",
        "\n",
        "#  our special tokens are (unknown, padding, start of sentence, end of sentence)\n",
        "vocabulary = vocab.vocab(counter, min_freq=2, specials=('<unk>', '<pad>', '<sos>', '<eos>'))"
      ],
      "metadata": {
        "id": "TGI6C9-8XETl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STOI - String To Integer\n",
        "This will be a dictionary that contains a string to integer mapping which will be our actual vocabulary. In the following code cell we are going to create object called `stoi` which is essentially a dictionary of word to index mapping. This dictionary will be used during training as well as during model inference."
      ],
      "metadata": {
        "id": "cTx0dEomYPXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = vocabulary.get_stoi()"
      ],
      "metadata": {
        "id": "P9qDNOS_XX-K"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Pipeline\n",
        "After our text has been tokenized we need a way of converting those words into numbers because machine leaning models understand numbers not words. That's where we the `text_pipeline` function comes into play. So this function takes in a sentence and tokenize it then converts each word to a number. Note that the word that does not exists in the vocabulay (`stoi`) will be converted to  an unkown `('<unk>')` token (0)."
      ],
      "metadata": {
        "id": "ERWg6ii7ZBR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_pipeline(x: str):\n",
        "  values = list()\n",
        "  tokens = tokenizer(x.lower()) # convert to lower case.\n",
        "  for token in tokens:\n",
        "    try:\n",
        "      v = stoi[token]\n",
        "    except KeyError as e:\n",
        "      v = stoi['<unk>']\n",
        "    values.append(v)\n",
        "  return values"
      ],
      "metadata": {
        "id": "76wRr0h0XX5U"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label pipeline\n",
        "Our labels for now are just textual. We also need to convert these labels into numbers. This is very simple what we need to do is to get all the uniqe labels and then create a `labels_vocab` which is a label to integer representation. which looks as follows:\n",
        "\n",
        "```json\n",
        "\"head injur\": 0,\n",
        "\"gastrointestinal problem\": 1,\n",
        "\"bruise\": 2,\n",
        "\"rectal bleedin\": 3,\n",
        "\"snake bit\": 4,\n",
        "\"abrasion\": 5,\n",
        "\"abdonominal pai\": 6,\n",
        "\"diarrhe\": 7,\n",
        "\"eye injur\": 8,\n",
        "\"cut\": 9,\n",
        "\"cp\": 10,\n",
        "\"heat strok\": 11,\n",
        "\"normal bleedin\": 12,\n",
        "\"vertig\": 13,\n",
        "\"testicle pai\": 14,\n",
        "\"seizur\": 15,\n",
        "\"sprain\": 16,\n",
        "\"drownin\": 17,\n",
        "\"pulled muscl\": 18,\n",
        "\"broken to\": 19,\n",
        "\"coug\": 20,\n",
        "\"splinte\": 21,\n",
        "\"chemical bur\": 22,\n",
        "\"faintin\": 23,\n",
        "\"frost bit\": 24,\n",
        "\"nasal congestio\": 25,\n",
        "\"sting\": 26,\n",
        "\"strain\": 27,\n",
        "\"woun\": 28,\n",
        "\"fractur\": 29,\n",
        "\"teet\": 30,\n",
        "\"poiso\": 31,\n",
        "\"animal bit\": 32,\n",
        "\"sun bur\": 33,\n",
        "\"skin problem\": 34,\n",
        "\"col\": 35,\n",
        "\"heat exhaustio\": 36,\n",
        "\"headach\": 37,\n",
        "\"feve\": 38,\n",
        "\"insect bite\": 39,\n",
        "\"nose blee\": 40,\n",
        "\"ras\": 41,\n",
        "\"sore throa\": 42,\n",
        "\"chokin\": 43}\n",
        "```\n",
        "\n",
        "> As you have noticed we have `44` labels which are tags that we need to be able to predict.\n",
        "\n",
        "The `label_pipeline` function will then takes in the label and then returns us an integer representation of that label."
      ],
      "metadata": {
        "id": "7T5oM8aIZqdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_dict = {k: v for v, k in enumerate(train_df.label.unique())}"
      ],
      "metadata": {
        "id": "-xdB9m-cXX0y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_pipeline = lambda x: labels_dict[x]"
      ],
      "metadata": {
        "id": "j8Ub0Wq4XXxd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our vocabularies for labels `labels_dict` and  features `stoi` we can then save thes files as they will be used suring model inference. We are going to save these files as `.json` files."
      ],
      "metadata": {
        "id": "0KSxxSUwbMLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(base_dir, \"vocab.json\"), 'w') as f:\n",
        "  f.write(json.dumps(stoi, indent=2))\n",
        "\n",
        "with open(os.path.join(base_dir, \"labels_dict.json\"), 'w') as f:\n",
        "  f.write(json.dumps(labels_dict, indent=2))\n",
        "\n",
        "print(\"Saved!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kpBXmdMbhOe",
        "outputId": "44062d5f-06ca-45fb-a006-da55fecdb0bb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained vectors\n",
        "In the following code cell we are going to download the predtrained word vectors. We are going to use the `GloVe.6B.100d`. These are pretrained vectors that were trained with about `~6B` words and have a vector representation of a word in `100` dimension for each word."
      ],
      "metadata": {
        "id": "D-s0S-pza939"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "glove_vectors = vocab.GloVe('6B', dim=EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "Mtrb3ctoXXsW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Embedding matrix\n",
        "Now that we have our glove vectors we need to costomize them so that they fit our use case. We are going to create an embedding matrix that suits the our vocabulary. So essentially this embedding matrix will be the word to vector mapping for all the words that arein our vocabulary."
      ],
      "metadata": {
        "id": "Kc_GWFnQcYmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(stoi)\n",
        "EMBEDDING_MATRIX= torch.zeros([VOCAB_SIZE, EMBEDDING_DIM])\n",
        "for i, word in enumerate(vocabulary.get_itos()):\n",
        "  EMBEDDING_MATRIX[i] = glove_vectors[word]"
      ],
      "metadata": {
        "id": "BeVKb-33a9dH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the followig code cell we are going to check the embedding matrix for the word `\"the\"`."
      ],
      "metadata": {
        "id": "y9Tr8ACuciDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_MATRIX[stoi['the']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84DLGctra9aF",
        "outputId": "8db83285-ba0c-4e94-f2bc-154024d63ed8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
              "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
              "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
              "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
              "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
              "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
              "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
              "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
              "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
              "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
              "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
              "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
              "        -0.5203, -0.1459,  0.8278,  0.2706])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Dataset for Training\n",
        "\n",
        "In the following code cell we are going to create a dataset class called `FARBDataset`. This dataset will takes in the labels and the text of a set."
      ],
      "metadata": {
        "id": "qzFJ0SZZcrhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FARBDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, labels, text):\n",
        "    super(FARBDataset, self).__init__()\n",
        "    self.labels = labels\n",
        "    self.text = text\n",
        "      \n",
        "  def __getitem__(self, index):\n",
        "    return self.labels[index], self.text[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.labels)"
      ],
      "metadata": {
        "id": "g3e35_Aza9W6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### collate_fn\n",
        "We are going to create a collate function called `tokenize_batch`. This function actually takes in a `batch` and does the preprocessing of the text and labels. This function will be passed to the `DataLoader` class to do the preprocessing of features and labels.\n",
        "\n",
        "`tokenize_batch` function:\n",
        "\n",
        "* this function takes in a batch in each set and convert the features and labels to integer representation. It goes ahead and `pad` and `truncate` the sequence to the same `length` and returns `labels` and `features`."
      ],
      "metadata": {
        "id": "AP49l5SIc8YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_batch(batch, max_len=100, padding=\"pre\"):\n",
        "  assert padding==\"pre\" or padding==\"post\", \"the padding can be either pre or post\"\n",
        "  labels_list, text_list = [], []\n",
        "  for _label, _text in batch:\n",
        "    labels_list.append(label_pipeline(_label))\n",
        "    text_holder = torch.zeros(max_len, dtype=torch.int32)\n",
        "    processed_text = torch.tensor(text_pipeline(_text.lower()), dtype=torch.int32)\n",
        "    pos = min(max_len, len(processed_text))\n",
        "    if padding == \"pre\":\n",
        "      text_holder[:pos] = processed_text[:pos]\n",
        "    else:\n",
        "      text_holder[-pos:] = processed_text[-pos:]\n",
        "    text_list.append(text_holder.unsqueeze(dim=0))\n",
        "  #  the labels will be torch long tensors since it is a multi-class classification.\n",
        "  return torch.LongTensor(labels_list), torch.cat(text_list, dim=0)"
      ],
      "metadata": {
        "id": "YzOXdOcka9UA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasets\n",
        "In the following code cell we are going to create the datasets for all our three sets using the `FARBDataset` class."
      ],
      "metadata": {
        "id": "BftA18_edart"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = FARBDataset(train_labels, train_texts)\n",
        "test_dataset = FARBDataset(test_labels, test_texts)\n",
        "val_dataset = FARBDataset(val_labels, val_texts)"
      ],
      "metadata": {
        "id": "tPaNeJOVdVrt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterators\n",
        "In the following code cell we are going to create loaders using the `DataLoader` class from `torch.utils.data` for our `3` sets. We are going to use the `batch_size` of `128` and our `collate_function` is `tokenize_batch`. For the validation and testing dataset we are going to set the shuffle to `False` because there's no need fo us to shuffle these examples."
      ],
      "metadata": {
        "id": "jLrPPmq2dpKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=tokenize_batch)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=tokenize_batch)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=tokenize_batch)"
      ],
      "metadata": {
        "id": "aFhmjJ0qdiXk"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking a single Batch Data"
      ],
      "metadata": {
        "id": "khiKQFrJd58l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lbl, txt = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "Pfq_L5KNd-GT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labels in the first batch."
      ],
      "metadata": {
        "id": "6EZVZH0hd-C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lbl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-6-3P76d9_s",
        "outputId": "190dd8ff-dcdf-4a8f-ad99-eda0aa60d88f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([17, 41,  2, 35, 17, 24, 17, 30, 42,  1,  0, 32, 26, 18, 12, 36, 27,  0,\n",
              "        38, 30, 20, 27, 35, 10, 40, 38, 19,  8, 35, 34,  0, 18, 42, 43, 17, 29,\n",
              "        10, 34, 23, 21,  0, 22, 25, 13, 23, 39,  5, 35, 17,  5, 16, 36, 17,  7,\n",
              "        21,  5,  3, 14, 15,  1, 21, 38, 33, 12, 22,  1, 40, 19, 10,  3, 43, 26,\n",
              "        29, 37, 31, 23, 18, 24, 15, 13, 31, 15, 27, 13, 31,  1, 28,  6, 28, 33,\n",
              "        18,  6, 20, 29, 16, 11,  4, 40, 42,  9, 37,  8, 37, 33,  3, 25,  9, 14,\n",
              "        11, 13,  2, 14,  5, 29, 10, 14,  7, 33, 24,  3, 41, 28,  2, 34, 15, 16,\n",
              "        42, 43])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first sentence in the batch."
      ],
      "metadata": {
        "id": "i-ho13LdeNC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12CNt4ffeM-b",
        "outputId": "1bce802d-c129-4afa-ea4d-9e184756a2ad"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4,  5,  6,  7,  8, 51, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Creation\n",
        "Now that we have our loaders we can now create a model. The model that we are going to create is called `FARBModel`.  As mentioned we are going to use `Convulutional Neural Networks (CNN)` to build this model."
      ],
      "metadata": {
        "id": "WlFHj0dBeYlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FARBModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "            dropout, pad_idx):\n",
        "    super(FARBModel, self).__init__()\n",
        "    self.embedding = nn.Sequential(\n",
        "        nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "    )\n",
        "    self.convs = nn.Sequential(\n",
        "        nn.ModuleList([\n",
        "            nn.Conv1d(\n",
        "                in_channels = embedding_dim, \n",
        "                out_channels = n_filters, \n",
        "                kernel_size = fs\n",
        "              ) for fs in filter_sizes\n",
        "        ])\n",
        "    )\n",
        "    self.out = nn.Sequential(\n",
        "        nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)  \n",
        "    embedded = embedded.permute(0, 2, 1)\n",
        "    conved = [F.relu(conv(embedded)) for conv in self.convs[0]]\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "    return self.out(cat)"
      ],
      "metadata": {
        "id": "KUWtbBIceM7d"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Instance\n",
        "In the following code cell we are going to create a model instance."
      ],
      "metadata": {
        "id": "z509c1kIe4b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(stoi) \n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = len(labels_dict)\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = stoi['<pad>'] \n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3, 4, 5]\n",
        "\n",
        "farb_model = FARBModel(\n",
        "    INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX\n",
        ").to(device)\n",
        "farb_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F0hcAj4eMtn",
        "outputId": "b4056bd4-302e-4313-e4e4-c8f7ed07b4f0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FARBModel(\n",
              "  (embedding): Sequential(\n",
              "    (0): Embedding(98, 100, padding_idx=1)\n",
              "  )\n",
              "  (convs): Sequential(\n",
              "    (0): ModuleList(\n",
              "      (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
              "      (1): Conv1d(100, 100, kernel_size=(4,), stride=(1,))\n",
              "      (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
              "    )\n",
              "  )\n",
              "  (out): Sequential(\n",
              "    (0): Linear(in_features=300, out_features=44, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Counting Model Parameters\n",
        "In the following code cell we are going to count the model parameters."
      ],
      "metadata": {
        "id": "5Q3sHK_rfLch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models.model_params(farb_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6aaOSVbd98d",
        "outputId": "36c8217e-fc5a-4c15-edc4-6fcdbecb58aa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOTAL MODEL PARAMETERS: \t143,344\n",
            "TOTAL TRAINABLE PARAMETERS: \t143,344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Embedding Vectors\n",
        "In the following code cell we are going to load the pretained custom vectors in our embedding layer. We are going to load the embedding vectors tha suits our data using the `farb_model.embedding[0].weight.data.copy_(EMBEDDING_MATRIX)` as follows:"
      ],
      "metadata": {
        "id": "ixhvbZrnfa1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "farb_model.embedding[0].weight.data.copy_(EMBEDDING_MATRIX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWmuwFOCd959",
        "outputId": "a8256456-ca4e-4214-b822-8a2bd342eb56"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        ...,\n",
              "        [-0.3809, -0.3992,  0.3630,  ..., -0.0667,  0.7872, -0.9540],\n",
              "        [-0.0788,  0.6902,  0.4748,  ..., -0.2634, -0.6086, -0.1911],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer and Criterion\n",
        "\n",
        "In the following code cell we are going to define the `optimizer` and `criterion`. For the `optimizer` we are going to use the `Adam` optimizer with default parameters and for the criterion we are going to use the `CrossEntropyLoss()` function since this is a `multi-class` classification."
      ],
      "metadata": {
        "id": "61W2JkF3f0V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(farb_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "bHJL3sJyd93Z"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code cell we are going to create our `categorical_accuracy` function, which is a function that calulates the the catecorical accuracy between the predicted labels and real labels."
      ],
      "metadata": {
        "id": "ifivhpn5gITZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "  top_pred = preds.argmax(1, keepdim = True)\n",
        "  correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "  acc = correct.float() / y.shape[0]\n",
        "  return acc"
      ],
      "metadata": {
        "id": "7LAsdm-DgEbF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Evaluate functions\n",
        "In the following code cell we are going to create our `train` and `evalute` functions:"
      ],
      "metadata": {
        "id": "JQZ49pfrgSPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss,epoch_acc = 0, 0\n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    y, X = batch\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions = model(X).squeeze(1)\n",
        "    loss = criterion(predictions, y)\n",
        "    acc = categorical_accuracy(predictions, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss,epoch_acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      y, X = batch\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      predictions = model(X).squeeze(1)\n",
        "      loss = criterion(predictions, y)\n",
        "      acc = categorical_accuracy(predictions, y)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "lkZUeIWJgPBx"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop\n",
        "In the following code cell we are going to run the training loop. We are going to save the model when the loss decreased."
      ],
      "metadata": {
        "id": "uSIas6DcgfMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 200\n",
        "MODEL_NAME = 'farb-model.pt'\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start = time.time()\n",
        "  train_loss, train_acc = train(farb_model, train_loader, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(farb_model, val_loader, criterion)\n",
        "  title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} {'saving best model...' if valid_loss < best_valid_loss else 'not saving...'}\"\n",
        "  if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(farb_model.state_dict(), MODEL_NAME)\n",
        "  end = time.time()\n",
        "  data = [\n",
        "       [\"Training\", f'{train_loss:.3f}', f'{train_acc:.3f}', f\"{hms_string(end - start)}\" ],\n",
        "       [\"Validation\", f'{valid_loss:.3f}', f'{valid_acc:.3f}', \"\" ],       \n",
        "   ]\n",
        "  columns = [\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"]\n",
        "  tabulate_data(columns, data, title)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DLKNbVmgba4",
        "outputId": "d1cabb65-d3a0-4257-e7ea-9a0b87f43906"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------+\n",
            "|     EPOCH: 01/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 3.803 |    0.016 | 0:00:02.10 |\n",
            "| Validation | 3.696 |    0.053 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 02/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 3.678 |    0.053 | 0:00:00.06 |\n",
            "| Validation | 3.602 |    0.158 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 03/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 3.616 |    0.117 | 0:00:00.05 |\n",
            "| Validation | 3.515 |    0.250 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 04/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 3.525 |    0.176 | 0:00:00.07 |\n",
            "| Validation | 3.430 |    0.289 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 05/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 3.423 |    0.234 | 0:00:00.06 |\n",
            "| Validation | 3.339 |    0.382 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 06/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 3.342 |    0.252 | 0:00:00.06 |\n",
            "| Validation | 3.239 |    0.474 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 07/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 3.220 |    0.363 | 0:00:00.06 |\n",
            "| Validation | 3.138 |    0.592 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 08/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 3.146 |    0.399 | 0:00:00.06 |\n",
            "| Validation | 3.030 |    0.711 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 09/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 3.054 |    0.541 | 0:00:00.06 |\n",
            "| Validation | 2.916 |    0.724 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 10/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 2.911 |    0.551 | 0:00:00.05 |\n",
            "| Validation | 2.802 |    0.750 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 11/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 2.841 |    0.526 | 0:00:00.05 |\n",
            "| Validation | 2.683 |    0.789 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 12/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 2.655 |    0.610 | 0:00:00.06 |\n",
            "| Validation | 2.560 |    0.776 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 13/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 2.598 |    0.710 | 0:00:00.06 |\n",
            "| Validation | 2.434 |    0.816 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 14/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 2.491 |    0.689 | 0:00:00.05 |\n",
            "| Validation | 2.309 |    0.829 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 15/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 2.306 |    0.738 | 0:00:00.05 |\n",
            "| Validation | 2.180 |    0.842 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 16/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 2.171 |    0.782 | 0:00:00.05 |\n",
            "| Validation | 2.050 |    0.855 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 17/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 2.078 |    0.794 | 0:00:00.07 |\n",
            "| Validation | 1.922 |    0.895 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 18/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 2.008 |    0.754 | 0:00:00.05 |\n",
            "| Validation | 1.792 |    0.921 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 19/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.803 |    0.815 | 0:00:00.06 |\n",
            "| Validation | 1.667 |    0.934 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 20/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.701 |    0.873 | 0:00:00.05 |\n",
            "| Validation | 1.546 |    0.934 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 21/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.594 |    0.840 | 0:00:00.05 |\n",
            "| Validation | 1.432 |    0.934 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 22/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.481 |    0.871 | 0:00:00.06 |\n",
            "| Validation | 1.321 |    0.934 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 23/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.417 |    0.850 | 0:00:00.05 |\n",
            "| Validation | 1.216 |    0.947 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 24/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.318 |    0.907 | 0:00:00.06 |\n",
            "| Validation | 1.117 |    0.947 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 25/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.218 |    0.907 | 0:00:00.05 |\n",
            "| Validation | 1.024 |    0.947 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 26/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.176 |    0.928 | 0:00:00.05 |\n",
            "| Validation | 0.936 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 27/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.032 |    0.933 | 0:00:00.05 |\n",
            "| Validation | 0.857 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 28/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.965 |    0.940 | 0:00:00.05 |\n",
            "| Validation | 0.786 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 29/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.833 |    0.952 | 0:00:00.05 |\n",
            "| Validation | 0.722 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 30/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.816 |    0.940 | 0:00:00.05 |\n",
            "| Validation | 0.663 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 31/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.746 |    0.940 | 0:00:00.05 |\n",
            "| Validation | 0.609 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 32/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.719 |    0.968 | 0:00:00.05 |\n",
            "| Validation | 0.560 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 33/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.685 |    0.947 | 0:00:00.05 |\n",
            "| Validation | 0.514 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 34/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.655 |    0.959 | 0:00:00.06 |\n",
            "| Validation | 0.473 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 35/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.630 |    0.934 | 0:00:00.06 |\n",
            "| Validation | 0.437 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 36/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.510 |    0.976 | 0:00:00.05 |\n",
            "| Validation | 0.404 |    0.974 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 37/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.522 |    0.968 | 0:00:00.04 |\n",
            "| Validation | 0.376 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 38/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.467 |    0.980 | 0:00:00.04 |\n",
            "| Validation | 0.350 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 39/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.428 |    0.977 | 0:00:00.04 |\n",
            "| Validation | 0.326 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 40/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.404 |    0.984 | 0:00:00.04 |\n",
            "| Validation | 0.302 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 41/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.389 |    0.977 | 0:00:00.04 |\n",
            "| Validation | 0.280 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 42/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.385 |    0.980 | 0:00:00.04 |\n",
            "| Validation | 0.259 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 43/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.331 |    0.988 | 0:00:00.04 |\n",
            "| Validation | 0.240 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 44/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.343 |    0.963 | 0:00:00.04 |\n",
            "| Validation | 0.225 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 45/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.332 |    0.984 | 0:00:00.04 |\n",
            "| Validation | 0.210 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 46/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.305 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.198 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 47/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.288 |    0.984 | 0:00:00.03 |\n",
            "| Validation | 0.187 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 48/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.311 |    0.967 | 0:00:00.03 |\n",
            "| Validation | 0.176 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 49/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.258 |    0.976 | 0:00:00.04 |\n",
            "| Validation | 0.167 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 50/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.230 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.158 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 51/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.245 |    0.979 | 0:00:00.03 |\n",
            "| Validation | 0.152 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 52/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.238 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.145 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 53/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.228 |    0.983 | 0:00:00.04 |\n",
            "| Validation | 0.137 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 54/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.244 |    0.983 | 0:00:00.04 |\n",
            "| Validation | 0.129 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 55/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.195 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.121 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 56/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.151 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.114 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 57/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.194 |    0.984 | 0:00:00.04 |\n",
            "| Validation | 0.108 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 58/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.183 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.103 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 59/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.153 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.098 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 60/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.155 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.093 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 61/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.166 |    0.984 | 0:00:00.03 |\n",
            "| Validation | 0.089 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 62/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.187 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.085 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 63/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.174 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.081 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 64/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.128 |    0.992 | 0:00:00.05 |\n",
            "| Validation | 0.077 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 65/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.145 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.074 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 66/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.145 |    0.988 | 0:00:00.04 |\n",
            "| Validation | 0.071 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 67/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.151 |    0.983 | 0:00:00.04 |\n",
            "| Validation | 0.067 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 68/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.134 |    0.992 | 0:00:00.04 |\n",
            "| Validation | 0.064 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 69/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.106 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.062 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 70/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.122 |    0.988 | 0:00:00.04 |\n",
            "| Validation | 0.060 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 71/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.122 |    1.000 | 0:00:00.04 |\n",
            "| Validation | 0.057 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 72/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.114 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.055 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 73/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.108 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.054 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 74/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.102 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.052 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 75/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.095 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.051 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 76/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.127 |    0.988 | 0:00:00.04 |\n",
            "| Validation | 0.049 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 77/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.095 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.047 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 78/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.113 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.046 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 79/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.114 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.044 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 80/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.106 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.042 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 81/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.100 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.041 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 82/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.076 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.040 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 83/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.097 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.039 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 84/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.085 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.038 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 85/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.098 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.037 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 86/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.086 |    0.988 | 0:00:00.04 |\n",
            "| Validation | 0.037 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 87/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.080 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.036 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 88/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.096 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.035 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 89/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.082 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.034 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 90/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.071 |    0.992 | 0:00:00.04 |\n",
            "| Validation | 0.034 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 91/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.092 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.033 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 92/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.070 |    1.000 | 0:00:00.04 |\n",
            "| Validation | 0.032 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 93/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.067 |    0.996 | 0:00:00.04 |\n",
            "| Validation | 0.032 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 94/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.066 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.030 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 95/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.061 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.029 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 96/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.064 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.028 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 97/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.083 |    0.983 | 0:00:00.03 |\n",
            "| Validation | 0.028 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 98/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.087 |    0.983 | 0:00:00.03 |\n",
            "| Validation | 0.027 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 99/200 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.067 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.028 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 100/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.057 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.028 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 101/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.067 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.028 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 102/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.053 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.028 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 103/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.061 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.028 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 104/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.058 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.028 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 105/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.060 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.028 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 106/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.056 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.027 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 107/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.056 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.027 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 108/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.049 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.027 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 109/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.061 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.026 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 110/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.047 |    1.000 | 0:00:00.04 |\n",
            "| Validation | 0.025 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 111/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.067 |    1.000 | 0:00:00.04 |\n",
            "| Validation | 0.025 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 112/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.055 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.024 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 113/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.051 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.022 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 114/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.053 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.021 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 115/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.075 |    0.992 | 0:00:00.04 |\n",
            "| Validation | 0.020 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 116/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.070 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 117/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.052 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 118/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.066 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.020 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 119/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.047 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.022 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 120/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.069 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.023 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 121/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.060 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.023 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 122/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.048 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.022 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 123/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.046 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.022 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 124/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.039 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.020 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 125/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.044 |    1.000 | 0:00:00.04 |\n",
            "| Validation | 0.020 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 126/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.040 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 127/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.051 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 128/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.056 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.018 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 129/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.046 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.016 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 130/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.052 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.015 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 131/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.056 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 132/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.034 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 133/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.063 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 134/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.050 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 135/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.035 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.015 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 136/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.049 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.017 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 137/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.059 |    0.992 | 0:00:00.04 |\n",
            "| Validation | 0.018 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 138/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.041 |    0.992 | 0:00:00.04 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 139/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.053 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 140/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.050 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 141/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.038 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 142/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.035 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 143/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.042 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 144/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.041 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 145/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.049 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 146/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.044 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.018 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 147/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.046 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.018 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 148/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.037 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.017 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 149/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.041 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.016 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 150/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.047 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.017 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 151/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.049 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 152/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.048 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.020 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 153/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.036 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.020 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 154/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.046 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 155/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.054 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.018 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 156/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.037 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.017 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 157/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.040 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.017 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 158/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.040 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 159/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.033 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 160/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.056 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.019 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 161/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.044 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.017 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 162/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.033 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.016 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 163/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.047 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 164/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.038 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.013 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 165/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.028 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.012 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 166/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.043 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.011 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 167/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.041 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.011 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 168/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.056 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.011 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 169/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.042 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.013 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 170/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.039 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 171/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.053 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 172/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.046 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.013 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 173/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.023 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.012 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 174/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.028 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.011 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 175/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.046 |    0.992 | 0:00:00.04 |\n",
            "| Validation | 0.011 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 176/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.029 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.010 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 177/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.045 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.009 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|    EPOCH: 178/200 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.029 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.009 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 179/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.034 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.010 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 180/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.036 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.011 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 181/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.035 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.012 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 182/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.030 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.013 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 183/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.044 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.013 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 184/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.032 |    0.988 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 185/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.028 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.015 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 186/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.037 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.015 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 187/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.030 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.015 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 188/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.027 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 189/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.034 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 190/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.034 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 191/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.045 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 192/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.033 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 193/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.033 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.012 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 194/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.023 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.012 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 195/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.037 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.012 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 196/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.025 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.012 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 197/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.021 |    1.000 | 0:00:00.03 |\n",
            "| Validation | 0.011 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 198/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.024 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.012 |    1.000 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 199/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.030 |    0.992 | 0:00:00.03 |\n",
            "| Validation | 0.013 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 200/200 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.022 |    0.996 | 0:00:00.03 |\n",
            "| Validation | 0.014 |    0.987 |            |\n",
            "+------------+-------+----------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the best model.\n",
        "In the following code cell we are going to evaluate the best model using on the `test` data as follows:"
      ],
      "metadata": {
        "id": "Tt6w6iSNhBsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = [\"Set\", \"Loss\", \"Accuracy\", \"ETA (time)\"]\n",
        "farb_model.load_state_dict(torch.load(MODEL_NAME))\n",
        "test_loss, test_acc = evaluate(farb_model, test_loader, criterion)\n",
        "title = \"Model Evaluation Summary\"\n",
        "data_rows = [[\"Test\", f'{test_loss:.3f}', f'{test_acc * 100:.2f}%', \"\"]]\n",
        "\n",
        "tabulate_data(column_names, data_rows, title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjI79Ryhg0oz",
        "outputId": "491bbcc8-de4d-4bb6-b664-7caf60e14461"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------+\n",
            "|       Model Evaluation Summary       |\n",
            "+------+-------+----------+------------+\n",
            "| Set  |  Loss | Accuracy | ETA (time) |\n",
            "+------+-------+----------+------------+\n",
            "| Test | 0.034 |   99.11% |            |\n",
            "+------+-------+----------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Inference\n",
        "In the following code cell we are going to make predictions with the best model. We will have the function called `inference_preprocess_text` which is a function that process the text for inference."
      ],
      "metadata": {
        "id": "KwHVSqWqhRDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_preprocess_text(text, max_len=100, padding=\"pre\"):\n",
        "  assert padding==\"pre\" or padding==\"post\", \"the padding can be either pre or post\"\n",
        "  text_holder = torch.zeros(max_len, dtype=torch.int32) # fixed size tensor of max_len with  = 0\n",
        "  processed_text = torch.tensor(text_pipeline(text), dtype=torch.int32)\n",
        "  pos = min(max_len, len(processed_text))\n",
        "  if padding == \"pre\":\n",
        "    text_holder[:pos] = processed_text[:pos]\n",
        "  else:\n",
        "    text_holder[-pos:] = processed_text[-pos:]\n",
        "  text_list= text_holder.unsqueeze(dim=0)\n",
        "  return text_list"
      ],
      "metadata": {
        "id": "b92dGb5-hI_I"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting Tags\n",
        "In the following code cell we are going to create a function that predicts the `tags` given a certain `pattern` called `predict_tags`."
      ],
      "metadata": {
        "id": "zmvxwzw8hp35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Prediction:\n",
        "  def __init__(self, pattern: str, tag: str, tagId: int, confidence: float):\n",
        "    self.pattern = pattern\n",
        "    self.tag = tag\n",
        "    self.tagId = tagId\n",
        "    self.confidence = confidence\n",
        "\n",
        "  def __repr__(self) -> str:\n",
        "    return f\"<FARB Preciction: {self.tag}>\"\n",
        "\n",
        "  def __str__(self) -> str:\n",
        "    return f\"<FARB Preciction: {self.tag}>\"\n",
        "\n",
        "  def to_json(self):\n",
        "    return {\n",
        "        'pattern':  self.pattern,\n",
        "        'tag':  self.tag,\n",
        "        'tagId':  self.tagId,\n",
        "        'confidence':  self.confidence,\n",
        "    }"
      ],
      "metadata": {
        "id": "INOb_R2XhozJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tag(model, sentence, device): \n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    tensor = inference_preprocess_text(sentence).to(device)\n",
        "    probabilities = torch.softmax(model(tensor).squeeze(0), dim=0)\n",
        "    prediction = torch.argmax(probabilities)\n",
        "    prediction = prediction.detach().cpu().item()\n",
        "    tags = {v:k for k, v in labels_dict.items()}\n",
        "    tag = tags[prediction]\n",
        "   \n",
        "    return Prediction(\n",
        "        sentence.lower(), tag, int(prediction), float(round(probabilities[prediction].item(), 2))\n",
        "    )"
      ],
      "metadata": {
        "id": "O3Nk45oOijTX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_tag(farb_model, \"How to cure Cuts?\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FotmLIEkqmE",
        "outputId": "a354f384-ab9b-4732-a8cd-63d4b99e3fe7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FARB Preciction: cuts>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the model.\n",
        "We are going to download the model"
      ],
      "metadata": {
        "id": "hZ1w-3vTlkXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "S0Yn_GM3llLp",
        "outputId": "73a97a59-4151-46f4-f370-495877b2b60a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d781cbb2-af56-4767-8725-d88374d1045a\", \"farb-model.pt\", 576556)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}