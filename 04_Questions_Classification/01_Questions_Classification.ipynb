{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Questions_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwFkL0ZK1L-X"
      },
      "source": [
        "### Questions Classification Custom dataset.\n",
        "\n",
        "In this notebook we are going to learn how to load the questions dataset using torchtext and prepare it for sentiment classification in pytorch. We are going to use [this series](https://github.com/CrispenGari/pytorch-python/tree/main/09_TorchText/02_Sentiment_Analyisis_Series) as the base of our code.\n",
        "\n",
        "In this series we will learn the following:\n",
        "\n",
        "1. Creating our own dataset using torchtext\n",
        "2. Using RNN and packed padded sequences for sentiment analysis\n",
        "3. Using Fasttext for sentiment analyisis\n",
        "4. Using ConvNet's to do sentiment analyisis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl1NzpCf2rlk"
      },
      "source": [
        "### 1. Data preparation using torchtext.\n",
        "* Refer to [this](https://github.com/CrispenGari/pytorch-python/blob/main/09_TorchText/02_Sentiment_Analyisis_Series/09_TorchText_with_custom_data.ipynb)  and [this](https://github.com/CrispenGari/pytorch-python/blob/main/09_TorchText/01_Introduction/01_TorchText.ipynb) notebook for claryification.\n",
        "\n",
        "I've already uploaded the files which we are going to use in my google drive. So the first thing we should do is to mount the google drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5bfB7PC1HRJ",
        "outputId": "3e6caefe-f779-4c68-fc47-5472a2566f5d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpcZ-TG63VID"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qpE80WdY3TgV",
        "outputId": "eb76acc1-994c-4d1f-8897-28238b1106c3"
      },
      "source": [
        "import time\n",
        "from prettytable import PrettyTable\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch, os, random\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.9.0+cu102'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAkhI0Ns3wiU"
      },
      "source": [
        "### Setting up the seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwYV_hrz3sSB"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deteministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IIGYz38RoEE"
      },
      "source": [
        "### Splitting sets\n",
        "We are going to create 3 files which are:\n",
        "\n",
        "```\n",
        "train.csv\n",
        "test.csv\n",
        "val.csv\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaeqCSHkRIBF"
      },
      "source": [
        "base_path = '/content/drive/MyDrive/NLP Data/questions-classification'\n",
        "file_path = os.path.join(base_path, \"Question_Classification_Dataset.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ifvUNxQdSEk6",
        "outputId": "cec130d9-5046-4a39-b22f-9a1df5c8477f"
      },
      "source": [
        "dataframe = pd.read_csv(file_path)\n",
        "dataframe.head(1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Questions</th>\n",
              "      <th>Category0</th>\n",
              "      <th>Category1</th>\n",
              "      <th>Category2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>How did serfdom develop in and then leave Russ...</td>\n",
              "      <td>DESCRIPTION</td>\n",
              "      <td>DESC</td>\n",
              "      <td>manner</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... Category2\n",
              "0           0  ...    manner\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am9nGu-hSKpB",
        "outputId": "138493e7-efe6-4ff7-dcfa-b6420e3ca304"
      },
      "source": [
        "dataframe.isnull().any()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0    False\n",
              "Questions     False\n",
              "Category0     False\n",
              "Category1     False\n",
              "Category2     False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfQzATNFSPgn"
      },
      "source": [
        "### Splitting the sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYogEqVUSR4h"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSBTdpYzSXdh",
        "outputId": "c8611cb0-8913-4f4b-f3a5-f62a5f2c9b5c"
      },
      "source": [
        "train, valid = train_test_split(dataframe, test_size=.05)\n",
        "valid, test = train_test_split(valid, test_size=.10)\n",
        "len(train), len(test), len(valid)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5179, 28, 245)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8hlzgh4Sp5m"
      },
      "source": [
        "### Saving the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUs7PySKSsmL"
      },
      "source": [
        "train_path = 'train.csv'\n",
        "test_path = 'test.csv'\n",
        "val_path = 'val.csv'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9OtPoGrSvkp",
        "outputId": "f7a0a75e-347d-4a37-d88c-a557b227ef3d"
      },
      "source": [
        "if not os.path.exists(os.path.join(base_path, \"pytorch\")):\n",
        "  os.makedirs(os.path.join(base_path, \"pytorch\"))\n",
        "\n",
        "valid.to_csv(os.path.join(base_path, \"pytorch\", val_path), index=False)\n",
        "test.to_csv(os.path.join(base_path, \"pytorch\", test_path), index=False)\n",
        "train.to_csv(os.path.join(base_path, \"pytorch\", train_path), index=False)\n",
        "\n",
        "print(\"files saved\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "files saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoTx8u2J344-"
      },
      "source": [
        "### Loading files.\n",
        "\n",
        "Now we have 3 files for three sets that were created which are:\n",
        "```\n",
        "train.csv\n",
        "test.csv\n",
        "val.csv\n",
        "```\n",
        "\n",
        "We are going to use torchtext to load these files.\n",
        "\n",
        "### Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdKKgohm34DD"
      },
      "source": [
        "files_path = '/content/drive/MyDrive/NLP Data/questions-classification/pytorch'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw7OEiJUGsa0"
      },
      "source": [
        "### Creating `.json` files for all the three sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBBoZ8MqGsGR"
      },
      "source": [
        "train_path_json = 'train.json'\n",
        "test_path_json = 'test.json'\n",
        "val_path_json = 'val.json'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVOskerXG67Z"
      },
      "source": [
        "### Creating dataframes for each set so that we can easily convert the files to `.json` files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4DCaeTcHGYw",
        "outputId": "7d03b979-153d-4552-da59-92140e48f417"
      },
      "source": [
        "train_dataframe = pd.read_csv(os.path.join(files_path, train_path))\n",
        "test_dataframe = pd.read_csv(os.path.join(files_path, test_path))\n",
        "val_dataframe = pd.read_csv(os.path.join(files_path, val_path))\n",
        "\n",
        "train_dataframe.to_json(os.path.join(files_path, train_path_json),  orient=\"records\", lines=True)\n",
        "test_dataframe.to_json(os.path.join(files_path, test_path_json),  orient=\"records\", lines=True)\n",
        "val_dataframe.to_json(os.path.join(files_path, val_path_json),  orient=\"records\", lines=True)\n",
        "\n",
        "print(\"saved!\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7YMbs8a43jD"
      },
      "source": [
        "### Creating the Fields.\n",
        "\n",
        "In this first notebook our task is simple we are going to classify one label based on a single question. So we need a `Label` and a `Text` Field. On the `Text` field we are going to pass the arg `include_lengths=True` since we are going to used packed padded sequences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_xUMByB5tGa"
      },
      "source": [
        "from torchtext.legacy import data, datasets"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RaqW-b-4lJJ"
      },
      "source": [
        "TEXT = data.Field(\n",
        "   tokenize=\"spacy\",\n",
        "   include_lengths = True,\n",
        "  tokenizer_language = 'en_core_web_sm',\n",
        ")\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugU18S_7tAS"
      },
      "source": [
        "fields = {\n",
        "  \"Questions\": ('text', TEXT),\n",
        "  \"Category1\": ('label', LABEL)\n",
        "}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiNOBqFO8pyo"
      },
      "source": [
        "### Creating the dataset.\n",
        "\n",
        "We ar going to use the `TabularDataset.split()` to create the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAgiWOoh8mWO"
      },
      "source": [
        "train_data, val_data, test_data = data.TabularDataset.splits(\n",
        "   files_path,\n",
        "   train=train_path_json,\n",
        "   test= test_path_json,\n",
        "   validation= val_path_json,\n",
        "   format = \"json\",\n",
        "   fields=fields\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f4YEu-fQ1WK",
        "outputId": "55ed8d3e-e92a-4a5d-b2a4-81e18095c306"
      },
      "source": [
        "len(train_data), len(test_data), len(val_data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5179, 28, 245)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ1oWIQW9KWn",
        "outputId": "ec7ca556-eea1-43ea-8776-d1d56d055c25"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['What', 'is', 'the', 'name', 'of', 'Miss', 'India', '1994', '?'], 'label': 'HUM'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t-0JC1U-l73"
      },
      "source": [
        "### Building the Vocabulary and Loading the `pretrained` word vectors.\n",
        "\n",
        "We are going to use the `glove.6B.100d` word vectors which was trained with 6 billion words and each word is a 100 dimesional vector.\n",
        "\n",
        "**Note** We should only build the vocabulary on the `train` dataset only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4p3m1_--WYU"
      },
      "source": [
        "MAX_VOCAB_SIZE = 100_000_000\n",
        "\n",
        "TEXT.build_vocab(\n",
        "    train_data,\n",
        "     max_size = MAX_VOCAB_SIZE,\n",
        "    vectors = \"glove.6B.100d\",\n",
        "    unk_init = torch.Tensor.normal_\n",
        ")\n",
        "LABEL.build_vocab(train_data)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFukx38W_aNv"
      },
      "source": [
        "### Device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYPGTIZ7_Zet",
        "outputId": "9cfa38ff-f3f9-4d25-d0a3-8a55a122f90d"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKkUJMz6K0WH",
        "outputId": "6a22af4b-4dca-4f5c-8f4a-d2df19f10756"
      },
      "source": [
        "LABEL.vocab.stoi"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None,\n",
              "            {'ABBR': 5, 'DESC': 2, 'ENTY': 0, 'HUM': 1, 'LOC': 4, 'NUM': 3})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaCMz4yZ_n5W"
      },
      "source": [
        "### Creating iterators.\n",
        "\n",
        "We are going to use our favorite iterator known as the `BucketIterator` to create iterators for all the sets that we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPDrPFKQ_mf1"
      },
      "source": [
        "sort_key = lambda x: len(x.text)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    device = device,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = sort_key,\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spZX8zodA91F"
      },
      "source": [
        "### Creating the Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReThGRspA7uO"
      },
      "source": [
        "class QuestionsLSTMRNN(nn.Module):\n",
        "  def __init__(self, \n",
        "               vocab_size,\n",
        "               embedding_size,\n",
        "               hidden_size,\n",
        "               output_size,\n",
        "               num_layers,\n",
        "               pad_index,\n",
        "               bidirectional = True,\n",
        "               dropout=.5\n",
        "               ):\n",
        "    super(QuestionsLSTMRNN, self).__init__()\n",
        "    self.embedding = nn.Embedding(\n",
        "        vocab_size,\n",
        "        embedding_size,\n",
        "        padding_idx = pad_index\n",
        "    )\n",
        "    self.lstm = nn.LSTM(\n",
        "        embedding_size,\n",
        "        hidden_size  = hidden_size,\n",
        "        bidirectional = bidirectional,\n",
        "        num_layers = num_layers,\n",
        "        dropout = dropout\n",
        "    )\n",
        "    self.fc_1 = nn.Linear(\n",
        "        hidden_size * 2 if bidirectional else hidden_size,\n",
        "        out_features = 512\n",
        "    )\n",
        "    self.fc_2 = nn.Linear(\n",
        "        512,\n",
        "        out_features = 256\n",
        "    )\n",
        "    self.out = nn.Linear(\n",
        "        256,\n",
        "        out_features = output_size\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text, text_lengths):\n",
        "    embedded = self.dropout(self.embedding(text))\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
        "        embedded, text_lengths.to('cpu'), enforce_sorted=False\n",
        "    )\n",
        "    packed_output, (h_0, c_0) = self.lstm(packed_embedded)\n",
        "    output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "    h_0 = self.dropout(torch.cat((h_0[-2,:,:], h_0[-1,:,:]), dim = 1))\n",
        "    out = self.dropout(self.fc_1(h_0))\n",
        "    out = self.dropout(self.fc_2(h_0))\n",
        "    return self.out(out)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2IVtv8EDhJd"
      },
      "source": [
        "### Creating the model instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbJdW058DgTl",
        "outputId": "7a88dbf1-3353-4b63-8367-7acf68bc11d4"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM =  6\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] \n",
        "\n",
        "questions_model = QuestionsLSTMRNN(\n",
        "            INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            bidirectional = BIDIRECTIONAL, \n",
        "            dropout = DROPOUT, \n",
        "            pad_index = PAD_IDX\n",
        "            ).to(device)\n",
        "questions_model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuestionsLSTMRNN(\n",
              "  (embedding): Embedding(9053, 100, padding_idx=1)\n",
              "  (lstm): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  (fc_1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (out): Linear(in_features=256, out_features=6, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acQD-B6zEE72"
      },
      "source": [
        "### Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQaztp4ID-HI",
        "outputId": "a425bdfe-d43c-41b6-e2eb-d9c317a30b3a"
      },
      "source": [
        "\n",
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(questions_model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of paramaters: 3,610,970\n",
            "Total tainable parameters: 3,610,970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8gjXny7EUNb"
      },
      "source": [
        "### Loading pretrained vextors to the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULe__PiKEQS8"
      },
      "source": [
        "pretrained_embeddings  = TEXT.vocab.vectors"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeXa9ycREfuV",
        "outputId": "e97a1e0d-536b-43af-dbee-b84da99654f2"
      },
      "source": [
        "questions_model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.1233,  0.3499,  0.6173],\n",
              "        [ 0.7262,  0.0912, -0.3891,  ...,  0.0821,  0.4440, -0.7240],\n",
              "        [ 0.1638,  0.6046,  1.0789,  ..., -0.3140,  0.1844,  0.3624],\n",
              "        ...,\n",
              "        [ 0.0091,  0.2810,  0.7356,  ..., -0.7508,  0.8967, -0.7631],\n",
              "        [ 0.2906,  0.3217,  0.2419,  ..., -0.9444, -0.3790,  0.6196],\n",
              "        [-0.3898, -0.5949,  0.2729,  ..., -1.0948,  0.8617, -0.4429]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q27hKnrpEoKF"
      },
      "source": [
        "### Zeroing the `<pad>` and `<unk>` tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_qvO2teEmvh",
        "outputId": "6df1a394-1e43-4288-e44d-557e6c85b44f"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token] or TEXT.vocab.stoi[\"<unk>\"]\n",
        "questions_model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "questions_model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "questions_model.embedding.weight.data"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.1638,  0.6046,  1.0789,  ..., -0.3140,  0.1844,  0.3624],\n",
              "        ...,\n",
              "        [ 0.0091,  0.2810,  0.7356,  ..., -0.7508,  0.8967, -0.7631],\n",
              "        [ 0.2906,  0.3217,  0.2419,  ..., -0.9444, -0.3790,  0.6196],\n",
              "        [-0.3898, -0.5949,  0.2729,  ..., -1.0948,  0.8617, -0.4429]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm2RklTLE-Dv"
      },
      "source": [
        "### Loss and optimizer.\n",
        "We are going to use the Adam as our optimizer with the default leaning rate. We are also going to use `CrossEntropyLoss()` as our loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7UCyAlYE1nA"
      },
      "source": [
        "optimizer = torch.optim.Adam(questions_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi2tk-kSFTVq"
      },
      "source": [
        "### Accuracy function.\n",
        "We are going to create the `categorical_accuracy()` function that will calculate the categorical accuracy for predicted labels and actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRCfQZvmFPBS"
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "  top_pred = preds.argmax(1, keepdim = True)\n",
        "  correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "  return correct.float() / y.shape[0]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gf_nyXVFvOG"
      },
      "source": [
        "### Training and Evaluation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80QEfQeaFuVZ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text, text_lengths = batch.text\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = categorical_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, text_lengths = batch.text\n",
        "            predictions = model(text, text_lengths)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = categorical_accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdtkgFFJG1WS"
      },
      "source": [
        "### Training loop.\n",
        "We are going to create helper functions that will help us to visualize our training.\n",
        "\n",
        "1. Time to string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMH6iA1AG0tj"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "    "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp5OjGiPHR6h"
      },
      "source": [
        "2. tabulate training epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtCTm84HHQb5"
      },
      "source": [
        "def visualize_training(start, end, train_loss, train_accuracy, val_loss, val_accuracy, title):\n",
        "  data = [\n",
        "       [\"Training\", f'{train_loss:.3f}', f'{train_accuracy:.3f}', f\"{hms_string(end - start)}\" ],\n",
        "       [\"Validation\", f'{val_loss:.3f}', f'{val_accuracy:.3f}', \"\" ],       \n",
        "  ]\n",
        "  table = PrettyTable([\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"])\n",
        "  table.align[\"CATEGORY\"] = 'l'\n",
        "  table.align[\"LOSS\"] = 'r'\n",
        "  table.align[\"ACCURACY\"] = 'r'\n",
        "  table.align[\"ETA\"] = 'r'\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcu_WMc2HXqb",
        "outputId": "f52b8661-b2e6-4fea-e7fb-fc7d6538525a"
      },
      "source": [
        "N_EPOCHS = 100\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss, train_acc = train(questions_model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(questions_model, val_iter, criterion)\n",
        "    title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} {'saving best model...' if valid_loss < best_valid_loss else 'not saving...'}\"\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(questions_model.state_dict(), 'best-model.pt')\n",
        "    end = time.time()\n",
        "    visualize_training(start, end, train_loss, train_acc, valid_loss, valid_acc, title)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------+\n",
            "|     EPOCH: 01/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 1.202 |    0.509 | 0:00:01.16 |\n",
            "| Validation | 0.882 |    0.696 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 02/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.815 |    0.692 | 0:00:01.06 |\n",
            "| Validation | 0.731 |    0.706 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 03/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.683 |    0.752 | 0:00:01.04 |\n",
            "| Validation | 0.599 |    0.778 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 04/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.596 |    0.789 | 0:00:01.05 |\n",
            "| Validation | 0.529 |    0.800 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 05/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.524 |    0.816 | 0:00:01.04 |\n",
            "| Validation | 0.487 |    0.813 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 06/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.460 |    0.838 | 0:00:01.04 |\n",
            "| Validation | 0.455 |    0.832 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 07/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.417 |    0.849 | 0:00:01.07 |\n",
            "| Validation | 0.391 |    0.842 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 08/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.351 |    0.874 | 0:00:01.06 |\n",
            "| Validation | 0.371 |    0.827 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 09/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.327 |    0.885 | 0:00:01.05 |\n",
            "| Validation | 0.359 |    0.869 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 10/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.280 |    0.903 | 0:00:01.01 |\n",
            "| Validation | 0.386 |    0.867 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 11/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.253 |    0.910 | 0:00:01.04 |\n",
            "| Validation | 0.349 |    0.872 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 12/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.226 |    0.920 | 0:00:01.04 |\n",
            "| Validation | 0.391 |    0.857 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 13/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.203 |    0.930 | 0:00:01.01 |\n",
            "| Validation | 0.350 |    0.874 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 14/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.176 |    0.940 | 0:00:01.01 |\n",
            "| Validation | 0.365 |    0.879 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 15/100 saving best model...     |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.171 |    0.942 | 0:00:01.06 |\n",
            "| Validation | 0.334 |    0.876 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 16/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.140 |    0.950 | 0:00:01.03 |\n",
            "| Validation | 0.371 |    0.874 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 17/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.133 |    0.957 | 0:00:01.02 |\n",
            "| Validation | 0.396 |    0.886 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 18/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.117 |    0.959 | 0:00:01.02 |\n",
            "| Validation | 0.416 |    0.883 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 19/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.116 |    0.962 | 0:00:01.02 |\n",
            "| Validation | 0.387 |    0.880 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 20/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.091 |    0.970 | 0:00:01.02 |\n",
            "| Validation | 0.398 |    0.886 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 21/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.091 |    0.971 | 0:00:01.02 |\n",
            "| Validation | 0.455 |    0.868 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 22/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.089 |    0.969 | 0:00:01.02 |\n",
            "| Validation | 0.480 |    0.882 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 23/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.080 |    0.973 | 0:00:01.02 |\n",
            "| Validation | 0.461 |    0.871 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 24/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.081 |    0.975 | 0:00:01.02 |\n",
            "| Validation | 0.454 |    0.895 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 25/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.063 |    0.977 | 0:00:01.01 |\n",
            "| Validation | 0.480 |    0.891 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 26/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.061 |    0.981 | 0:00:01.01 |\n",
            "| Validation | 0.560 |    0.861 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 27/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.068 |    0.977 | 0:00:01.02 |\n",
            "| Validation | 0.485 |    0.890 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 28/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.068 |    0.976 | 0:00:01.01 |\n",
            "| Validation | 0.388 |    0.895 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 29/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.070 |    0.975 | 0:00:01.01 |\n",
            "| Validation | 0.499 |    0.896 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 30/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.054 |    0.982 | 0:00:01.01 |\n",
            "| Validation | 0.532 |    0.890 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 31/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.044 |    0.988 | 0:00:01.01 |\n",
            "| Validation | 0.456 |    0.892 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 32/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.048 |    0.986 | 0:00:01.01 |\n",
            "| Validation | 0.507 |    0.890 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 33/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.042 |    0.986 | 0:00:01.03 |\n",
            "| Validation | 0.554 |    0.901 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 34/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.043 |    0.986 | 0:00:01.03 |\n",
            "| Validation | 0.524 |    0.894 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 35/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.039 |    0.987 | 0:00:01.03 |\n",
            "| Validation | 0.610 |    0.881 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 36/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.052 |    0.983 | 0:00:01.04 |\n",
            "| Validation | 0.543 |    0.898 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 37/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.038 |    0.989 | 0:00:01.03 |\n",
            "| Validation | 0.603 |    0.886 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 38/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.041 |    0.987 | 0:00:01.03 |\n",
            "| Validation | 0.560 |    0.886 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 39/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.044 |    0.984 | 0:00:01.04 |\n",
            "| Validation | 0.578 |    0.886 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 40/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.034 |    0.989 | 0:00:01.04 |\n",
            "| Validation | 0.545 |    0.890 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 41/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.037 |    0.988 | 0:00:01.03 |\n",
            "| Validation | 0.531 |    0.883 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 42/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.036 |    0.990 | 0:00:01.02 |\n",
            "| Validation | 0.602 |    0.899 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 43/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.027 |    0.992 | 0:00:01.04 |\n",
            "| Validation | 0.660 |    0.898 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 44/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.038 |    0.988 | 0:00:01.02 |\n",
            "| Validation | 0.566 |    0.890 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 45/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.026 |    0.992 | 0:00:01.02 |\n",
            "| Validation | 0.546 |    0.901 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 46/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.031 |    0.991 | 0:00:01.03 |\n",
            "| Validation | 0.522 |    0.902 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 47/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.032 |    0.992 | 0:00:01.03 |\n",
            "| Validation | 0.568 |    0.895 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 48/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.023 |    0.991 | 0:00:01.03 |\n",
            "| Validation | 0.628 |    0.899 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 49/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.029 |    0.991 | 0:00:01.02 |\n",
            "| Validation | 0.568 |    0.895 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 50/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.027 |    0.991 | 0:00:01.04 |\n",
            "| Validation | 0.602 |    0.890 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 51/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.021 |    0.994 | 0:00:01.03 |\n",
            "| Validation | 0.629 |    0.879 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 52/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.024 |    0.992 | 0:00:01.03 |\n",
            "| Validation | 0.614 |    0.892 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 53/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.027 |    0.991 | 0:00:01.03 |\n",
            "| Validation | 0.622 |    0.891 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 54/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.031 |    0.991 | 0:00:01.04 |\n",
            "| Validation | 0.576 |    0.896 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 55/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.022 |    0.993 | 0:00:01.02 |\n",
            "| Validation | 0.739 |    0.883 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 56/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.028 |    0.992 | 0:00:01.02 |\n",
            "| Validation | 0.623 |    0.896 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 57/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.019 |    0.996 | 0:00:01.02 |\n",
            "| Validation | 0.495 |    0.908 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 58/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.025 |    0.991 | 0:00:01.01 |\n",
            "| Validation | 0.639 |    0.890 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 59/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.022 |    0.994 | 0:00:01.00 |\n",
            "| Validation | 0.717 |    0.899 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 60/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.028 |    0.992 | 0:00:01.00 |\n",
            "| Validation | 0.594 |    0.897 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 61/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.016 |    0.995 | 0:00:01.00 |\n",
            "| Validation | 0.663 |    0.899 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 62/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.015 |    0.995 | 0:00:01.00 |\n",
            "| Validation | 0.695 |    0.891 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 63/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.020 |    0.993 | 0:00:00.99 |\n",
            "| Validation | 0.658 |    0.894 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 64/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.023 |    0.992 | 0:00:01.00 |\n",
            "| Validation | 0.658 |    0.881 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 65/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.025 |    0.991 | 0:00:01.00 |\n",
            "| Validation | 0.734 |    0.890 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 66/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.014 |    0.995 | 0:00:01.02 |\n",
            "| Validation | 0.686 |    0.879 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 67/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.016 |    0.996 | 0:00:01.00 |\n",
            "| Validation | 0.619 |    0.892 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 68/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.020 |    0.992 | 0:00:00.99 |\n",
            "| Validation | 0.601 |    0.890 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 69/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.014 |    0.995 | 0:00:00.99 |\n",
            "| Validation | 0.729 |    0.883 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 70/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.021 |    0.993 | 0:00:01.00 |\n",
            "| Validation | 0.752 |    0.891 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 71/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.015 |    0.996 | 0:00:01.00 |\n",
            "| Validation | 0.750 |    0.879 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 72/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.016 |    0.995 | 0:00:00.99 |\n",
            "| Validation | 0.840 |    0.883 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 73/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.011 |    0.997 | 0:00:01.00 |\n",
            "| Validation | 0.763 |    0.878 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 74/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.018 |    0.995 | 0:00:00.99 |\n",
            "| Validation | 0.743 |    0.895 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 75/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.016 |    0.995 | 0:00:00.99 |\n",
            "| Validation | 0.645 |    0.901 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 76/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.015 |    0.996 | 0:00:01.00 |\n",
            "| Validation | 0.642 |    0.892 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 77/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.012 |    0.996 | 0:00:00.99 |\n",
            "| Validation | 0.668 |    0.895 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 78/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.025 |    0.994 | 0:00:01.00 |\n",
            "| Validation | 0.646 |    0.890 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 79/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.014 |    0.996 | 0:00:00.99 |\n",
            "| Validation | 0.758 |    0.887 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 80/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.018 |    0.995 | 0:00:01.01 |\n",
            "| Validation | 0.762 |    0.873 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 81/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.012 |    0.995 | 0:00:01.00 |\n",
            "| Validation | 0.713 |    0.884 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 82/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.014 |    0.996 | 0:00:00.99 |\n",
            "| Validation | 0.675 |    0.895 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 83/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.020 |    0.993 | 0:00:00.99 |\n",
            "| Validation | 0.795 |    0.882 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 84/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.017 |    0.996 | 0:00:00.99 |\n",
            "| Validation | 0.711 |    0.896 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 85/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.010 |    0.997 | 0:00:01.01 |\n",
            "| Validation | 0.806 |    0.908 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 86/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.019 |    0.994 | 0:00:01.01 |\n",
            "| Validation | 0.654 |    0.886 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 87/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.012 |    0.996 | 0:00:01.00 |\n",
            "| Validation | 0.688 |    0.890 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 88/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.019 |    0.994 | 0:00:01.00 |\n",
            "| Validation | 0.680 |    0.895 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 89/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.016 |    0.995 | 0:00:00.99 |\n",
            "| Validation | 0.782 |    0.904 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 90/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.015 |    0.996 | 0:00:01.00 |\n",
            "| Validation | 0.879 |    0.883 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 91/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.014 |    0.996 | 0:00:01.00 |\n",
            "| Validation | 0.829 |    0.901 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 92/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.008 |    0.997 | 0:00:01.00 |\n",
            "| Validation | 0.906 |    0.879 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 93/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.016 |    0.996 | 0:00:01.00 |\n",
            "| Validation | 0.848 |    0.870 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 94/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.020 |    0.994 | 0:00:01.00 |\n",
            "| Validation | 0.772 |    0.899 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 95/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.010 |    0.997 | 0:00:01.00 |\n",
            "| Validation | 0.850 |    0.893 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 96/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.014 |    0.996 | 0:00:01.01 |\n",
            "| Validation | 0.863 |    0.907 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 97/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.019 |    0.995 | 0:00:01.00 |\n",
            "| Validation | 0.826 |    0.883 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 98/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.017 |    0.996 | 0:00:01.01 |\n",
            "| Validation | 0.785 |    0.902 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 99/100 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.013 |    0.996 | 0:00:01.02 |\n",
            "| Validation | 0.728 |    0.899 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|        EPOCH: 100/100 not saving...        |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.013 |    0.995 | 0:00:01.03 |\n",
            "| Validation | 0.746 |    0.879 |            |\n",
            "+------------+-------+----------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNkikbDIB2z"
      },
      "source": [
        "### Model Evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8fWTBruHw1p",
        "outputId": "0f6bc030-6002-4207-b87d-a1856ff5d34f"
      },
      "source": [
        "questions_model.load_state_dict(torch.load('best-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(questions_model, test_iter, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.568 | Test Acc: 85.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4zEBLYsLki5"
      },
      "source": [
        "### Model Inference.\n",
        "\n",
        "We are now ready to make predictions with our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyNLifHaJBKS"
      },
      "source": [
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clNBiJ9NPkRJ",
        "outputId": "d5bf324e-689f-4b8a-fccd-b885eb1c1826"
      },
      "source": [
        "reversed_labels = dict([(v, k) for (k, v) in LABEL.vocab.stoi.items()])\n",
        "reversed_labels"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'ENTY', 1: 'HUM', 2: 'DESC', 3: 'NUM', 4: 'LOC', 5: 'ABBR'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9A6ZGTILzWD"
      },
      "source": [
        "def tabulate(column_names, data, title=\"QUESTIONS PREDICTIONS TABLE\"):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.align[column_names[0]] = \"l\"\n",
        "  table.align[column_names[1]] = \"l\"\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "\n",
        "def predict_question_type(model, sentence, min_len = 5, actual_class=0):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "     \n",
        "      if len(tokenized) < min_len:\n",
        "          tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "      indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "      length =  [len(indexed)]\n",
        "      tensor = torch.LongTensor(indexed).to(device)\n",
        "      tensor = tensor.unsqueeze(1)\n",
        "      length_tensor = torch.LongTensor(length)\n",
        "      probabilities = model(tensor, length_tensor)\n",
        "      prediction = torch.argmax(probabilities, dim=1)\n",
        "      prediction = prediction.item()\n",
        "    \n",
        "      table_headers =[\"KEY\", \"VALUE\"]\n",
        "      table_data = [\n",
        "          [\"PREDICTED CLASS\",  prediction],\n",
        "          [\"ACTUAL CLASS\", actual_class],\n",
        "          [\"PREDICTED CLASS NAME\",  reversed_labels[prediction]],    \n",
        "      ]\n",
        "      tabulate(table_headers, table_data)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm5h2CDLUECt",
        "outputId": "8130987b-f72c-4c99-a7eb-d43952ba0399"
      },
      "source": [
        "reversed_labels"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'ENTY', 1: 'HUM', 2: 'DESC', 3: 'NUM', 4: 'LOC', 5: 'ABBR'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W93zzSlQMO4p"
      },
      "source": [
        "### Location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcuHlaPwML4Y",
        "outputId": "efa9d482-24d5-43f0-fa59-55ebf47c7276"
      },
      "source": [
        "predict_question_type(questions_model, \"What are the largest libraries in the US ?\", actual_class=4)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 4     |\n",
            "| ACTUAL CLASS         | 4     |\n",
            "| PREDICTED CLASS NAME | LOC   |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5Eqjo0MMP8L"
      },
      "source": [
        "### Human"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnhFchDiMQQn",
        "outputId": "4b8600ad-df6e-4214-8cf3-c66eb4511fd2"
      },
      "source": [
        "predict_question_type(questions_model, \"Who is John Macarthur , 1767-1834 ?\", actual_class=1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 1     |\n",
            "| ACTUAL CLASS         | 1     |\n",
            "| PREDICTED CLASS NAME | HUM   |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WvswKe5MQ3D"
      },
      "source": [
        "### DESCRIPTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3jeZM6xMRVy",
        "outputId": "bd5b5dad-d7ff-45e6-e067-47ea7e9618cf"
      },
      "source": [
        "predict_question_type(questions_model, \"What is the root of all evil ? \", actual_class=2)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 2     |\n",
            "| ACTUAL CLASS         | 2     |\n",
            "| PREDICTED CLASS NAME | DESC  |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeGjIT9NMRxA"
      },
      "source": [
        "### Numeric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GxH8LKiMSOH",
        "outputId": "5e576792-a0c0-42d1-da21-438dab4662c7"
      },
      "source": [
        "predict_question_type(questions_model, \"How many watts make a kilowatt ?\", actual_class=3)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 3     |\n",
            "| ACTUAL CLASS         | 3     |\n",
            "| PREDICTED CLASS NAME | NUM   |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-7beS0jPLW7"
      },
      "source": [
        "### ENTITY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvQq7ul9PHFI",
        "outputId": "2ef9a1a1-fff1-4f09-b569-b3f0df7c401c"
      },
      "source": [
        "\n",
        "predict_question_type(questions_model, \"What films featured the character Popeye Doyle ?\", actual_class=0)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 0     |\n",
            "| ACTUAL CLASS         | 0     |\n",
            "| PREDICTED CLASS NAME | ENTY  |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ0cQrfFQ9QI"
      },
      "source": [
        "### ABBREVIATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvzy3XHRQZQQ",
        "outputId": "939aef7a-ef29-4b7e-8af9-b3bb96959ec8"
      },
      "source": [
        "predict_question_type(questions_model, \"What does NECROSIS mean ?\", actual_class=5)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+-------+\n",
            "| KEY                  | VALUE |\n",
            "+----------------------+-------+\n",
            "| PREDICTED CLASS      | 5     |\n",
            "| ACTUAL CLASS         | 5     |\n",
            "| PREDICTED CLASS NAME | ABBR  |\n",
            "+----------------------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sa3_lq4VHSn"
      },
      "source": [
        "### Next Step\n",
        "* In the next Notebook we are going to use `FastText` to perform sentiment analyisis on this dataset."
      ]
    }
  ]
}