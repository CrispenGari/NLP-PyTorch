{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Duplicate_Questions_FastText.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7Jsp1cXo42F"
      },
      "source": [
        "### Question Pairs\n",
        "\n",
        "In the last notebook we used packed padded to do a binary classification on questions. We were classifying weather questions are duplicated or not. In this notebook we are going to create a modified `FastText` that will do the same task.\n",
        "\n",
        "**Note**: The rest of the notebook will remain unchanged from the previous one. Where there's a change i will highlight.\n",
        "\n",
        "### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7CjjHG0zomH9",
        "outputId": "77c49aa1-e143-468d-c9b9-0f0d00606c08"
      },
      "source": [
        "import time, os, torch, random, math\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch, os, random\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.9.0+cu102'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GP7IDeFrG_y"
      },
      "source": [
        "### SEEDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFDVrd3arD1-"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deteministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l8XBaShrNPp"
      },
      "source": [
        "### Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0nGBaM2rKqn",
        "outputId": "95bb5f07-3f0a-49dc-b3dd-bb069d48de7e"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TtGHvnUsML-"
      },
      "source": [
        "### Mounting the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHCa7e5NsR3L",
        "outputId": "502d3456-ce7e-4a11-8eb2-32fc49fb9706"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLVZWBcorbTh"
      },
      "source": [
        "### Paths to data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0KKQSDjrXhr",
        "outputId": "efa37730-e34a-464a-f7a4-3cd67f34a35d"
      },
      "source": [
        "base_path = '/content/drive/MyDrive/NLP Data/duplicates-questions'\n",
        "train_path = 'train.csv'\n",
        "val_path = 'val.csv'\n",
        "test_path = 'test.csv'\n",
        "\n",
        "os.path.exists(base_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_gtMwjPsjxa"
      },
      "source": [
        "### Data Loading\n",
        "This is a binary classification task where we are going to predict weather questions are duplicates or not. We are going to have 2 inputs which is two differant questions that will map to one label, is_duplicate(1) or is_not_duplicate (0). We are going to create the fields of our data. \n",
        "\n",
        "### Fast Text\n",
        "Accoding to the FastText paper we need to generate bigrams for each question.\n",
        "\n",
        "We are going to create a function called ``generate_bigram()`` that will generate bigrams for us for both of these two input questions. We will pass this function to the Text field as the preprocessing function.\n",
        "\n",
        "### What do we have?\n",
        "We are having three `csv` files for each set whih makes it easy to create the dataset for this task.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8rjJRvF7sbe",
        "outputId": "45dcd10f-deaa-4578-ef7e-563b4933ca67"
      },
      "source": [
        "def generate_bigrams(x):\n",
        "  x = [i.lower() for i in x]\n",
        "  n_grams = set(zip(*[x[i: ] for i in range(2)]))\n",
        "  for n_gram in n_grams:\n",
        "      x.append(' '.join(n_gram))\n",
        "  return x\n",
        "generate_bigrams(['What', 'is', 'the', 'meaning', \"of\", \"OCR\", \"in\", \"python\"])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'meaning',\n",
              " 'of',\n",
              " 'ocr',\n",
              " 'in',\n",
              " 'python',\n",
              " 'the meaning',\n",
              " 'of ocr',\n",
              " 'in python',\n",
              " 'meaning of',\n",
              " 'is the',\n",
              " 'what is',\n",
              " 'ocr in']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbyLjuhrsDES"
      },
      "source": [
        "from torchtext.legacy import data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwE4hbQAvMRp"
      },
      "source": [
        "### Fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSxCs527vK5G"
      },
      "source": [
        "TEXT = data.Field(\n",
        "      tokenize = 'spacy',\n",
        "      tokenizer_language = 'en_core_web_sm',\n",
        "      preprocessing = generate_bigrams,\n",
        "    )\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDB7h4t8wNc0"
      },
      "source": [
        "fields = {\n",
        "    \"question1\": (\"qn1\", TEXT),\n",
        "    \"question2\": (\"qn2\", TEXT), \n",
        "    \"is_duplicate\": (\"label\", LABEL),\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LsuY9EXwsm-"
      },
      "source": [
        "Next we will create our dataset using our favourate class fro  torchtext `TabularDataset`. We are going to load the data that is in `csv` format as follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVu-sAxPwryA"
      },
      "source": [
        "train_data, val_data, test_data = data.TabularDataset.splits(\n",
        "   base_path,\n",
        "   train=train_path,\n",
        "   test= test_path,\n",
        "   validation= val_path,\n",
        "   format = \"csv\",\n",
        "   fields=fields\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWjZPcAZxGHS",
        "outputId": "6bb5853c-67f3-4397-f463-2d7871e4d9f0"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'qn1': ['is', 'it', 'right', 'for', 'a', 'woman', 'to', 'date', 'someone', '2', '-', '3', 'years', 'younger', 'than', 'her', '?', 'is it', 'for a', 'date someone', 'a woman', 'woman to', 'to date', 'someone 2', '2 -', 'younger than', 'it right', 'her ?', '3 years', 'right for', '- 3', 'than her', 'years younger'], 'qn2': ['is', 'it', 'strange', 'to', 'have', 'a', 'crush', 'on', 'someone', 'say', '17', 'years', 'younger', 'than', 'me', '?', 'crush on', 'is it', 'to have', 'have a', 'me ?', 'on someone', 'younger than', 'strange to', 'than me', 'it strange', 'say 17', 'someone say', 'a crush', 'years younger', '17 years'], 'label': '0'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlNAFiSnxNhd"
      },
      "source": [
        "#### Next we will build the Vocabulary.\n",
        "\n",
        "We are going to use the pretrained word vectors `glove.6B.100d` which was trained on about 6 billion english words.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfx6__Xxx3xN"
      },
      "source": [
        "\n",
        "MAX_VOCAB_SIZE = 100_000\n",
        "\n",
        "TEXT.build_vocab(\n",
        "     train_data,\n",
        "     max_size = MAX_VOCAB_SIZE,\n",
        "     vectors = \"glove.6B.100d\",\n",
        "    unk_init = torch.Tensor.normal_\n",
        ")\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jx5d2T-0NXe",
        "outputId": "cd53d428-abc4-4cd2-c626-29ed8a5c59ae"
      },
      "source": [
        "LABEL.vocab.stoi"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None, {'0': 0, '1': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG3-CxkOz50d"
      },
      "source": [
        "### Creating iterators\n",
        "\n",
        "We are going to use the `BucketIterator` to create iterators for all these sets that we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pzygmoay7jG"
      },
      "source": [
        "sort_key = lambda x: len(x.qn1)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    device = device,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = sort_key,\n",
        "    sort_within_batch=True\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUxdqysr0bK-"
      },
      "source": [
        "### Next we are going to create the model.\n",
        "\n",
        "We are going to have two inputs which will be Question1 and Question2.\n",
        "* Each question will be passed through it's own embedding layer.\n",
        "* These embedding layers will then be concatenated and passed through a linear layer for predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOe3SQ6b0WMz"
      },
      "source": [
        "class DuplicateQuestionsFastText(nn.Module):\n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               embedding_size,\n",
        "               output_dim,\n",
        "               pad_index,\n",
        "               dropout=.5\n",
        "               ):\n",
        "    super(DuplicateQuestionsFastText, self).__init__()\n",
        "    self.embedding_1 = nn.Embedding(\n",
        "        vocab_size,\n",
        "        embedding_size,\n",
        "        padding_idx = pad_index\n",
        "    )\n",
        "    self.embedding_2 = nn.Embedding(\n",
        "        vocab_size,\n",
        "        embedding_size,\n",
        "        padding_idx = pad_index\n",
        "    )\n",
        "    self.out = nn.Linear(\n",
        "        embedding_size,\n",
        "        out_features = output_dim\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self,\n",
        "              question1, \n",
        "              question2, \n",
        "              ):\n",
        "    embedded_1 = self.embedding_1(question1).permute(1 ,0, 2)\n",
        "    embedded_2 = self.embedding_2(question2).permute(1 ,0, 2)\n",
        "    embedded = self.dropout(torch.cat((embedded_1, embedded_2), dim=1))\n",
        "    pooled = F.avg_pool2d(embedded,\n",
        "                         (embedded.shape[1], 1)\n",
        "                          ).squeeze(1)\n",
        "    return self.out(pooled)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyQnPnO7A8fw",
        "outputId": "c322d910-5401-4a72-c8cd-82ac04a15b73"
      },
      "source": [
        "a = torch.tensor([[2, 3, 5], [2, 3, 4]])\n",
        "a = a.reshape((3, -1))\n",
        "a.shape\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPZB4wPJ8MH5"
      },
      "source": [
        "### Creating the model instance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jemm7xH8LKE",
        "outputId": "4e9209b2-230d-4ae1-f347-208e434b6583"
      },
      "source": [
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM =  1\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] \n",
        "\n",
        "duplicate_questions_model = DuplicateQuestionsFastText(\n",
        "            INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            pad_index = PAD_IDX\n",
        "            ).to(device)\n",
        "duplicate_questions_model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DuplicateQuestionsFastText(\n",
              "  (embedding_1): Embedding(100002, 100, padding_idx=1)\n",
              "  (embedding_2): Embedding(100002, 100, padding_idx=1)\n",
              "  (out): Linear(in_features=100, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF84BeAV8yIc"
      },
      "source": [
        "### Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8ahZtoC8iMX",
        "outputId": "0b36657c-5657-4dff-dc84-9203ab14c79c"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(duplicate_questions_model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of paramaters: 20,000,501\n",
            "Total tainable parameters: 20,000,501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIWPKwjl88OA"
      },
      "source": [
        "### Loading pretrained vectors to the `embedding` layers.\n",
        "* Now we have two embedding layers in the model, so we need to add the word vectors to each embedding layer as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTfwoZlo849_"
      },
      "source": [
        "pretrained_embeddings  = TEXT.vocab.vectors"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr9kpInY9DmE",
        "outputId": "7848c9d4-c463-4ec8-8522-b4bfc2eac4c8"
      },
      "source": [
        "duplicate_questions_model.embedding_1.weight.data.copy_(\n",
        "    pretrained_embeddings\n",
        "    )\n",
        "duplicate_questions_model.embedding_2.weight.data.copy_(\n",
        "    pretrained_embeddings\n",
        "    )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.1233,  0.3499,  0.6173],\n",
              "        [ 0.7262,  0.0912, -0.3891,  ...,  0.0821,  0.4440, -0.7240],\n",
              "        [ 0.1638,  0.6046,  1.0789,  ..., -0.3140,  0.1844,  0.3624],\n",
              "        ...,\n",
              "        [-1.0188, -1.3804, -1.4044,  ..., -2.0274, -0.4045, -1.8920],\n",
              "        [ 0.0247, -1.1202, -0.2275,  ...,  1.1231,  0.2079, -2.3545],\n",
              "        [-1.8090,  0.4517, -1.6228,  ..., -0.1685, -0.4630, -0.9866]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzAbLd5P9iZ6"
      },
      "source": [
        "### Zeroing the `<pad>` and the `<unk>` tokens.\n",
        "\n",
        "These tokens are not acually necessary for the model trainning that's the reason we are zeroing them. We will do this for all our emmbedding layers in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEvzZ5yG9fII",
        "outputId": "51de296e-d76e-4a47-90e0-3c8f55500880"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token] or TEXT.vocab.stoi[\"<unk>\"]\n",
        "\n",
        "duplicate_questions_model.embedding_1.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "duplicate_questions_model.embedding_1.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "duplicate_questions_model.embedding_2.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "duplicate_questions_model.embedding_2.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "duplicate_questions_model.embedding_1.weight.data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.1638,  0.6046,  1.0789,  ..., -0.3140,  0.1844,  0.3624],\n",
              "        ...,\n",
              "        [-1.0188, -1.3804, -1.4044,  ..., -2.0274, -0.4045, -1.8920],\n",
              "        [ 0.0247, -1.1202, -0.2275,  ...,  1.1231,  0.2079, -2.3545],\n",
              "        [-1.8090,  0.4517, -1.6228,  ..., -0.1685, -0.4630, -0.9866]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB0sVZ2T-Xiz"
      },
      "source": [
        "### Loss and optimizer\n",
        "For the optimizer we are going to use `Adam()` with default paramaters and for the loss function we are going to use the `BCEWithLogitsLoss()` since we are doing a binary classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDNamG-K976I"
      },
      "source": [
        "optimizer = torch.optim.Adam(duplicate_questions_model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss().to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdWa5_qp-_4K"
      },
      "source": [
        "### Accuracy function.\n",
        "For the accuracy we are going to create a `binary_accuracy` function that will take predicted labels and accual labels to return the accuracy as a probability value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF1P4NyX-XQp"
      },
      "source": [
        "def binary_accuracy(y_preds, y_true):\n",
        "  rounded_preds = torch.round(torch.sigmoid(y_preds))\n",
        "  correct = (rounded_preds == y_true).float()\n",
        "  return correct.sum() / len(correct)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEiypTM7_iF9"
      },
      "source": [
        "### Train and evaluation function.\n",
        "This time around we have two features which is our two text labels. The model except 2 positional args which are:\n",
        "```\n",
        "  question1, \n",
        "  question2\n",
        "```\n",
        "### Where are we going to get them?\n",
        "\n",
        "Well our iterator contains all this information so we dont have o worry much about that. Let's create a train and evaluation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8TMKyT5-XM_"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss,epoch_acc = 0, 0\n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    qn1 = batch.qn1\n",
        "    qn2= batch.qn2\n",
        "    predictions = model(qn1, qn2).squeeze(1)\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    acc = binary_accuracy(predictions, batch.label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss,epoch_acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      qn1 = batch.qn1\n",
        "      qn2 = batch.qn2\n",
        "      predictions = model(qn1, qn2).squeeze(1)\n",
        "      loss = criterion(predictions, batch.label)\n",
        "      acc = binary_accuracy(predictions, batch.label)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_Ddb4rDBpeH"
      },
      "source": [
        "### Train Loop\n",
        "\n",
        "We are going to create some helper functions that will help us to visualize every epoch during training.\n",
        "\n",
        "Time to string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81icrKOD-XKU"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewfk-aIcB8BW"
      },
      "source": [
        "Tabulate training epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSnir_zT-XGi"
      },
      "source": [
        "def visualize_training(start, end, train_loss, train_accuracy, val_loss, val_accuracy, title):\n",
        "  data = [\n",
        "       [\"Training\", f'{train_loss:.3f}', f'{train_accuracy:.3f}', f\"{hms_string(end - start)}\" ],\n",
        "       [\"Validation\", f'{val_loss:.3f}', f'{val_accuracy:.3f}', \"\" ],       \n",
        "  ]\n",
        "  table = PrettyTable([\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"])\n",
        "  table.align[\"CATEGORY\"] = 'l'\n",
        "  table.align[\"LOSS\"] = 'r'\n",
        "  table.align[\"ACCURACY\"] = 'r'\n",
        "  table.align[\"ETA\"] = 'r'\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "  "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JdSJnqp-XDO",
        "outputId": "8d989653-1350-4313-f00b-856a00b9f989"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start = time.time()\n",
        "  train_loss, train_acc = train(duplicate_questions_model, train_iter, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(duplicate_questions_model, val_iter, criterion)\n",
        "  title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} {'saving best model...' if valid_loss < best_valid_loss else 'not saving...'}\"\n",
        "  if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(duplicate_questions_model.state_dict(), 'best-model.pt')\n",
        "  end = time.time()\n",
        "  visualize_training(start, end, train_loss, train_acc, valid_loss, valid_acc, title)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------+\n",
            "|     EPOCH: 01/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.530 |    0.739 | 0:00:45.04 |\n",
            "| Validation | 0.492 |    0.765 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 02/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.466 |    0.783 | 0:00:44.70 |\n",
            "| Validation | 0.470 |    0.777 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 03/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.435 |    0.800 | 0:00:45.06 |\n",
            "| Validation | 0.458 |    0.785 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 04/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.411 |    0.813 | 0:00:44.78 |\n",
            "| Validation | 0.451 |    0.789 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 05/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.393 |    0.823 | 0:00:44.83 |\n",
            "| Validation | 0.449 |    0.795 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 06/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.377 |    0.831 | 0:00:45.10 |\n",
            "| Validation | 0.450 |    0.799 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 07/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.365 |    0.837 | 0:00:44.85 |\n",
            "| Validation | 0.455 |    0.798 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 08/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.353 |    0.843 | 0:00:44.85 |\n",
            "| Validation | 0.457 |    0.796 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 09/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.344 |    0.848 | 0:00:44.45 |\n",
            "| Validation | 0.460 |    0.796 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 10/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.335 |    0.852 | 0:00:44.83 |\n",
            "| Validation | 0.464 |    0.797 |            |\n",
            "+------------+-------+----------+------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IMcTLBMq-T5"
      },
      "source": [
        "### Evaluating the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOjGeUSMrGMK",
        "outputId": "166377a0-4b02-49dc-b479-db5ab4f7076d"
      },
      "source": [
        "duplicate_questions_model.load_state_dict(torch.load('best-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(duplicate_questions_model, test_iter, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.450 | Test Acc: 78.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QJBuD65ioTa"
      },
      "source": [
        "### Model Inference\n",
        "\n",
        "Our predict sentiment function will:\n",
        "\n",
        "* get `two` question pairs, tokenize them and convert them to sequences.\n",
        "* pass the model the, questions that are converted to tensors.\n",
        "* Apply the sigmoid to get the accual label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URonyAkn-W8J"
      },
      "source": [
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "def predict_sentiment(model, q1, q2):\n",
        "  model.eval()\n",
        "  tokenized_q1 = [tok.text for tok in nlp.tokenizer(q1.lower())]\n",
        "  tokenized_q2 = [tok.text for tok in nlp.tokenizer(q2.lower())]\n",
        "\n",
        "  indexed_1 = [TEXT.vocab.stoi[t] for t in tokenized_q1]\n",
        "  indexed_2 = [TEXT.vocab.stoi[t] for t in tokenized_q2]\n",
        "\n",
        "  tensor_1 = torch.LongTensor(indexed_1).to(device).unsqueeze(1)\n",
        "  tensor_2 = torch.LongTensor(indexed_2).to(device).unsqueeze(1)\n",
        "\n",
        "  prediction = torch.sigmoid(model(tensor_1, tensor_2))\n",
        "  return prediction.item()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ReNykvykiHn"
      },
      "source": [
        "### Getting questions for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZAPfDiIEcG9"
      },
      "source": [
        "dataframe = pd.read_csv(os.path.join(\n",
        "    base_path,\n",
        "    test_path\n",
        "))\n",
        "\n",
        "qns1 = dataframe.question1.values\n",
        "qns2 = dataframe.question2.values\n",
        "true_labels = dataframe.is_duplicate.values"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ0b8lZWkhm9"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "def tabulate(column_names, data, max_characters:int, title:str):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.align[column_names[0]] = \"l\"\n",
        "  table.align[column_names[1]] = \"l\"\n",
        "  table.title = title\n",
        "  table._max_width = {column_names[0] :max_characters, column_names[1] :max_characters}\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L-s8DwykhkG",
        "outputId": "ba08c12f-e918-4c1a-8564-458a72081246"
      },
      "source": [
        "\n",
        "for i, (q1, q2, label) in enumerate(zip(qns1, qns2, true_labels[:10])):\n",
        "  pred = predict_sentiment(duplicate_questions_model, q1, q2)\n",
        "  classes = [\"not duplicate\", \"duplicate\"]\n",
        "  probability = pred if pred >=0.5 else 1 - pred\n",
        "  table_headers =[\"KEY\", \"VALUE\"]\n",
        "  table_data = [\n",
        "        [\"Question 1\", q1],\n",
        "        [\"Question2\", q2],\n",
        "        [\"PREDICTED CLASS\",  round(pred)],\n",
        "        [\"PREDICTED CLASS NAME\",  classes[round(pred)]],\n",
        "        [\"REAL CLASS\",  label],\n",
        "        [\"REAL CLASS NAME\",  classes[label]],\n",
        "        [\"CONFIDENCE OVER OTHER CLASSES\", f'{ probability * 100:.2f}%'],\n",
        "             \n",
        "    ]\n",
        "  title = \"Duplicate Questions\"\n",
        "  tabulate(table_headers, table_data, 50, title=title)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------------------------+\n",
            "|                                Duplicate Questions                                 |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| KEY                           | VALUE                                              |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| Question 1                    | Do you watch Korean dramas?                        |\n",
            "| Question2                     | Is it normal to watch Korean drama if you are a    |\n",
            "|                               | guy?                                               |\n",
            "| PREDICTED CLASS               | 0                                                  |\n",
            "| PREDICTED CLASS NAME          | not duplicate                                      |\n",
            "| REAL CLASS                    | 0                                                  |\n",
            "| REAL CLASS NAME               | not duplicate                                      |\n",
            "| CONFIDENCE OVER OTHER CLASSES | 89.91%                                             |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "+------------------------------------------------------------------------------------+\n",
            "|                                Duplicate Questions                                 |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| KEY                           | VALUE                                              |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| Question 1                    | What are some good home remedies for getting rid   |\n",
            "|                               | of stress bumps on the lips?                       |\n",
            "| Question2                     | How do I get rid of an acidic tummy and a sore     |\n",
            "|                               | mouth? Is there any home remedies?                 |\n",
            "| PREDICTED CLASS               | 0                                                  |\n",
            "| PREDICTED CLASS NAME          | not duplicate                                      |\n",
            "| REAL CLASS                    | 0                                                  |\n",
            "| REAL CLASS NAME               | not duplicate                                      |\n",
            "| CONFIDENCE OVER OTHER CLASSES | 65.72%                                             |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "+------------------------------------------------------------------------------------+\n",
            "|                                Duplicate Questions                                 |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| KEY                           | VALUE                                              |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| Question 1                    | “Everyone wants to go to Baghdad. Real men want to |\n",
            "|                               | go to Tehran.” What does this mean?                |\n",
            "| Question2                     | Why do you want to go back to college days?        |\n",
            "| PREDICTED CLASS               | 1                                                  |\n",
            "| PREDICTED CLASS NAME          | duplicate                                          |\n",
            "| REAL CLASS                    | 0                                                  |\n",
            "| REAL CLASS NAME               | not duplicate                                      |\n",
            "| CONFIDENCE OVER OTHER CLASSES | 56.61%                                             |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "+-------------------------------------------------------------------+\n",
            "|                        Duplicate Questions                        |\n",
            "+-------------------------------+-----------------------------------+\n",
            "| KEY                           | VALUE                             |\n",
            "+-------------------------------+-----------------------------------+\n",
            "| Question 1                    | How can I ask my wife for sex?    |\n",
            "| Question2                     | Do I have to ask my wife for sex? |\n",
            "| PREDICTED CLASS               | 1                                 |\n",
            "| PREDICTED CLASS NAME          | duplicate                         |\n",
            "| REAL CLASS                    | 0                                 |\n",
            "| REAL CLASS NAME               | not duplicate                     |\n",
            "| CONFIDENCE OVER OTHER CLASSES | 93.09%                            |\n",
            "+-------------------------------+-----------------------------------+\n",
            "+------------------------------------------------------------------------------------+\n",
            "|                                Duplicate Questions                                 |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| KEY                           | VALUE                                              |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| Question 1                    | How do you deal with having a bad reputation in    |\n",
            "|                               | college?                                           |\n",
            "| Question2                     | How can I deal with bad reputation in college?     |\n",
            "| PREDICTED CLASS               | 1                                                  |\n",
            "| PREDICTED CLASS NAME          | duplicate                                          |\n",
            "| REAL CLASS                    | 0                                                  |\n",
            "| REAL CLASS NAME               | not duplicate                                      |\n",
            "| CONFIDENCE OVER OTHER CLASSES | 76.68%                                             |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "+------------------------------------------------------------------------------------+\n",
            "|                                Duplicate Questions                                 |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| KEY                           | VALUE                                              |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| Question 1                    | What credit card is the one that you pay the       |\n",
            "|                               | least?                                             |\n",
            "| Question2                     | What are the consiquences of not paying the credit |\n",
            "|                               | card?                                              |\n",
            "| PREDICTED CLASS               | 0                                                  |\n",
            "| PREDICTED CLASS NAME          | not duplicate                                      |\n",
            "| REAL CLASS                    | 0                                                  |\n",
            "| REAL CLASS NAME               | not duplicate                                      |\n",
            "| CONFIDENCE OVER OTHER CLASSES | 67.27%                                             |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "+----------------------------------------------------------------------+\n",
            "|                         Duplicate Questions                          |\n",
            "+-------------------------------+--------------------------------------+\n",
            "| KEY                           | VALUE                                |\n",
            "+-------------------------------+--------------------------------------+\n",
            "| Question 1                    | Does Elon Musk have a lack of focus? |\n",
            "| Question2                     | What is the origin of the Drama?     |\n",
            "| PREDICTED CLASS               | 1                                    |\n",
            "| PREDICTED CLASS NAME          | duplicate                            |\n",
            "| REAL CLASS                    | 0                                    |\n",
            "| REAL CLASS NAME               | not duplicate                        |\n",
            "| CONFIDENCE OVER OTHER CLASSES | 98.80%                               |\n",
            "+-------------------------------+--------------------------------------+\n",
            "+------------------------------------------------------------------------------------+\n",
            "|                                Duplicate Questions                                 |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| KEY                           | VALUE                                              |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| Question 1                    | What universities does Investors Real estate       |\n",
            "|                               | recruit new grads from? What majors are they       |\n",
            "|                               | looking for?                                       |\n",
            "| Question2                     | What universities does Renaissance Real estate     |\n",
            "|                               | recruit new grads from? What majors are they       |\n",
            "|                               | looking for?                                       |\n",
            "| PREDICTED CLASS               | 0                                                  |\n",
            "| PREDICTED CLASS NAME          | not duplicate                                      |\n",
            "| REAL CLASS                    | 0                                                  |\n",
            "| REAL CLASS NAME               | not duplicate                                      |\n",
            "| CONFIDENCE OVER OTHER CLASSES | 99.37%                                             |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "+------------------------------------------------------------------------------------+\n",
            "|                                Duplicate Questions                                 |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| KEY                           | VALUE                                              |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| Question 1                    | Could God who is truly all powerful create a rock  |\n",
            "|                               | that he himself could not lift?                    |\n",
            "| Question2                     | If God is all powerful can he make a rock so heavy |\n",
            "|                               | even he cannot lift it?                            |\n",
            "| PREDICTED CLASS               | 1                                                  |\n",
            "| PREDICTED CLASS NAME          | duplicate                                          |\n",
            "| REAL CLASS                    | 1                                                  |\n",
            "| REAL CLASS NAME               | duplicate                                          |\n",
            "| CONFIDENCE OVER OTHER CLASSES | 99.31%                                             |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "+------------------------------------------------------------------------------------+\n",
            "|                                Duplicate Questions                                 |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| KEY                           | VALUE                                              |\n",
            "+-------------------------------+----------------------------------------------------+\n",
            "| Question 1                    | How do I convey my mom (single mother) that i      |\n",
            "|                               | want/need to get married asap indirectly? Please   |\n",
            "|                               | help                                               |\n",
            "| Question2                     | How do I convey my parents that they need to let   |\n",
            "|                               | me take my own decisions?                          |\n",
            "| PREDICTED CLASS               | 0                                                  |\n",
            "| PREDICTED CLASS NAME          | not duplicate                                      |\n",
            "| REAL CLASS                    | 0                                                  |\n",
            "| REAL CLASS NAME               | not duplicate                                      |\n",
            "| CONFIDENCE OVER OTHER CLASSES | 89.29%                                             |\n",
            "+-------------------------------+----------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKQW_sudmrj0"
      },
      "source": [
        "### Conclusion.\n",
        "\n",
        "We have learned how to create a model that maps 2 inputs to one output using the modified FastText model. What's Next?\n",
        "\n",
        "### Next.\n",
        "In the next notebook we are going to do the same task with `ConvNets` specifically the use of `Conv2D` layers on sequential data. We are going to use this notebook as the base and then we expand it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4-amj_DGKYH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}